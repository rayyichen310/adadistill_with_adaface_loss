Training: 2025-11-30 20:06:15,001-rank_id: 0
Training: 2025-11-30 20:07:29,687-rank_id: 0
Training: 2025-11-30 20:08:10,300-Total Step is: 394238
Training: 2025-11-30 20:08:10,300-Steps per epoch: 15163, eval every 4 epochs => eval_step=60652
Training: 2025-11-30 20:11:15,326-rank_id: 0
Training: 2025-11-30 20:11:19,826-Total Step is: 394238
Training: 2025-11-30 20:11:19,826-Steps per epoch: 15163, eval every 4 epochs => eval_step=60652
Training: 2025-11-30 20:15:43,446-rank_id: 0
Training: 2025-11-30 20:15:47,962-Total Step is: 394238
Training: 2025-11-30 20:15:47,962-Steps per epoch: 15163, eval every 4 epochs => eval_step=60652
Training: 2025-11-30 20:18:34,958-[IJB][IJBB_gt_aligned] {'Norm:True_Det:True_tpr_at_fpr_1e-06': 0.4868549172346641, 'Norm:True_Det:True_thresh_at_fpr_1e-06': 0.9889598366078083, 'Norm:True_Det:True_tpr_at_fpr_1e-05': 0.8860759493670887, 'Norm:True_Det:True_thresh_at_fpr_1e-05': 0.986447468413859, 'Norm:True_Det:True_tpr_at_fpr_0.0001': 1.8208373904576434, 'Norm:True_Det:True_thresh_at_fpr_0.0001': 0.9815472514989444, 'Norm:True_Det:True_tpr_at_fpr_0.001': 4.371957156767283, 'Norm:True_Det:True_thresh_at_fpr_0.001': 0.9745632804414803, 'Norm:True_Det:True_tpr_at_fpr_0.01': 12.239532619279455, 'Norm:True_Det:True_thresh_at_fpr_0.01': 0.9621445934841554, 'Norm:True_Det:True_tpr_at_fpr_0.1': 36.28042843232716, 'Norm:True_Det:True_thresh_at_fpr_0.1': 0.9322201617690422, 'Norm:True_Det:False_tpr_at_fpr_1e-06': 0.3894839337877313, 'Norm:True_Det:False_thresh_at_fpr_1e-06': 0.9894596824603032, 'Norm:True_Det:False_tpr_at_fpr_1e-05': 0.8179162609542356, 'Norm:True_Det:False_thresh_at_fpr_1e-05': 0.9865710982142826, 'Norm:True_Det:False_tpr_at_fpr_0.0001': 1.7429406037000974, 'Norm:True_Det:False_thresh_at_fpr_0.0001': 0.9816861142812441, 'Norm:True_Det:False_tpr_at_fpr_0.001': 4.177215189873418, 'Norm:True_Det:False_thresh_at_fpr_0.001': 0.9748905856021465, 'Norm:True_Det:False_tpr_at_fpr_0.01': 12.035053554040896, 'Norm:True_Det:False_thresh_at_fpr_0.01': 0.9624955959182642, 'Norm:True_Det:False_tpr_at_fpr_0.1': 36.075949367088604, 'Norm:True_Det:False_thresh_at_fpr_0.1': 0.9327003059791068, 'Norm:False_Det:True_tpr_at_fpr_1e-06': 0.5160662122687439, 'Norm:False_Det:True_thresh_at_fpr_1e-06': 0.9884315035031062, 'Norm:False_Det:True_tpr_at_fpr_1e-05': 0.9347614410905549, 'Norm:False_Det:True_thresh_at_fpr_1e-05': 0.9859381439889208, 'Norm:False_Det:True_tpr_at_fpr_0.0001': 1.8500486854917235, 'Norm:False_Det:True_thresh_at_fpr_0.0001': 0.9812045687604697, 'Norm:False_Det:True_tpr_at_fpr_0.001': 4.469328140214216, 'Norm:False_Det:True_thresh_at_fpr_0.001': 0.9742107226931458, 'Norm:False_Det:True_tpr_at_fpr_0.01': 12.590068159688414, 'Norm:False_Det:True_thresh_at_fpr_0.01': 0.9617897114884904, 'Norm:False_Det:True_tpr_at_fpr_0.1': 36.397273612463486, 'Norm:False_Det:True_thresh_at_fpr_0.1': 0.9322214020434256}
Training: 2025-11-30 20:22:35,147-[IJB][IJBC_gt_aligned] {'Norm:True_Det:True_tpr_at_fpr_1e-06': 0.28634248606637014, 'Norm:True_Det:True_thresh_at_fpr_1e-06': 0.9900421647353153, 'Norm:True_Det:True_tpr_at_fpr_1e-05': 0.6647236283683591, 'Norm:True_Det:True_thresh_at_fpr_1e-05': 0.9865337461386673, 'Norm:True_Det:True_tpr_at_fpr_0.0001': 1.5799969320447922, 'Norm:True_Det:True_thresh_at_fpr_0.0001': 0.9815292963773068, 'Norm:True_Det:True_tpr_at_fpr_0.001': 4.555913483663138, 'Norm:True_Det:True_thresh_at_fpr_0.001': 0.9741424118830662, 'Norm:True_Det:True_tpr_at_fpr_0.01': 13.069489185457892, 'Norm:True_Det:True_thresh_at_fpr_0.01': 0.9612026728374523, 'Norm:True_Det:True_tpr_at_fpr_0.1': 37.822774454159635, 'Norm:True_Det:True_thresh_at_fpr_0.1': 0.9315155637683177, 'Norm:True_Det:False_tpr_at_fpr_1e-06': 0.2505496753080738, 'Norm:True_Det:False_thresh_at_fpr_1e-06': 0.99020534276227, 'Norm:True_Det:False_tpr_at_fpr_1e-05': 0.628930817610063, 'Norm:True_Det:False_thresh_at_fpr_1e-05': 0.9868338479226071, 'Norm:True_Det:False_tpr_at_fpr_0.0001': 1.5135245692079562, 'Norm:True_Det:False_thresh_at_fpr_0.0001': 0.9818801252212634, 'Norm:True_Det:False_tpr_at_fpr_0.001': 4.397402464590684, 'Norm:True_Det:False_thresh_at_fpr_0.001': 0.9745426676324223, 'Norm:True_Det:False_tpr_at_fpr_0.01': 12.890525131666411, 'Norm:True_Det:False_thresh_at_fpr_0.01': 0.9616391042784298, 'Norm:True_Det:False_tpr_at_fpr_0.1': 37.57222477885156, 'Norm:True_Det:False_thresh_at_fpr_0.1': 0.9320398137544783, 'Norm:False_Det:True_tpr_at_fpr_1e-06': 0.2965690034258833, 'Norm:False_Det:True_thresh_at_fpr_1e-06': 0.9895001849725134, 'Norm:False_Det:True_tpr_at_fpr_1e-05': 0.7567622846039781, 'Norm:False_Det:True_thresh_at_fpr_1e-05': 0.9856863406778048, 'Norm:False_Det:True_tpr_at_fpr_0.0001': 1.6311295188423582, 'Norm:False_Det:True_thresh_at_fpr_0.0001': 0.9807920516353498, 'Norm:False_Det:True_tpr_at_fpr_0.001': 4.693971468016567, 'Norm:False_Det:True_thresh_at_fpr_0.001': 0.9734237309853356, 'Norm:False_Det:True_tpr_at_fpr_0.01': 13.596154829472823, 'Norm:False_Det:True_thresh_at_fpr_0.01': 0.9605753707570313, 'Norm:False_Det:True_tpr_at_fpr_0.1': 38.46193178912921, 'Norm:False_Det:True_thresh_at_fpr_0.1': 0.93131833585488}
Training: 2025-11-30 20:24:17,575-[TinyFace][tinyface_aligned_pad_0.1] {'rank-1': 14.833691716194153, 'rank-5': 19.635193049907684, 'rank-20': 24.40987080335617}
Training: 2025-11-30 20:24:33,840-Reducer buckets have been rebuilt in this iteration.
Training: 2025-11-30 20:24:34,117-Reducer buckets have been rebuilt in this iteration.
Training: 2025-11-30 20:25:07,715-Speed 1123.18 samples/sec   Loss 36.7585 target_logit_mean 0.0087 lma 0.2864  cos_theta_tmp 0.1411  Epoch: 0   Global Step: 100   Required: 556 hours
Training: 2025-11-30 20:25:24,865-Speed 1119.57 samples/sec   Loss 31.5484 target_logit_mean 0.0091 lma 0.3508  cos_theta_tmp 0.1884  Epoch: 0   Global Step: 150   Required: 384 hours
Training: 2025-11-30 20:25:42,042-Speed 1117.78 samples/sec   Loss 29.3565 target_logit_mean 0.0083 lma 0.3728  cos_theta_tmp 0.2318  Epoch: 0   Global Step: 200   Required: 298 hours
Training: 2025-11-30 20:25:59,242-Speed 1116.36 samples/sec   Loss 27.3684 target_logit_mean 0.0072 lma 0.4303  cos_theta_tmp 0.2649  Epoch: 0   Global Step: 250   Required: 246 hours
Training: 2025-11-30 20:26:16,581-Speed 1107.37 samples/sec   Loss 25.7888 target_logit_mean 0.0065 lma 0.4697  cos_theta_tmp 0.2874  Epoch: 0   Global Step: 300   Required: 211 hours
Training: 2025-11-30 20:26:33,978-Speed 1103.66 samples/sec   Loss 24.2866 target_logit_mean 0.0059 lma 0.5248  cos_theta_tmp 0.3183  Epoch: 0   Global Step: 350   Required: 187 hours
Training: 2025-11-30 20:26:51,203-Speed 1114.70 samples/sec   Loss 23.0317 target_logit_mean 0.0034 lma 0.5329  cos_theta_tmp 0.3432  Epoch: 0   Global Step: 400   Required: 168 hours
Training: 2025-11-30 20:27:08,673-Speed 1099.07 samples/sec   Loss 21.8075 target_logit_mean 0.0022 lma 0.5537  cos_theta_tmp 0.3631  Epoch: 0   Global Step: 450   Required: 154 hours
Training: 2025-11-30 20:27:26,115-Speed 1100.87 samples/sec   Loss 20.8785 target_logit_mean 0.0035 lma 0.5644  cos_theta_tmp 0.3919  Epoch: 0   Global Step: 500   Required: 142 hours
Training: 2025-11-30 20:27:43,341-Speed 1114.64 samples/sec   Loss 20.0265 target_logit_mean -0.0005 lma 0.5472  cos_theta_tmp 0.4017  Epoch: 0   Global Step: 550   Required: 133 hours
Training: 2025-11-30 20:28:00,680-Speed 1107.34 samples/sec   Loss 19.3451 target_logit_mean 0.0017 lma 0.5929  cos_theta_tmp 0.4098  Epoch: 0   Global Step: 600   Required: 125 hours
Training: 2025-11-30 20:28:18,222-Speed 1094.58 samples/sec   Loss 18.6191 target_logit_mean -0.0002 lma 0.5987  cos_theta_tmp 0.4275  Epoch: 0   Global Step: 650   Required: 118 hours
Training: 2025-11-30 20:28:35,522-Speed 1109.87 samples/sec   Loss 17.9408 target_logit_mean 0.0007 lma 0.6120  cos_theta_tmp 0.4416  Epoch: 0   Global Step: 700   Required: 112 hours
Training: 2025-11-30 20:28:53,167-Speed 1088.19 samples/sec   Loss 17.3674 target_logit_mean 0.0023 lma 0.6139  cos_theta_tmp 0.4489  Epoch: 0   Global Step: 750   Required: 107 hours
Training: 2025-11-30 20:29:10,440-Speed 1111.57 samples/sec   Loss 16.8794 target_logit_mean 0.0020 lma 0.5995  cos_theta_tmp 0.4559  Epoch: 0   Global Step: 800   Required: 103 hours
Training: 2025-11-30 20:29:27,753-Speed 1109.05 samples/sec   Loss 16.4212 target_logit_mean 0.0013 lma 0.6096  cos_theta_tmp 0.4723  Epoch: 0   Global Step: 850   Required: 99 hours
Training: 2025-11-30 20:29:45,232-Speed 1098.49 samples/sec   Loss 15.9075 target_logit_mean -0.0005 lma 0.6298  cos_theta_tmp 0.4784  Epoch: 0   Global Step: 900   Required: 96 hours
Training: 2025-11-30 20:30:02,458-Speed 1114.62 samples/sec   Loss 15.5064 target_logit_mean 0.0003 lma 0.6268  cos_theta_tmp 0.4909  Epoch: 0   Global Step: 950   Required: 93 hours
Training: 2025-11-30 20:30:19,940-Speed 1098.32 samples/sec   Loss 15.0725 target_logit_mean 0.0007 lma 0.6158  cos_theta_tmp 0.4899  Epoch: 0   Global Step: 1000   Required: 90 hours
Training: 2025-11-30 20:30:37,608-Speed 1086.75 samples/sec   Loss 14.7007 target_logit_mean 0.0011 lma 0.6304  cos_theta_tmp 0.5067  Epoch: 0   Global Step: 1050   Required: 88 hours
Training: 2025-11-30 20:30:55,262-Speed 1087.66 samples/sec   Loss 14.3494 target_logit_mean -0.0021 lma 0.6468  cos_theta_tmp 0.5148  Epoch: 0   Global Step: 1100   Required: 85 hours
Training: 2025-11-30 20:31:12,775-Speed 1096.36 samples/sec   Loss 14.0036 target_logit_mean -0.0014 lma 0.6352  cos_theta_tmp 0.5174  Epoch: 0   Global Step: 1150   Required: 83 hours
Training: 2025-11-30 20:31:30,169-Speed 1103.90 samples/sec   Loss 13.7128 target_logit_mean 0.0008 lma 0.6468  cos_theta_tmp 0.5200  Epoch: 0   Global Step: 1200   Required: 81 hours
Training: 2025-11-30 20:31:47,341-Speed 1118.11 samples/sec   Loss 13.4210 target_logit_mean -0.0019 lma 0.6325  cos_theta_tmp 0.5291  Epoch: 0   Global Step: 1250   Required: 80 hours
Training: 2025-11-30 20:32:04,594-Speed 1112.93 samples/sec   Loss 13.2055 target_logit_mean -0.0001 lma 0.6296  cos_theta_tmp 0.5241  Epoch: 0   Global Step: 1300   Required: 78 hours
Training: 2025-11-30 20:32:22,037-Speed 1100.74 samples/sec   Loss 12.7911 target_logit_mean 0.0002 lma 0.6320  cos_theta_tmp 0.5528  Epoch: 0   Global Step: 1350   Required: 77 hours
Training: 2025-11-30 20:32:39,363-Speed 1108.20 samples/sec   Loss 12.5286 target_logit_mean -0.0007 lma 0.6415  cos_theta_tmp 0.5422  Epoch: 0   Global Step: 1400   Required: 75 hours
Training: 2025-11-30 20:32:56,601-Speed 1113.85 samples/sec   Loss 12.2761 target_logit_mean -0.0017 lma 0.6590  cos_theta_tmp 0.5504  Epoch: 0   Global Step: 1450   Required: 74 hours
Training: 2025-11-30 20:33:13,825-Speed 1114.79 samples/sec   Loss 11.9820 target_logit_mean 0.0023 lma 0.6448  cos_theta_tmp 0.5513  Epoch: 0   Global Step: 1500   Required: 73 hours
Training: 2025-11-30 20:33:31,441-Speed 1089.94 samples/sec   Loss 11.7790 target_logit_mean 0.0004 lma 0.6595  cos_theta_tmp 0.5571  Epoch: 0   Global Step: 1550   Required: 71 hours
Training: 2025-11-30 20:33:48,783-Speed 1107.20 samples/sec   Loss 11.6130 target_logit_mean -0.0016 lma 0.6301  cos_theta_tmp 0.5592  Epoch: 0   Global Step: 1600   Required: 70 hours
Training: 2025-11-30 20:34:06,131-Speed 1106.80 samples/sec   Loss 11.3032 target_logit_mean -0.0000 lma 0.6610  cos_theta_tmp 0.5642  Epoch: 0   Global Step: 1650   Required: 69 hours
Training: 2025-11-30 20:34:23,809-Speed 1086.09 samples/sec   Loss 11.1070 target_logit_mean -0.0000 lma 0.6445  cos_theta_tmp 0.5708  Epoch: 0   Global Step: 1700   Required: 69 hours
Training: 2025-11-30 20:34:41,544-Speed 1082.64 samples/sec   Loss 10.9005 target_logit_mean 0.0021 lma 0.6480  cos_theta_tmp 0.5838  Epoch: 0   Global Step: 1750   Required: 68 hours
Training: 2025-11-30 20:34:58,999-Speed 1100.04 samples/sec   Loss 10.7100 target_logit_mean -0.0007 lma 0.6457  cos_theta_tmp 0.5739  Epoch: 0   Global Step: 1800   Required: 67 hours
Training: 2025-11-30 20:35:16,455-Speed 1099.97 samples/sec   Loss 10.3978 target_logit_mean -0.0028 lma 0.6391  cos_theta_tmp 0.5759  Epoch: 0   Global Step: 1850   Required: 66 hours
Training: 2025-11-30 20:35:33,628-Speed 1118.05 samples/sec   Loss 10.3106 target_logit_mean -0.0014 lma 0.6488  cos_theta_tmp 0.5837  Epoch: 0   Global Step: 1900   Required: 65 hours
Training: 2025-11-30 20:35:50,800-Speed 1118.13 samples/sec   Loss 10.0829 target_logit_mean 0.0013 lma 0.6589  cos_theta_tmp 0.5940  Epoch: 0   Global Step: 1950   Required: 65 hours
Training: 2025-11-30 20:36:07,972-Speed 1118.13 samples/sec   Loss 9.8629 target_logit_mean -0.0011 lma 0.6703  cos_theta_tmp 0.5951  Epoch: 0   Global Step: 2000   Required: 64 hours
Training: 2025-11-30 20:36:25,144-Speed 1118.14 samples/sec   Loss 9.5917 target_logit_mean -0.0004 lma 0.6520  cos_theta_tmp 0.5929  Epoch: 0   Global Step: 2050   Required: 63 hours
Training: 2025-11-30 20:36:42,316-Speed 1118.15 samples/sec   Loss 9.5100 target_logit_mean 0.0007 lma 0.6639  cos_theta_tmp 0.6037  Epoch: 0   Global Step: 2100   Required: 63 hours
Training: 2025-11-30 20:36:59,487-Speed 1118.20 samples/sec   Loss 9.3439 target_logit_mean -0.0004 lma 0.6605  cos_theta_tmp 0.6010  Epoch: 0   Global Step: 2150   Required: 62 hours
Training: 2025-11-30 20:37:16,661-Speed 1118.00 samples/sec   Loss 9.1926 target_logit_mean 0.0001 lma 0.6593  cos_theta_tmp 0.6085  Epoch: 0   Global Step: 2200   Required: 61 hours
Training: 2025-11-30 20:37:33,834-Speed 1118.08 samples/sec   Loss 9.0109 target_logit_mean 0.0009 lma 0.6581  cos_theta_tmp 0.6101  Epoch: 0   Global Step: 2250   Required: 61 hours
Training: 2025-11-30 20:37:51,011-Speed 1117.81 samples/sec   Loss 8.8048 target_logit_mean -0.0025 lma 0.6561  cos_theta_tmp 0.6138  Epoch: 0   Global Step: 2300   Required: 60 hours
Training: 2025-11-30 20:38:08,184-Speed 1118.05 samples/sec   Loss 8.7756 target_logit_mean -0.0005 lma 0.6753  cos_theta_tmp 0.6123  Epoch: 0   Global Step: 2350   Required: 60 hours
Training: 2025-11-30 20:38:25,355-Speed 1118.23 samples/sec   Loss 8.5938 target_logit_mean -0.0007 lma 0.6470  cos_theta_tmp 0.6168  Epoch: 0   Global Step: 2400   Required: 59 hours
Training: 2025-11-30 20:38:42,564-Speed 1115.68 samples/sec   Loss 8.4089 target_logit_mean 0.0006 lma 0.6730  cos_theta_tmp 0.6236  Epoch: 0   Global Step: 2450   Required: 59 hours
Training: 2025-11-30 20:39:00,010-Speed 1100.61 samples/sec   Loss 8.3954 target_logit_mean -0.0001 lma 0.6589  cos_theta_tmp 0.6187  Epoch: 0   Global Step: 2500   Required: 59 hours
Training: 2025-11-30 20:39:17,349-Speed 1107.33 samples/sec   Loss 8.1782 target_logit_mean -0.0003 lma 0.6604  cos_theta_tmp 0.6299  Epoch: 0   Global Step: 2550   Required: 58 hours
Training: 2025-11-30 20:39:34,521-Speed 1118.16 samples/sec   Loss 8.1216 target_logit_mean -0.0013 lma 0.6524  cos_theta_tmp 0.6249  Epoch: 0   Global Step: 2600   Required: 58 hours
Training: 2025-11-30 20:39:51,692-Speed 1118.20 samples/sec   Loss 8.0345 target_logit_mean 0.0028 lma 0.6653  cos_theta_tmp 0.6319  Epoch: 0   Global Step: 2650   Required: 57 hours
Training: 2025-11-30 20:40:08,863-Speed 1118.14 samples/sec   Loss 7.8820 target_logit_mean -0.0034 lma 0.6626  cos_theta_tmp 0.6281  Epoch: 0   Global Step: 2700   Required: 57 hours
Training: 2025-11-30 20:40:26,036-Speed 1118.09 samples/sec   Loss 7.8618 target_logit_mean 0.0036 lma 0.6716  cos_theta_tmp 0.6415  Epoch: 0   Global Step: 2750   Required: 57 hours
Training: 2025-11-30 20:40:43,211-Speed 1117.97 samples/sec   Loss 7.6870 target_logit_mean 0.0005 lma 0.6671  cos_theta_tmp 0.6313  Epoch: 0   Global Step: 2800   Required: 56 hours
Training: 2025-11-30 20:41:00,385-Speed 1117.95 samples/sec   Loss 7.5962 target_logit_mean 0.0001 lma 0.6741  cos_theta_tmp 0.6361  Epoch: 0   Global Step: 2850   Required: 56 hours
Training: 2025-11-30 20:41:17,558-Speed 1118.12 samples/sec   Loss 7.4568 target_logit_mean -0.0015 lma 0.6648  cos_theta_tmp 0.6493  Epoch: 0   Global Step: 2900   Required: 56 hours
Training: 2025-11-30 20:41:34,729-Speed 1118.19 samples/sec   Loss 7.4125 target_logit_mean 0.0009 lma 0.6511  cos_theta_tmp 0.6476  Epoch: 0   Global Step: 2950   Required: 55 hours
Training: 2025-11-30 20:41:51,908-Speed 1117.67 samples/sec   Loss 7.3079 target_logit_mean 0.0006 lma 0.6693  cos_theta_tmp 0.6478  Epoch: 0   Global Step: 3000   Required: 55 hours
Training: 2025-11-30 20:42:09,083-Speed 1117.93 samples/sec   Loss 7.1401 target_logit_mean 0.0020 lma 0.6608  cos_theta_tmp 0.6444  Epoch: 0   Global Step: 3050   Required: 55 hours
Training: 2025-11-30 20:42:26,255-Speed 1118.12 samples/sec   Loss 7.1744 target_logit_mean 0.0012 lma 0.6756  cos_theta_tmp 0.6465  Epoch: 0   Global Step: 3100   Required: 54 hours
Training: 2025-11-30 20:42:43,428-Speed 1118.12 samples/sec   Loss 6.9941 target_logit_mean 0.0008 lma 0.6811  cos_theta_tmp 0.6519  Epoch: 0   Global Step: 3150   Required: 54 hours
Training: 2025-11-30 20:43:00,602-Speed 1118.00 samples/sec   Loss 6.9457 target_logit_mean -0.0009 lma 0.6722  cos_theta_tmp 0.6520  Epoch: 0   Global Step: 3200   Required: 54 hours
Training: 2025-11-30 20:43:17,774-Speed 1118.11 samples/sec   Loss 6.8402 target_logit_mean -0.0000 lma 0.6625  cos_theta_tmp 0.6494  Epoch: 0   Global Step: 3250   Required: 54 hours
Training: 2025-11-30 20:43:34,945-Speed 1118.19 samples/sec   Loss 6.8348 target_logit_mean 0.0009 lma 0.6710  cos_theta_tmp 0.6562  Epoch: 0   Global Step: 3300   Required: 53 hours
Training: 2025-11-30 20:43:52,118-Speed 1118.08 samples/sec   Loss 6.7115 target_logit_mean 0.0007 lma 0.6603  cos_theta_tmp 0.6583  Epoch: 0   Global Step: 3350   Required: 53 hours
Training: 2025-11-30 20:44:09,292-Speed 1118.02 samples/sec   Loss 6.5921 target_logit_mean -0.0005 lma 0.6746  cos_theta_tmp 0.6531  Epoch: 0   Global Step: 3400   Required: 53 hours
Training: 2025-11-30 20:44:26,465-Speed 1118.09 samples/sec   Loss 6.5719 target_logit_mean 0.0017 lma 0.6668  cos_theta_tmp 0.6598  Epoch: 0   Global Step: 3450   Required: 53 hours
Training: 2025-11-30 20:44:43,674-Speed 1115.73 samples/sec   Loss 6.5574 target_logit_mean 0.0008 lma 0.6798  cos_theta_tmp 0.6677  Epoch: 0   Global Step: 3500   Required: 52 hours
Training: 2025-11-30 20:45:00,845-Speed 1118.14 samples/sec   Loss 6.3802 target_logit_mean 0.0008 lma 0.6775  cos_theta_tmp 0.6692  Epoch: 0   Global Step: 3550   Required: 52 hours
Training: 2025-11-30 20:45:18,021-Speed 1117.93 samples/sec   Loss 6.3249 target_logit_mean 0.0007 lma 0.6625  cos_theta_tmp 0.6637  Epoch: 0   Global Step: 3600   Required: 52 hours
Training: 2025-11-30 20:45:35,195-Speed 1118.02 samples/sec   Loss 6.3686 target_logit_mean -0.0029 lma 0.6664  cos_theta_tmp 0.6621  Epoch: 0   Global Step: 3650   Required: 52 hours
Training: 2025-11-30 20:45:52,366-Speed 1118.18 samples/sec   Loss 6.2621 target_logit_mean 0.0002 lma 0.6810  cos_theta_tmp 0.6580  Epoch: 0   Global Step: 3700   Required: 52 hours
Training: 2025-11-30 20:46:09,539-Speed 1118.03 samples/sec   Loss 6.2280 target_logit_mean 0.0009 lma 0.6610  cos_theta_tmp 0.6740  Epoch: 0   Global Step: 3750   Required: 51 hours
Training: 2025-11-30 20:46:26,711-Speed 1118.15 samples/sec   Loss 6.0843 target_logit_mean 0.0043 lma 0.6700  cos_theta_tmp 0.6774  Epoch: 0   Global Step: 3800   Required: 51 hours
Training: 2025-11-30 20:46:43,883-Speed 1118.16 samples/sec   Loss 6.0653 target_logit_mean 0.0007 lma 0.6696  cos_theta_tmp 0.6733  Epoch: 0   Global Step: 3850   Required: 51 hours
Training: 2025-11-30 20:47:01,059-Speed 1117.88 samples/sec   Loss 6.0482 target_logit_mean -0.0012 lma 0.6596  cos_theta_tmp 0.6799  Epoch: 0   Global Step: 3900   Required: 51 hours
Training: 2025-11-30 20:47:18,439-Speed 1104.75 samples/sec   Loss 6.0446 target_logit_mean -0.0010 lma 0.6626  cos_theta_tmp 0.6717  Epoch: 0   Global Step: 3950   Required: 51 hours
Training: 2025-11-30 20:47:35,982-Speed 1094.49 samples/sec   Loss 5.9647 target_logit_mean 0.0020 lma 0.6789  cos_theta_tmp 0.6746  Epoch: 0   Global Step: 4000   Required: 50 hours
Training: 2025-11-30 20:47:53,400-Speed 1102.37 samples/sec   Loss 5.9025 target_logit_mean 0.0015 lma 0.6762  cos_theta_tmp 0.6825  Epoch: 0   Global Step: 4050   Required: 50 hours
Training: 2025-11-30 20:48:10,564-Speed 1118.67 samples/sec   Loss 5.8627 target_logit_mean -0.0005 lma 0.6645  cos_theta_tmp 0.6668  Epoch: 0   Global Step: 4100   Required: 50 hours
Training: 2025-11-30 20:48:27,743-Speed 1117.66 samples/sec   Loss 5.8110 target_logit_mean 0.0001 lma 0.6748  cos_theta_tmp 0.6748  Epoch: 0   Global Step: 4150   Required: 50 hours
Training: 2025-11-30 20:48:44,905-Speed 1118.83 samples/sec   Loss 5.7287 target_logit_mean -0.0021 lma 0.6782  cos_theta_tmp 0.6800  Epoch: 0   Global Step: 4200   Required: 50 hours
Training: 2025-11-30 20:49:02,088-Speed 1117.41 samples/sec   Loss 5.7126 target_logit_mean 0.0005 lma 0.6657  cos_theta_tmp 0.6836  Epoch: 0   Global Step: 4250   Required: 50 hours
Training: 2025-11-30 20:49:19,267-Speed 1117.68 samples/sec   Loss 5.8104 target_logit_mean -0.0023 lma 0.6749  cos_theta_tmp 0.6759  Epoch: 0   Global Step: 4300   Required: 49 hours
Training: 2025-11-30 20:49:36,431-Speed 1118.67 samples/sec   Loss 5.6868 target_logit_mean 0.0015 lma 0.6731  cos_theta_tmp 0.6844  Epoch: 0   Global Step: 4350   Required: 49 hours
Training: 2025-11-30 20:49:53,610-Speed 1117.65 samples/sec   Loss 5.6582 target_logit_mean -0.0006 lma 0.6758  cos_theta_tmp 0.6776  Epoch: 0   Global Step: 4400   Required: 49 hours
Training: 2025-11-30 20:50:10,775-Speed 1118.60 samples/sec   Loss 5.6003 target_logit_mean -0.0023 lma 0.6686  cos_theta_tmp 0.6711  Epoch: 0   Global Step: 4450   Required: 49 hours
Training: 2025-11-30 20:50:27,955-Speed 1117.62 samples/sec   Loss 5.6195 target_logit_mean -0.0003 lma 0.6702  cos_theta_tmp 0.6751  Epoch: 0   Global Step: 4500   Required: 49 hours
Training: 2025-11-30 20:50:45,117-Speed 1118.77 samples/sec   Loss 5.5554 target_logit_mean 0.0008 lma 0.6764  cos_theta_tmp 0.6803  Epoch: 0   Global Step: 4550   Required: 49 hours
Training: 2025-11-30 20:51:02,302-Speed 1117.31 samples/sec   Loss 5.5122 target_logit_mean 0.0032 lma 0.6771  cos_theta_tmp 0.6888  Epoch: 0   Global Step: 4600   Required: 49 hours
Training: 2025-11-30 20:51:19,482-Speed 1117.57 samples/sec   Loss 5.4206 target_logit_mean 0.0010 lma 0.6689  cos_theta_tmp 0.6772  Epoch: 0   Global Step: 4650   Required: 49 hours
Training: 2025-11-30 20:51:36,643-Speed 1118.86 samples/sec   Loss 5.4713 target_logit_mean 0.0011 lma 0.6868  cos_theta_tmp 0.6904  Epoch: 0   Global Step: 4700   Required: 48 hours
Training: 2025-11-30 20:51:53,824-Speed 1117.56 samples/sec   Loss 5.4697 target_logit_mean -0.0014 lma 0.6676  cos_theta_tmp 0.6835  Epoch: 0   Global Step: 4750   Required: 48 hours
Training: 2025-11-30 20:52:10,986-Speed 1118.73 samples/sec   Loss 5.4983 target_logit_mean 0.0016 lma 0.6838  cos_theta_tmp 0.6893  Epoch: 0   Global Step: 4800   Required: 48 hours
Training: 2025-11-30 20:52:28,164-Speed 1117.77 samples/sec   Loss 5.3988 target_logit_mean -0.0023 lma 0.6641  cos_theta_tmp 0.6850  Epoch: 0   Global Step: 4850   Required: 48 hours
Training: 2025-11-30 20:52:45,327-Speed 1118.72 samples/sec   Loss 5.3409 target_logit_mean 0.0019 lma 0.6711  cos_theta_tmp 0.6933  Epoch: 0   Global Step: 4900   Required: 48 hours
Training: 2025-11-30 20:53:02,524-Speed 1116.52 samples/sec   Loss 5.3600 target_logit_mean 0.0020 lma 0.6695  cos_theta_tmp 0.6898  Epoch: 0   Global Step: 4950   Required: 48 hours
Training: 2025-11-30 20:53:19,704-Speed 1117.62 samples/sec   Loss 5.3384 target_logit_mean 0.0004 lma 0.6747  cos_theta_tmp 0.6838  Epoch: 0   Global Step: 5000   Required: 48 hours
Training: 2025-11-30 20:53:36,869-Speed 1118.59 samples/sec   Loss 5.1637 target_logit_mean 0.0019 lma 0.6733  cos_theta_tmp 0.6921  Epoch: 0   Global Step: 5050   Required: 48 hours
Training: 2025-11-30 20:53:54,050-Speed 1117.54 samples/sec   Loss 5.1146 target_logit_mean 0.0007 lma 0.6796  cos_theta_tmp 0.6885  Epoch: 0   Global Step: 5100   Required: 47 hours
Training: 2025-11-30 20:54:11,216-Speed 1118.50 samples/sec   Loss 5.2420 target_logit_mean 0.0005 lma 0.6722  cos_theta_tmp 0.6955  Epoch: 0   Global Step: 5150   Required: 47 hours
Training: 2025-11-30 20:54:28,396-Speed 1117.64 samples/sec   Loss 5.1867 target_logit_mean 0.0001 lma 0.6677  cos_theta_tmp 0.6872  Epoch: 0   Global Step: 5200   Required: 47 hours
Training: 2025-11-30 20:54:45,574-Speed 1117.71 samples/sec   Loss 5.1302 target_logit_mean 0.0005 lma 0.6746  cos_theta_tmp 0.6990  Epoch: 0   Global Step: 5250   Required: 47 hours
Training: 2025-11-30 20:55:02,766-Speed 1116.85 samples/sec   Loss 5.2030 target_logit_mean -0.0030 lma 0.6648  cos_theta_tmp 0.6898  Epoch: 0   Global Step: 5300   Required: 47 hours
Training: 2025-11-30 20:55:19,949-Speed 1117.44 samples/sec   Loss 5.1086 target_logit_mean 0.0017 lma 0.6855  cos_theta_tmp 0.6978  Epoch: 0   Global Step: 5350   Required: 47 hours
Training: 2025-11-30 20:55:37,112-Speed 1118.72 samples/sec   Loss 5.0950 target_logit_mean -0.0021 lma 0.6827  cos_theta_tmp 0.6979  Epoch: 0   Global Step: 5400   Required: 47 hours
Training: 2025-11-30 20:55:54,293-Speed 1117.56 samples/sec   Loss 5.0651 target_logit_mean 0.0009 lma 0.6729  cos_theta_tmp 0.6867  Epoch: 0   Global Step: 5450   Required: 47 hours
Training: 2025-11-30 20:56:11,459-Speed 1118.53 samples/sec   Loss 5.0493 target_logit_mean -0.0003 lma 0.6725  cos_theta_tmp 0.6949  Epoch: 0   Global Step: 5500   Required: 47 hours
Training: 2025-11-30 20:56:28,637-Speed 1117.68 samples/sec   Loss 5.1841 target_logit_mean 0.0001 lma 0.6708  cos_theta_tmp 0.6890  Epoch: 0   Global Step: 5550   Required: 47 hours
Training: 2025-11-30 20:56:45,801-Speed 1118.68 samples/sec   Loss 5.0604 target_logit_mean 0.0005 lma 0.6752  cos_theta_tmp 0.6983  Epoch: 0   Global Step: 5600   Required: 46 hours
Training: 2025-11-30 20:57:02,982-Speed 1117.56 samples/sec   Loss 4.9905 target_logit_mean 0.0016 lma 0.6922  cos_theta_tmp 0.7053  Epoch: 0   Global Step: 5650   Required: 46 hours
Training: 2025-11-30 20:57:20,163-Speed 1117.56 samples/sec   Loss 4.9037 target_logit_mean -0.0002 lma 0.6737  cos_theta_tmp 0.6945  Epoch: 0   Global Step: 5700   Required: 46 hours
Training: 2025-11-30 20:57:37,326-Speed 1118.69 samples/sec   Loss 4.9777 target_logit_mean -0.0006 lma 0.6830  cos_theta_tmp 0.7040  Epoch: 0   Global Step: 5750   Required: 46 hours
Training: 2025-11-30 20:57:54,507-Speed 1117.55 samples/sec   Loss 4.9311 target_logit_mean -0.0015 lma 0.6678  cos_theta_tmp 0.6900  Epoch: 0   Global Step: 5800   Required: 46 hours
Training: 2025-11-30 20:58:11,671-Speed 1118.69 samples/sec   Loss 4.9322 target_logit_mean 0.0006 lma 0.6729  cos_theta_tmp 0.6980  Epoch: 0   Global Step: 5850   Required: 46 hours
Training: 2025-11-30 20:58:28,850-Speed 1117.64 samples/sec   Loss 4.9052 target_logit_mean -0.0004 lma 0.6693  cos_theta_tmp 0.6984  Epoch: 0   Global Step: 5900   Required: 46 hours
Training: 2025-11-30 20:58:46,011-Speed 1118.85 samples/sec   Loss 4.8102 target_logit_mean 0.0015 lma 0.6777  cos_theta_tmp 0.6948  Epoch: 0   Global Step: 5950   Required: 46 hours
Training: 2025-11-30 20:59:03,195-Speed 1117.34 samples/sec   Loss 4.8185 target_logit_mean 0.0005 lma 0.6700  cos_theta_tmp 0.7071  Epoch: 0   Global Step: 6000   Required: 46 hours
Training: 2025-11-30 20:59:20,378-Speed 1117.43 samples/sec   Loss 4.9074 target_logit_mean 0.0028 lma 0.6597  cos_theta_tmp 0.7023  Epoch: 0   Global Step: 6050   Required: 46 hours
Training: 2025-11-30 20:59:37,541-Speed 1118.74 samples/sec   Loss 4.8594 target_logit_mean -0.0000 lma 0.6726  cos_theta_tmp 0.7000  Epoch: 0   Global Step: 6100   Required: 46 hours
Training: 2025-11-30 20:59:54,720-Speed 1117.66 samples/sec   Loss 4.8218 target_logit_mean 0.0000 lma 0.6773  cos_theta_tmp 0.7025  Epoch: 0   Global Step: 6150   Required: 46 hours
Training: 2025-11-30 21:00:11,882-Speed 1118.76 samples/sec   Loss 4.7765 target_logit_mean -0.0030 lma 0.6873  cos_theta_tmp 0.7014  Epoch: 0   Global Step: 6200   Required: 45 hours
Training: 2025-11-30 21:00:29,064-Speed 1117.53 samples/sec   Loss 4.7792 target_logit_mean 0.0010 lma 0.6680  cos_theta_tmp 0.7020  Epoch: 0   Global Step: 6250   Required: 45 hours
Training: 2025-11-30 21:00:46,226-Speed 1118.74 samples/sec   Loss 4.7616 target_logit_mean 0.0011 lma 0.6676  cos_theta_tmp 0.7008  Epoch: 0   Global Step: 6300   Required: 45 hours
Training: 2025-11-30 21:01:03,410-Speed 1117.38 samples/sec   Loss 4.7499 target_logit_mean 0.0012 lma 0.6749  cos_theta_tmp 0.6998  Epoch: 0   Global Step: 6350   Required: 45 hours
Training: 2025-11-30 21:01:20,591-Speed 1117.54 samples/sec   Loss 4.7062 target_logit_mean 0.0022 lma 0.6727  cos_theta_tmp 0.7014  Epoch: 0   Global Step: 6400   Required: 45 hours
Training: 2025-11-30 21:01:37,756-Speed 1118.60 samples/sec   Loss 4.6826 target_logit_mean 0.0010 lma 0.6707  cos_theta_tmp 0.7085  Epoch: 0   Global Step: 6450   Required: 45 hours
Training: 2025-11-30 21:01:54,937-Speed 1117.51 samples/sec   Loss 4.6642 target_logit_mean -0.0011 lma 0.6641  cos_theta_tmp 0.7019  Epoch: 0   Global Step: 6500   Required: 45 hours
Training: 2025-11-30 21:02:12,101-Speed 1118.65 samples/sec   Loss 4.6897 target_logit_mean -0.0025 lma 0.6765  cos_theta_tmp 0.7059  Epoch: 0   Global Step: 6550   Required: 45 hours
Training: 2025-11-30 21:02:29,284-Speed 1117.48 samples/sec   Loss 4.5517 target_logit_mean 0.0009 lma 0.6742  cos_theta_tmp 0.7088  Epoch: 0   Global Step: 6600   Required: 45 hours
Training: 2025-11-30 21:02:46,447-Speed 1118.67 samples/sec   Loss 4.5946 target_logit_mean 0.0016 lma 0.6810  cos_theta_tmp 0.7036  Epoch: 0   Global Step: 6650   Required: 45 hours
Training: 2025-11-30 21:03:03,630-Speed 1117.43 samples/sec   Loss 4.6465 target_logit_mean 0.0024 lma 0.6805  cos_theta_tmp 0.6987  Epoch: 0   Global Step: 6700   Required: 45 hours
Training: 2025-11-30 21:03:20,810-Speed 1117.59 samples/sec   Loss 4.5834 target_logit_mean -0.0014 lma 0.6784  cos_theta_tmp 0.7057  Epoch: 0   Global Step: 6750   Required: 45 hours
Training: 2025-11-30 21:03:37,974-Speed 1118.66 samples/sec   Loss 4.5781 target_logit_mean 0.0005 lma 0.6728  cos_theta_tmp 0.7001  Epoch: 0   Global Step: 6800   Required: 45 hours
Training: 2025-11-30 21:03:55,182-Speed 1117.56 samples/sec   Loss 4.5025 target_logit_mean 0.0011 lma 0.6815  cos_theta_tmp 0.7110  Epoch: 0   Global Step: 6850   Required: 45 hours
Training: 2025-11-30 21:04:12,347-Speed 1118.58 samples/sec   Loss 4.5167 target_logit_mean -0.0005 lma 0.6789  cos_theta_tmp 0.7066  Epoch: 0   Global Step: 6900   Required: 45 hours
Training: 2025-11-30 21:04:29,526-Speed 1117.63 samples/sec   Loss 4.4418 target_logit_mean -0.0005 lma 0.6680  cos_theta_tmp 0.7013  Epoch: 0   Global Step: 6950   Required: 44 hours
Training: 2025-11-30 21:04:46,689-Speed 1118.76 samples/sec   Loss 4.5230 target_logit_mean -0.0024 lma 0.6847  cos_theta_tmp 0.7113  Epoch: 0   Global Step: 7000   Required: 44 hours
Training: 2025-11-30 21:05:03,869-Speed 1117.58 samples/sec   Loss 4.5203 target_logit_mean -0.0002 lma 0.6755  cos_theta_tmp 0.7068  Epoch: 0   Global Step: 7050   Required: 44 hours
Training: 2025-11-30 21:05:21,050-Speed 1117.55 samples/sec   Loss 4.4516 target_logit_mean -0.0019 lma 0.6744  cos_theta_tmp 0.7122  Epoch: 0   Global Step: 7100   Required: 44 hours
Training: 2025-11-30 21:05:38,214-Speed 1118.64 samples/sec   Loss 4.4261 target_logit_mean 0.0029 lma 0.6756  cos_theta_tmp 0.7101  Epoch: 0   Global Step: 7150   Required: 44 hours
Training: 2025-11-30 21:05:55,397-Speed 1117.45 samples/sec   Loss 4.5070 target_logit_mean -0.0012 lma 0.6811  cos_theta_tmp 0.7097  Epoch: 0   Global Step: 7200   Required: 44 hours
Training: 2025-11-30 21:06:12,564-Speed 1118.45 samples/sec   Loss 4.4233 target_logit_mean 0.0014 lma 0.6657  cos_theta_tmp 0.7068  Epoch: 0   Global Step: 7250   Required: 44 hours
Training: 2025-11-30 21:06:29,746-Speed 1117.51 samples/sec   Loss 4.3579 target_logit_mean -0.0022 lma 0.6797  cos_theta_tmp 0.7050  Epoch: 0   Global Step: 7300   Required: 44 hours
Training: 2025-11-30 21:06:46,909-Speed 1118.67 samples/sec   Loss 4.3828 target_logit_mean 0.0034 lma 0.6744  cos_theta_tmp 0.7134  Epoch: 0   Global Step: 7350   Required: 44 hours
Training: 2025-11-30 21:07:04,095-Speed 1117.26 samples/sec   Loss 4.4388 target_logit_mean 0.0017 lma 0.6642  cos_theta_tmp 0.7067  Epoch: 0   Global Step: 7400   Required: 44 hours
Training: 2025-11-30 21:07:21,274-Speed 1117.66 samples/sec   Loss 4.4150 target_logit_mean 0.0008 lma 0.6714  cos_theta_tmp 0.7139  Epoch: 0   Global Step: 7450   Required: 44 hours
Training: 2025-11-30 21:07:38,438-Speed 1118.65 samples/sec   Loss 4.3340 target_logit_mean 0.0008 lma 0.6723  cos_theta_tmp 0.7089  Epoch: 0   Global Step: 7500   Required: 44 hours
Training: 2025-11-30 21:07:55,618-Speed 1117.60 samples/sec   Loss 4.3667 target_logit_mean 0.0013 lma 0.6740  cos_theta_tmp 0.7090  Epoch: 0   Global Step: 7550   Required: 44 hours
Training: 2025-11-30 21:08:12,786-Speed 1118.41 samples/sec   Loss 4.3559 target_logit_mean -0.0008 lma 0.6867  cos_theta_tmp 0.7121  Epoch: 0   Global Step: 7600   Required: 44 hours
Training: 2025-11-30 21:08:29,969-Speed 1117.43 samples/sec   Loss 4.3121 target_logit_mean 0.0007 lma 0.6777  cos_theta_tmp 0.7095  Epoch: 0   Global Step: 7650   Required: 44 hours
Training: 2025-11-30 21:08:47,132-Speed 1118.70 samples/sec   Loss 4.2253 target_logit_mean -0.0026 lma 0.6762  cos_theta_tmp 0.7032  Epoch: 0   Global Step: 7700   Required: 44 hours
Training: 2025-11-30 21:09:04,315-Speed 1117.42 samples/sec   Loss 4.3172 target_logit_mean 0.0017 lma 0.6811  cos_theta_tmp 0.7133  Epoch: 0   Global Step: 7750   Required: 44 hours
Training: 2025-11-30 21:09:21,495-Speed 1117.63 samples/sec   Loss 4.2164 target_logit_mean -0.0004 lma 0.6790  cos_theta_tmp 0.7093  Epoch: 0   Global Step: 7800   Required: 44 hours
Training: 2025-11-30 21:09:38,658-Speed 1118.67 samples/sec   Loss 4.2791 target_logit_mean 0.0015 lma 0.6746  cos_theta_tmp 0.7151  Epoch: 0   Global Step: 7850   Required: 44 hours
Training: 2025-11-30 21:09:55,839-Speed 1117.54 samples/sec   Loss 4.2365 target_logit_mean 0.0013 lma 0.6694  cos_theta_tmp 0.7054  Epoch: 0   Global Step: 7900   Required: 43 hours
Training: 2025-11-30 21:10:13,005-Speed 1118.52 samples/sec   Loss 4.2763 target_logit_mean -0.0024 lma 0.6800  cos_theta_tmp 0.7144  Epoch: 0   Global Step: 7950   Required: 43 hours
Training: 2025-11-30 21:10:30,187-Speed 1117.49 samples/sec   Loss 4.2253 target_logit_mean -0.0007 lma 0.6861  cos_theta_tmp 0.7154  Epoch: 0   Global Step: 8000   Required: 43 hours
Training: 2025-11-30 21:10:47,355-Speed 1118.45 samples/sec   Loss 4.2426 target_logit_mean 0.0007 lma 0.6745  cos_theta_tmp 0.7091  Epoch: 0   Global Step: 8050   Required: 43 hours
Training: 2025-11-30 21:11:04,538-Speed 1117.44 samples/sec   Loss 4.2051 target_logit_mean 0.0004 lma 0.6685  cos_theta_tmp 0.7159  Epoch: 0   Global Step: 8100   Required: 43 hours
Training: 2025-11-30 21:11:21,718-Speed 1117.58 samples/sec   Loss 4.2287 target_logit_mean -0.0000 lma 0.6857  cos_theta_tmp 0.7202  Epoch: 0   Global Step: 8150   Required: 43 hours
Training: 2025-11-30 21:11:38,883-Speed 1118.59 samples/sec   Loss 4.2021 target_logit_mean -0.0014 lma 0.6828  cos_theta_tmp 0.7173  Epoch: 0   Global Step: 8200   Required: 43 hours
Training: 2025-11-30 21:11:56,070-Speed 1117.17 samples/sec   Loss 4.0912 target_logit_mean 0.0011 lma 0.6741  cos_theta_tmp 0.7140  Epoch: 0   Global Step: 8250   Required: 43 hours
Training: 2025-11-30 21:12:13,236-Speed 1118.54 samples/sec   Loss 4.1335 target_logit_mean 0.0007 lma 0.6796  cos_theta_tmp 0.7124  Epoch: 0   Global Step: 8300   Required: 43 hours
Training: 2025-11-30 21:12:30,416-Speed 1117.63 samples/sec   Loss 4.1845 target_logit_mean 0.0034 lma 0.6822  cos_theta_tmp 0.7209  Epoch: 0   Global Step: 8350   Required: 43 hours
Training: 2025-11-30 21:12:47,595-Speed 1117.67 samples/sec   Loss 4.1500 target_logit_mean 0.0015 lma 0.6856  cos_theta_tmp 0.7182  Epoch: 0   Global Step: 8400   Required: 43 hours
Training: 2025-11-30 21:13:04,765-Speed 1118.25 samples/sec   Loss 4.1296 target_logit_mean -0.0019 lma 0.6780  cos_theta_tmp 0.7166  Epoch: 0   Global Step: 8450   Required: 43 hours
Training: 2025-11-30 21:13:21,950-Speed 1117.31 samples/sec   Loss 4.1194 target_logit_mean -0.0045 lma 0.6672  cos_theta_tmp 0.7127  Epoch: 0   Global Step: 8500   Required: 43 hours
Training: 2025-11-30 21:13:39,115-Speed 1118.54 samples/sec   Loss 4.1096 target_logit_mean 0.0027 lma 0.6749  cos_theta_tmp 0.7088  Epoch: 0   Global Step: 8550   Required: 43 hours
Training: 2025-11-30 21:13:56,297-Speed 1117.51 samples/sec   Loss 4.0869 target_logit_mean -0.0011 lma 0.6897  cos_theta_tmp 0.7192  Epoch: 0   Global Step: 8600   Required: 43 hours
Training: 2025-11-30 21:14:13,465-Speed 1118.42 samples/sec   Loss 4.1210 target_logit_mean 0.0011 lma 0.6711  cos_theta_tmp 0.7119  Epoch: 0   Global Step: 8650   Required: 43 hours
Training: 2025-11-30 21:14:30,647-Speed 1117.44 samples/sec   Loss 4.0898 target_logit_mean 0.0019 lma 0.6815  cos_theta_tmp 0.7182  Epoch: 0   Global Step: 8700   Required: 43 hours
Training: 2025-11-30 21:14:47,828-Speed 1117.60 samples/sec   Loss 4.0303 target_logit_mean -0.0000 lma 0.6825  cos_theta_tmp 0.7216  Epoch: 0   Global Step: 8750   Required: 43 hours
Training: 2025-11-30 21:15:04,995-Speed 1118.48 samples/sec   Loss 4.0021 target_logit_mean -0.0000 lma 0.6773  cos_theta_tmp 0.7169  Epoch: 0   Global Step: 8800   Required: 43 hours
Training: 2025-11-30 21:15:22,174-Speed 1117.70 samples/sec   Loss 4.0236 target_logit_mean 0.0002 lma 0.6835  cos_theta_tmp 0.7218  Epoch: 0   Global Step: 8850   Required: 43 hours
Training: 2025-11-30 21:15:39,338-Speed 1118.64 samples/sec   Loss 3.9730 target_logit_mean -0.0013 lma 0.6756  cos_theta_tmp 0.7217  Epoch: 0   Global Step: 8900   Required: 43 hours
Training: 2025-11-30 21:15:56,520-Speed 1117.44 samples/sec   Loss 3.9829 target_logit_mean 0.0028 lma 0.6873  cos_theta_tmp 0.7277  Epoch: 0   Global Step: 8950   Required: 43 hours
Training: 2025-11-30 21:16:13,686-Speed 1118.56 samples/sec   Loss 4.0252 target_logit_mean -0.0006 lma 0.6816  cos_theta_tmp 0.7177  Epoch: 0   Global Step: 9000   Required: 43 hours
Training: 2025-11-30 21:16:30,869-Speed 1117.39 samples/sec   Loss 4.0149 target_logit_mean 0.0017 lma 0.6779  cos_theta_tmp 0.7216  Epoch: 0   Global Step: 9050   Required: 43 hours
Training: 2025-11-30 21:16:48,050-Speed 1117.53 samples/sec   Loss 3.9452 target_logit_mean 0.0013 lma 0.6728  cos_theta_tmp 0.7178  Epoch: 0   Global Step: 9100   Required: 42 hours
Training: 2025-11-30 21:17:05,217-Speed 1118.48 samples/sec   Loss 3.9431 target_logit_mean 0.0009 lma 0.6878  cos_theta_tmp 0.7250  Epoch: 0   Global Step: 9150   Required: 42 hours
Training: 2025-11-30 21:17:22,398-Speed 1117.50 samples/sec   Loss 3.9912 target_logit_mean 0.0009 lma 0.6700  cos_theta_tmp 0.7186  Epoch: 0   Global Step: 9200   Required: 42 hours
Training: 2025-11-30 21:17:39,561-Speed 1118.73 samples/sec   Loss 3.9848 target_logit_mean -0.0003 lma 0.6798  cos_theta_tmp 0.7244  Epoch: 0   Global Step: 9250   Required: 42 hours
Training: 2025-11-30 21:17:56,744-Speed 1117.44 samples/sec   Loss 3.9279 target_logit_mean 0.0007 lma 0.6885  cos_theta_tmp 0.7277  Epoch: 0   Global Step: 9300   Required: 42 hours
Training: 2025-11-30 21:18:13,909-Speed 1118.60 samples/sec   Loss 3.9445 target_logit_mean 0.0008 lma 0.6745  cos_theta_tmp 0.7173  Epoch: 0   Global Step: 9350   Required: 42 hours
Training: 2025-11-30 21:18:31,088-Speed 1117.64 samples/sec   Loss 3.9005 target_logit_mean 0.0003 lma 0.6764  cos_theta_tmp 0.7218  Epoch: 0   Global Step: 9400   Required: 42 hours
Training: 2025-11-30 21:18:48,271-Speed 1117.46 samples/sec   Loss 3.8832 target_logit_mean 0.0020 lma 0.6823  cos_theta_tmp 0.7197  Epoch: 0   Global Step: 9450   Required: 42 hours
Training: 2025-11-30 21:19:05,439-Speed 1118.33 samples/sec   Loss 3.8808 target_logit_mean 0.0019 lma 0.6740  cos_theta_tmp 0.7216  Epoch: 0   Global Step: 9500   Required: 42 hours
Training: 2025-11-30 21:19:22,620-Speed 1117.57 samples/sec   Loss 3.9510 target_logit_mean 0.0013 lma 0.6759  cos_theta_tmp 0.7175  Epoch: 0   Global Step: 9550   Required: 42 hours
Training: 2025-11-30 21:19:39,785-Speed 1118.63 samples/sec   Loss 3.8467 target_logit_mean 0.0002 lma 0.6829  cos_theta_tmp 0.7252  Epoch: 0   Global Step: 9600   Required: 42 hours
Training: 2025-11-30 21:19:56,966-Speed 1117.51 samples/sec   Loss 3.8549 target_logit_mean -0.0004 lma 0.6698  cos_theta_tmp 0.7265  Epoch: 0   Global Step: 9650   Required: 42 hours
Training: 2025-11-30 21:20:14,131-Speed 1118.60 samples/sec   Loss 3.9254 target_logit_mean -0.0002 lma 0.6718  cos_theta_tmp 0.7196  Epoch: 0   Global Step: 9700   Required: 42 hours
Training: 2025-11-30 21:20:31,433-Speed 1109.77 samples/sec   Loss 3.9079 target_logit_mean 0.0015 lma 0.6811  cos_theta_tmp 0.7196  Epoch: 0   Global Step: 9750   Required: 42 hours
Training: 2025-11-30 21:20:48,884-Speed 1100.26 samples/sec   Loss 3.9058 target_logit_mean 0.0013 lma 0.6814  cos_theta_tmp 0.7181  Epoch: 0   Global Step: 9800   Required: 42 hours
Training: 2025-11-30 21:21:06,332-Speed 1100.40 samples/sec   Loss 3.9069 target_logit_mean 0.0010 lma 0.6701  cos_theta_tmp 0.7233  Epoch: 0   Global Step: 9850   Required: 42 hours
Training: 2025-11-30 21:21:23,721-Speed 1104.23 samples/sec   Loss 3.8449 target_logit_mean 0.0028 lma 0.6831  cos_theta_tmp 0.7323  Epoch: 0   Global Step: 9900   Required: 42 hours
Training: 2025-11-30 21:21:41,079-Speed 1106.16 samples/sec   Loss 3.8773 target_logit_mean 0.0007 lma 0.6678  cos_theta_tmp 0.7261  Epoch: 0   Global Step: 9950   Required: 42 hours
Training: 2025-11-30 21:21:58,355-Speed 1111.37 samples/sec   Loss 3.8991 target_logit_mean -0.0012 lma 0.6781  cos_theta_tmp 0.7179  Epoch: 0   Global Step: 10000   Required: 42 hours
Training: 2025-11-30 21:22:15,522-Speed 1118.47 samples/sec   Loss 3.8606 target_logit_mean 0.0005 lma 0.6852  cos_theta_tmp 0.7253  Epoch: 0   Global Step: 10050   Required: 42 hours
Training: 2025-11-30 21:22:32,710-Speed 1117.10 samples/sec   Loss 3.7923 target_logit_mean 0.0017 lma 0.6818  cos_theta_tmp 0.7273  Epoch: 0   Global Step: 10100   Required: 42 hours
Training: 2025-11-30 21:22:49,900-Speed 1116.96 samples/sec   Loss 3.7840 target_logit_mean 0.0007 lma 0.6729  cos_theta_tmp 0.7241  Epoch: 0   Global Step: 10150   Required: 42 hours
Training: 2025-11-30 21:23:07,065-Speed 1118.59 samples/sec   Loss 3.7720 target_logit_mean -0.0015 lma 0.6688  cos_theta_tmp 0.7221  Epoch: 0   Global Step: 10200   Required: 42 hours
Training: 2025-11-30 21:23:24,252-Speed 1117.16 samples/sec   Loss 3.7683 target_logit_mean 0.0018 lma 0.6739  cos_theta_tmp 0.7278  Epoch: 0   Global Step: 10250   Required: 42 hours
Training: 2025-11-30 21:23:41,418-Speed 1118.52 samples/sec   Loss 3.8531 target_logit_mean 0.0021 lma 0.6835  cos_theta_tmp 0.7321  Epoch: 0   Global Step: 10300   Required: 42 hours
Training: 2025-11-30 21:23:58,605-Speed 1117.13 samples/sec   Loss 3.8262 target_logit_mean -0.0009 lma 0.6787  cos_theta_tmp 0.7214  Epoch: 0   Global Step: 10350   Required: 42 hours
Training: 2025-11-30 21:24:15,769-Speed 1118.64 samples/sec   Loss 3.7405 target_logit_mean -0.0008 lma 0.6871  cos_theta_tmp 0.7289  Epoch: 0   Global Step: 10400   Required: 42 hours
Training: 2025-11-30 21:24:32,955-Speed 1117.25 samples/sec   Loss 3.7296 target_logit_mean -0.0004 lma 0.6856  cos_theta_tmp 0.7270  Epoch: 0   Global Step: 10450   Required: 42 hours
Training: 2025-11-30 21:24:50,140-Speed 1117.28 samples/sec   Loss 3.7971 target_logit_mean 0.0021 lma 0.6795  cos_theta_tmp 0.7350  Epoch: 0   Global Step: 10500   Required: 42 hours
Training: 2025-11-30 21:25:07,304-Speed 1118.64 samples/sec   Loss 3.8047 target_logit_mean -0.0013 lma 0.6723  cos_theta_tmp 0.7214  Epoch: 0   Global Step: 10550   Required: 42 hours
Training: 2025-11-30 21:25:24,529-Speed 1114.69 samples/sec   Loss 3.8182 target_logit_mean 0.0011 lma 0.6663  cos_theta_tmp 0.7242  Epoch: 0   Global Step: 10600   Required: 42 hours
Training: 2025-11-30 21:25:41,694-Speed 1118.60 samples/sec   Loss 3.7910 target_logit_mean -0.0008 lma 0.6693  cos_theta_tmp 0.7214  Epoch: 0   Global Step: 10650   Required: 41 hours
Training: 2025-11-30 21:25:58,990-Speed 1110.09 samples/sec   Loss 3.7176 target_logit_mean -0.0006 lma 0.6753  cos_theta_tmp 0.7336  Epoch: 0   Global Step: 10700   Required: 41 hours
Training: 2025-11-30 21:26:16,153-Speed 1118.71 samples/sec   Loss 3.7554 target_logit_mean -0.0012 lma 0.6721  cos_theta_tmp 0.7213  Epoch: 0   Global Step: 10750   Required: 41 hours
Training: 2025-11-30 21:26:33,334-Speed 1117.61 samples/sec   Loss 3.7040 target_logit_mean -0.0017 lma 0.6682  cos_theta_tmp 0.7241  Epoch: 0   Global Step: 10800   Required: 41 hours
Training: 2025-11-30 21:26:50,519-Speed 1117.27 samples/sec   Loss 3.7203 target_logit_mean 0.0004 lma 0.6767  cos_theta_tmp 0.7292  Epoch: 0   Global Step: 10850   Required: 41 hours
Training: 2025-11-30 21:27:07,685-Speed 1118.54 samples/sec   Loss 3.6972 target_logit_mean -0.0009 lma 0.6700  cos_theta_tmp 0.7237  Epoch: 0   Global Step: 10900   Required: 41 hours
Training: 2025-11-30 21:27:24,871-Speed 1117.21 samples/sec   Loss 3.7132 target_logit_mean -0.0006 lma 0.6910  cos_theta_tmp 0.7332  Epoch: 0   Global Step: 10950   Required: 41 hours
Training: 2025-11-30 21:27:42,145-Speed 1111.53 samples/sec   Loss 3.6888 target_logit_mean 0.0022 lma 0.6911  cos_theta_tmp 0.7283  Epoch: 0   Global Step: 11000   Required: 41 hours
Training: 2025-11-30 21:27:59,414-Speed 1111.85 samples/sec   Loss 3.7398 target_logit_mean -0.0008 lma 0.6807  cos_theta_tmp 0.7287  Epoch: 0   Global Step: 11050   Required: 41 hours
Training: 2025-11-30 21:28:16,638-Speed 1114.74 samples/sec   Loss 3.6957 target_logit_mean -0.0026 lma 0.6829  cos_theta_tmp 0.7251  Epoch: 0   Global Step: 11100   Required: 41 hours
Training: 2025-11-30 21:28:34,115-Speed 1098.63 samples/sec   Loss 3.7380 target_logit_mean 0.0005 lma 0.6717  cos_theta_tmp 0.7309  Epoch: 0   Global Step: 11150   Required: 41 hours
Training: 2025-11-30 21:28:51,738-Speed 1089.53 samples/sec   Loss 3.7214 target_logit_mean -0.0005 lma 0.6821  cos_theta_tmp 0.7199  Epoch: 0   Global Step: 11200   Required: 41 hours
Training: 2025-11-30 21:29:09,020-Speed 1111.00 samples/sec   Loss 3.6337 target_logit_mean -0.0011 lma 0.6797  cos_theta_tmp 0.7331  Epoch: 0   Global Step: 11250   Required: 41 hours
Training: 2025-11-30 21:29:26,476-Speed 1099.95 samples/sec   Loss 3.6564 target_logit_mean -0.0008 lma 0.6763  cos_theta_tmp 0.7250  Epoch: 0   Global Step: 11300   Required: 41 hours
Training: 2025-11-30 21:29:43,827-Speed 1106.60 samples/sec   Loss 3.6285 target_logit_mean 0.0004 lma 0.6908  cos_theta_tmp 0.7267  Epoch: 0   Global Step: 11350   Required: 41 hours
Training: 2025-11-30 21:30:01,068-Speed 1113.69 samples/sec   Loss 3.6567 target_logit_mean -0.0044 lma 0.6839  cos_theta_tmp 0.7288  Epoch: 0   Global Step: 11400   Required: 41 hours
Training: 2025-11-30 21:30:18,290-Speed 1114.87 samples/sec   Loss 3.6358 target_logit_mean 0.0023 lma 0.6869  cos_theta_tmp 0.7342  Epoch: 0   Global Step: 11450   Required: 41 hours
Training: 2025-11-30 21:30:35,580-Speed 1110.50 samples/sec   Loss 3.6435 target_logit_mean -0.0011 lma 0.6743  cos_theta_tmp 0.7259  Epoch: 0   Global Step: 11500   Required: 41 hours
Training: 2025-11-30 21:30:52,931-Speed 1106.60 samples/sec   Loss 3.6303 target_logit_mean 0.0016 lma 0.6730  cos_theta_tmp 0.7246  Epoch: 0   Global Step: 11550   Required: 41 hours
Training: 2025-11-30 21:31:10,360-Speed 1101.67 samples/sec   Loss 3.6417 target_logit_mean -0.0022 lma 0.6775  cos_theta_tmp 0.7252  Epoch: 0   Global Step: 11600   Required: 41 hours
Training: 2025-11-30 21:31:27,857-Speed 1097.34 samples/sec   Loss 3.6579 target_logit_mean 0.0013 lma 0.6781  cos_theta_tmp 0.7330  Epoch: 0   Global Step: 11650   Required: 41 hours
Training: 2025-11-30 21:31:45,318-Speed 1099.60 samples/sec   Loss 3.6179 target_logit_mean 0.0011 lma 0.6686  cos_theta_tmp 0.7262  Epoch: 0   Global Step: 11700   Required: 41 hours
Training: 2025-11-30 21:32:02,762-Speed 1100.75 samples/sec   Loss 3.5954 target_logit_mean 0.0006 lma 0.6788  cos_theta_tmp 0.7303  Epoch: 0   Global Step: 11750   Required: 41 hours
Training: 2025-11-30 21:32:20,192-Speed 1101.56 samples/sec   Loss 3.6274 target_logit_mean 0.0014 lma 0.6860  cos_theta_tmp 0.7304  Epoch: 0   Global Step: 11800   Required: 41 hours
Training: 2025-11-30 21:32:37,637-Speed 1100.69 samples/sec   Loss 3.5159 target_logit_mean 0.0013 lma 0.6791  cos_theta_tmp 0.7331  Epoch: 0   Global Step: 11850   Required: 41 hours
Training: 2025-11-30 21:32:55,082-Speed 1100.62 samples/sec   Loss 3.5837 target_logit_mean -0.0019 lma 0.6777  cos_theta_tmp 0.7308  Epoch: 0   Global Step: 11900   Required: 41 hours
Training: 2025-11-30 21:33:12,572-Speed 1097.79 samples/sec   Loss 3.5612 target_logit_mean 0.0001 lma 0.6727  cos_theta_tmp 0.7296  Epoch: 0   Global Step: 11950   Required: 41 hours
Training: 2025-11-30 21:33:30,029-Speed 1099.88 samples/sec   Loss 3.5895 target_logit_mean 0.0007 lma 0.6771  cos_theta_tmp 0.7309  Epoch: 0   Global Step: 12000   Required: 41 hours
Training: 2025-11-30 21:33:47,465-Speed 1101.22 samples/sec   Loss 3.5896 target_logit_mean 0.0006 lma 0.6839  cos_theta_tmp 0.7289  Epoch: 0   Global Step: 12050   Required: 41 hours
Training: 2025-11-30 21:34:04,880-Speed 1102.56 samples/sec   Loss 3.5905 target_logit_mean -0.0016 lma 0.6865  cos_theta_tmp 0.7354  Epoch: 0   Global Step: 12100   Required: 41 hours
Training: 2025-11-30 21:34:22,286-Speed 1103.08 samples/sec   Loss 3.5965 target_logit_mean 0.0024 lma 0.6814  cos_theta_tmp 0.7380  Epoch: 0   Global Step: 12150   Required: 41 hours
Training: 2025-11-30 21:34:39,708-Speed 1102.11 samples/sec   Loss 3.5325 target_logit_mean 0.0012 lma 0.6850  cos_theta_tmp 0.7315  Epoch: 0   Global Step: 12200   Required: 41 hours
Training: 2025-11-30 21:34:57,126-Speed 1102.36 samples/sec   Loss 3.5629 target_logit_mean -0.0000 lma 0.6880  cos_theta_tmp 0.7324  Epoch: 0   Global Step: 12250   Required: 41 hours
Training: 2025-11-30 21:35:14,530-Speed 1103.21 samples/sec   Loss 3.6052 target_logit_mean 0.0021 lma 0.6835  cos_theta_tmp 0.7285  Epoch: 0   Global Step: 12300   Required: 41 hours
Training: 2025-11-30 21:35:31,947-Speed 1102.45 samples/sec   Loss 3.5191 target_logit_mean 0.0010 lma 0.6856  cos_theta_tmp 0.7282  Epoch: 0   Global Step: 12350   Required: 41 hours
Training: 2025-11-30 21:35:49,354-Speed 1103.03 samples/sec   Loss 3.5720 target_logit_mean 0.0000 lma 0.6922  cos_theta_tmp 0.7330  Epoch: 0   Global Step: 12400   Required: 41 hours
Training: 2025-11-30 21:36:06,770-Speed 1102.44 samples/sec   Loss 3.5544 target_logit_mean -0.0003 lma 0.6735  cos_theta_tmp 0.7263  Epoch: 0   Global Step: 12450   Required: 41 hours
Training: 2025-11-30 21:36:24,191-Speed 1102.17 samples/sec   Loss 3.5974 target_logit_mean 0.0028 lma 0.6841  cos_theta_tmp 0.7316  Epoch: 0   Global Step: 12500   Required: 41 hours
Training: 2025-11-30 21:36:41,597-Speed 1103.14 samples/sec   Loss 3.5250 target_logit_mean -0.0012 lma 0.6725  cos_theta_tmp 0.7297  Epoch: 0   Global Step: 12550   Required: 41 hours
Training: 2025-11-30 21:36:59,019-Speed 1102.06 samples/sec   Loss 3.5449 target_logit_mean -0.0009 lma 0.6852  cos_theta_tmp 0.7326  Epoch: 0   Global Step: 12600   Required: 41 hours
Training: 2025-11-30 21:37:16,433-Speed 1102.60 samples/sec   Loss 3.5214 target_logit_mean 0.0025 lma 0.6874  cos_theta_tmp 0.7344  Epoch: 0   Global Step: 12650   Required: 41 hours
Training: 2025-11-30 21:37:33,847-Speed 1102.61 samples/sec   Loss 3.5476 target_logit_mean 0.0009 lma 0.6773  cos_theta_tmp 0.7302  Epoch: 0   Global Step: 12700   Required: 41 hours
Training: 2025-11-30 21:37:51,253-Speed 1103.10 samples/sec   Loss 3.5349 target_logit_mean -0.0008 lma 0.6769  cos_theta_tmp 0.7295  Epoch: 0   Global Step: 12750   Required: 41 hours
Training: 2025-11-30 21:38:08,678-Speed 1101.95 samples/sec   Loss 3.4635 target_logit_mean -0.0015 lma 0.6789  cos_theta_tmp 0.7326  Epoch: 0   Global Step: 12800   Required: 41 hours
Training: 2025-11-30 21:38:26,095-Speed 1102.38 samples/sec   Loss 3.5056 target_logit_mean 0.0020 lma 0.6722  cos_theta_tmp 0.7334  Epoch: 0   Global Step: 12850   Required: 40 hours
Training: 2025-11-30 21:38:43,500-Speed 1103.18 samples/sec   Loss 3.4324 target_logit_mean 0.0008 lma 0.6830  cos_theta_tmp 0.7359  Epoch: 0   Global Step: 12900   Required: 40 hours
Training: 2025-11-30 21:39:00,921-Speed 1102.18 samples/sec   Loss 3.5754 target_logit_mean 0.0002 lma 0.6755  cos_theta_tmp 0.7331  Epoch: 0   Global Step: 12950   Required: 40 hours
Training: 2025-11-30 21:39:18,331-Speed 1102.86 samples/sec   Loss 3.5539 target_logit_mean 0.0006 lma 0.6785  cos_theta_tmp 0.7290  Epoch: 0   Global Step: 13000   Required: 40 hours
Training: 2025-11-30 21:39:35,754-Speed 1102.01 samples/sec   Loss 3.5462 target_logit_mean 0.0016 lma 0.6857  cos_theta_tmp 0.7331  Epoch: 0   Global Step: 13050   Required: 40 hours
Training: 2025-11-30 21:39:53,160-Speed 1103.13 samples/sec   Loss 3.5771 target_logit_mean 0.0029 lma 0.6896  cos_theta_tmp 0.7366  Epoch: 0   Global Step: 13100   Required: 40 hours
Training: 2025-11-30 21:40:10,580-Speed 1102.17 samples/sec   Loss 3.4831 target_logit_mean -0.0028 lma 0.6769  cos_theta_tmp 0.7390  Epoch: 0   Global Step: 13150   Required: 40 hours
Training: 2025-11-30 21:40:28,018-Speed 1101.13 samples/sec   Loss 3.4926 target_logit_mean -0.0019 lma 0.6732  cos_theta_tmp 0.7332  Epoch: 0   Global Step: 13200   Required: 40 hours
Training: 2025-11-30 21:40:45,654-Speed 1088.73 samples/sec   Loss 3.5125 target_logit_mean 0.0004 lma 0.6645  cos_theta_tmp 0.7361  Epoch: 0   Global Step: 13250   Required: 40 hours
Training: 2025-11-30 21:41:03,077-Speed 1102.01 samples/sec   Loss 3.4635 target_logit_mean -0.0016 lma 0.6838  cos_theta_tmp 0.7364  Epoch: 0   Global Step: 13300   Required: 40 hours
Training: 2025-11-30 21:41:20,480-Speed 1103.28 samples/sec   Loss 3.4032 target_logit_mean 0.0017 lma 0.6832  cos_theta_tmp 0.7316  Epoch: 0   Global Step: 13350   Required: 40 hours
Training: 2025-11-30 21:41:37,902-Speed 1102.13 samples/sec   Loss 3.4795 target_logit_mean 0.0044 lma 0.6791  cos_theta_tmp 0.7340  Epoch: 0   Global Step: 13400   Required: 40 hours
Training: 2025-11-30 21:41:55,326-Speed 1101.96 samples/sec   Loss 3.4717 target_logit_mean 0.0020 lma 0.6736  cos_theta_tmp 0.7348  Epoch: 0   Global Step: 13450   Required: 40 hours
Training: 2025-11-30 21:42:12,792-Speed 1099.33 samples/sec   Loss 3.4231 target_logit_mean -0.0004 lma 0.6825  cos_theta_tmp 0.7322  Epoch: 0   Global Step: 13500   Required: 40 hours
Training: 2025-11-30 21:42:30,214-Speed 1102.11 samples/sec   Loss 3.3790 target_logit_mean 0.0007 lma 0.6797  cos_theta_tmp 0.7340  Epoch: 0   Global Step: 13550   Required: 40 hours
Training: 2025-11-30 21:42:47,621-Speed 1103.02 samples/sec   Loss 3.4099 target_logit_mean 0.0000 lma 0.6616  cos_theta_tmp 0.7324  Epoch: 0   Global Step: 13600   Required: 40 hours
Training: 2025-11-30 21:43:05,038-Speed 1102.40 samples/sec   Loss 3.4610 target_logit_mean 0.0025 lma 0.6885  cos_theta_tmp 0.7357  Epoch: 0   Global Step: 13650   Required: 40 hours
Training: 2025-11-30 21:43:22,442-Speed 1103.26 samples/sec   Loss 3.3758 target_logit_mean -0.0008 lma 0.6545  cos_theta_tmp 0.7321  Epoch: 0   Global Step: 13700   Required: 40 hours
Training: 2025-11-30 21:43:39,877-Speed 1101.28 samples/sec   Loss 3.4018 target_logit_mean -0.0009 lma 0.6775  cos_theta_tmp 0.7276  Epoch: 0   Global Step: 13750   Required: 40 hours
Training: 2025-11-30 21:43:57,383-Speed 1096.77 samples/sec   Loss 3.4789 target_logit_mean 0.0001 lma 0.6884  cos_theta_tmp 0.7374  Epoch: 0   Global Step: 13800   Required: 40 hours
Training: 2025-11-30 21:44:14,826-Speed 1100.79 samples/sec   Loss 3.4277 target_logit_mean -0.0003 lma 0.6918  cos_theta_tmp 0.7354  Epoch: 0   Global Step: 13850   Required: 40 hours
Training: 2025-11-30 21:44:32,327-Speed 1097.11 samples/sec   Loss 3.4667 target_logit_mean -0.0008 lma 0.6750  cos_theta_tmp 0.7335  Epoch: 0   Global Step: 13900   Required: 40 hours
Training: 2025-11-30 21:44:49,899-Speed 1092.69 samples/sec   Loss 3.4675 target_logit_mean -0.0001 lma 0.6780  cos_theta_tmp 0.7331  Epoch: 0   Global Step: 13950   Required: 40 hours
Training: 2025-11-30 21:45:07,346-Speed 1100.53 samples/sec   Loss 3.4178 target_logit_mean 0.0008 lma 0.6755  cos_theta_tmp 0.7288  Epoch: 0   Global Step: 14000   Required: 40 hours
Training: 2025-11-30 21:45:24,756-Speed 1102.83 samples/sec   Loss 3.4176 target_logit_mean -0.0011 lma 0.6711  cos_theta_tmp 0.7284  Epoch: 0   Global Step: 14050   Required: 40 hours
Training: 2025-11-30 21:45:42,163-Speed 1103.05 samples/sec   Loss 3.4636 target_logit_mean -0.0008 lma 0.6708  cos_theta_tmp 0.7343  Epoch: 0   Global Step: 14100   Required: 40 hours
Training: 2025-11-30 21:45:59,579-Speed 1102.43 samples/sec   Loss 3.5244 target_logit_mean 0.0030 lma 0.6820  cos_theta_tmp 0.7372  Epoch: 0   Global Step: 14150   Required: 40 hours
Training: 2025-11-30 21:46:17,057-Speed 1098.60 samples/sec   Loss 3.4459 target_logit_mean 0.0020 lma 0.6822  cos_theta_tmp 0.7330  Epoch: 0   Global Step: 14200   Required: 40 hours
Training: 2025-11-30 21:46:34,490-Speed 1101.39 samples/sec   Loss 3.4679 target_logit_mean 0.0015 lma 0.6844  cos_theta_tmp 0.7298  Epoch: 0   Global Step: 14250   Required: 40 hours
Training: 2025-11-30 21:46:51,900-Speed 1102.85 samples/sec   Loss 3.4101 target_logit_mean 0.0008 lma 0.6770  cos_theta_tmp 0.7283  Epoch: 0   Global Step: 14300   Required: 40 hours
Training: 2025-11-30 21:47:09,317-Speed 1102.39 samples/sec   Loss 3.3584 target_logit_mean -0.0009 lma 0.6694  cos_theta_tmp 0.7312  Epoch: 0   Global Step: 14350   Required: 40 hours
Training: 2025-11-30 21:47:26,735-Speed 1102.37 samples/sec   Loss 3.4722 target_logit_mean -0.0002 lma 0.6802  cos_theta_tmp 0.7326  Epoch: 0   Global Step: 14400   Required: 40 hours
Training: 2025-11-30 21:47:44,138-Speed 1103.27 samples/sec   Loss 3.4070 target_logit_mean 0.0007 lma 0.6805  cos_theta_tmp 0.7373  Epoch: 0   Global Step: 14450   Required: 40 hours
Training: 2025-11-30 21:48:01,557-Speed 1102.32 samples/sec   Loss 3.4019 target_logit_mean 0.0030 lma 0.6796  cos_theta_tmp 0.7429  Epoch: 0   Global Step: 14500   Required: 40 hours
Training: 2025-11-30 21:48:18,968-Speed 1102.80 samples/sec   Loss 3.3936 target_logit_mean 0.0010 lma 0.6737  cos_theta_tmp 0.7316  Epoch: 0   Global Step: 14550   Required: 40 hours
Training: 2025-11-30 21:48:36,385-Speed 1102.36 samples/sec   Loss 3.3835 target_logit_mean -0.0024 lma 0.6854  cos_theta_tmp 0.7337  Epoch: 0   Global Step: 14600   Required: 40 hours
Training: 2025-11-30 21:48:53,824-Speed 1101.06 samples/sec   Loss 3.3784 target_logit_mean 0.0011 lma 0.6941  cos_theta_tmp 0.7422  Epoch: 0   Global Step: 14650   Required: 40 hours
Training: 2025-11-30 21:49:11,256-Speed 1101.42 samples/sec   Loss 3.3588 target_logit_mean -0.0021 lma 0.6846  cos_theta_tmp 0.7356  Epoch: 0   Global Step: 14700   Required: 40 hours
Training: 2025-11-30 21:49:28,671-Speed 1102.58 samples/sec   Loss 3.3820 target_logit_mean 0.0019 lma 0.6784  cos_theta_tmp 0.7337  Epoch: 0   Global Step: 14750   Required: 40 hours
Training: 2025-11-30 21:49:46,076-Speed 1103.18 samples/sec   Loss 3.3922 target_logit_mean -0.0009 lma 0.6885  cos_theta_tmp 0.7362  Epoch: 0   Global Step: 14800   Required: 40 hours
Training: 2025-11-30 21:50:03,493-Speed 1102.37 samples/sec   Loss 3.3766 target_logit_mean -0.0003 lma 0.6826  cos_theta_tmp 0.7400  Epoch: 0   Global Step: 14850   Required: 40 hours
Training: 2025-11-30 21:50:20,895-Speed 1103.41 samples/sec   Loss 3.2973 target_logit_mean -0.0010 lma 0.6734  cos_theta_tmp 0.7361  Epoch: 0   Global Step: 14900   Required: 40 hours
Training: 2025-11-30 21:50:38,307-Speed 1102.70 samples/sec   Loss 3.3480 target_logit_mean 0.0012 lma 0.6879  cos_theta_tmp 0.7389  Epoch: 0   Global Step: 14950   Required: 40 hours
Training: 2025-11-30 21:50:55,709-Speed 1103.33 samples/sec   Loss 3.3040 target_logit_mean 0.0016 lma 0.6730  cos_theta_tmp 0.7379  Epoch: 0   Global Step: 15000   Required: 40 hours
Training: 2025-11-30 21:51:13,121-Speed 1102.77 samples/sec   Loss 3.3486 target_logit_mean 0.0005 lma 0.6798  cos_theta_tmp 0.7340  Epoch: 0   Global Step: 15050   Required: 40 hours
Training: 2025-11-30 21:51:30,535-Speed 1102.56 samples/sec   Loss 3.4091 target_logit_mean -0.0000 lma 0.6717  cos_theta_tmp 0.7329  Epoch: 0   Global Step: 15100   Required: 40 hours
Training: 2025-11-30 21:51:47,969-Speed 1101.36 samples/sec   Loss 3.3896 target_logit_mean -0.0024 lma 0.6731  cos_theta_tmp 0.7352  Epoch: 0   Global Step: 15150   Required: 40 hours
Training: 2025-11-30 21:52:11,457-[lfw][15163]XNorm: 23.160479
Training: 2025-11-30 21:52:11,457-[lfw][15163]Accuracy-Flip: 0.99050+-0.00409
Training: 2025-11-30 21:52:11,457-[lfw][15163]Accuracy-Highest: 0.99050
Training: 2025-11-30 21:52:25,854-[cfp_fp][15163]XNorm: 18.679785
Training: 2025-11-30 21:52:25,854-[cfp_fp][15163]Accuracy-Flip: 0.85386+-0.01444
Training: 2025-11-30 21:52:25,854-[cfp_fp][15163]Accuracy-Highest: 0.85386
Training: 2025-11-30 21:52:39,693-[cfp_ff][15163]XNorm: 22.379825
Training: 2025-11-30 21:52:39,694-[cfp_ff][15163]Accuracy-Flip: 0.98986+-0.00347
Training: 2025-11-30 21:52:39,694-[cfp_ff][15163]Accuracy-Highest: 0.98986
Training: 2025-11-30 21:52:51,622-[agedb_30][15163]XNorm: 21.905366
Training: 2025-11-30 21:52:51,622-[agedb_30][15163]Accuracy-Flip: 0.92283+-0.01218
Training: 2025-11-30 21:52:51,622-[agedb_30][15163]Accuracy-Highest: 0.92283
Training: 2025-11-30 21:53:03,656-[calfw][15163]XNorm: 23.030295
Training: 2025-11-30 21:53:03,656-[calfw][15163]Accuracy-Flip: 0.93133+-0.01149
Training: 2025-11-30 21:53:03,656-[calfw][15163]Accuracy-Highest: 0.93133
Training: 2025-11-30 21:53:15,667-[cplfw][15163]XNorm: 18.877565
Training: 2025-11-30 21:53:15,667-[cplfw][15163]Accuracy-Flip: 0.84150+-0.01771
Training: 2025-11-30 21:53:15,667-[cplfw][15163]Accuracy-Highest: 0.84150
Training: 2025-11-30 21:53:25,719-[vgg2_fp][15163]XNorm: 19.360043
Training: 2025-11-30 21:53:25,719-[vgg2_fp][15163]Accuracy-Flip: 0.86820+-0.01319
Training: 2025-11-30 21:53:25,719-[vgg2_fp][15163]Accuracy-Highest: 0.86820
Training: 2025-11-30 21:53:56,995-Speed 148.81 samples/sec   Loss 3.3235 target_logit_mean -0.0034 lma 0.6732  cos_theta_tmp 0.7374  Epoch: 1   Global Step: 15200   Required: 40 hours
Training: 2025-11-30 21:54:14,366-Speed 1105.33 samples/sec   Loss 3.2962 target_logit_mean -0.0010 lma 0.6879  cos_theta_tmp 0.7330  Epoch: 1   Global Step: 15250   Required: 40 hours
Training: 2025-11-30 21:54:31,764-Speed 1103.65 samples/sec   Loss 3.3176 target_logit_mean 0.0018 lma 0.6825  cos_theta_tmp 0.7374  Epoch: 1   Global Step: 15300   Required: 40 hours
Training: 2025-11-30 21:54:49,164-Speed 1103.49 samples/sec   Loss 3.2993 target_logit_mean -0.0013 lma 0.6872  cos_theta_tmp 0.7357  Epoch: 1   Global Step: 15350   Required: 40 hours
Training: 2025-11-30 21:55:06,573-Speed 1102.91 samples/sec   Loss 3.2945 target_logit_mean -0.0017 lma 0.6805  cos_theta_tmp 0.7292  Epoch: 1   Global Step: 15400   Required: 40 hours
Training: 2025-11-30 21:55:23,969-Speed 1103.75 samples/sec   Loss 3.3377 target_logit_mean -0.0005 lma 0.6717  cos_theta_tmp 0.7349  Epoch: 1   Global Step: 15450   Required: 40 hours
Training: 2025-11-30 21:55:41,375-Speed 1103.06 samples/sec   Loss 3.2935 target_logit_mean 0.0010 lma 0.6855  cos_theta_tmp 0.7408  Epoch: 1   Global Step: 15500   Required: 40 hours
Training: 2025-11-30 21:55:58,789-Speed 1102.66 samples/sec   Loss 3.2662 target_logit_mean -0.0006 lma 0.6872  cos_theta_tmp 0.7374  Epoch: 1   Global Step: 15550   Required: 40 hours
Training: 2025-11-30 21:56:16,195-Speed 1103.07 samples/sec   Loss 3.3332 target_logit_mean 0.0022 lma 0.6755  cos_theta_tmp 0.7405  Epoch: 1   Global Step: 15600   Required: 40 hours
Training: 2025-11-30 21:56:33,609-Speed 1102.62 samples/sec   Loss 3.3072 target_logit_mean -0.0009 lma 0.6860  cos_theta_tmp 0.7420  Epoch: 1   Global Step: 15650   Required: 40 hours
Training: 2025-11-30 21:56:51,009-Speed 1103.50 samples/sec   Loss 3.3141 target_logit_mean -0.0010 lma 0.6810  cos_theta_tmp 0.7352  Epoch: 1   Global Step: 15700   Required: 40 hours
Training: 2025-11-30 21:57:08,421-Speed 1102.73 samples/sec   Loss 3.3683 target_logit_mean 0.0007 lma 0.6627  cos_theta_tmp 0.7295  Epoch: 1   Global Step: 15750   Required: 40 hours
Training: 2025-11-30 21:57:25,824-Speed 1103.29 samples/sec   Loss 3.3854 target_logit_mean -0.0026 lma 0.6685  cos_theta_tmp 0.7295  Epoch: 1   Global Step: 15800   Required: 40 hours
Training: 2025-11-30 21:57:43,232-Speed 1102.98 samples/sec   Loss 3.2902 target_logit_mean -0.0026 lma 0.6824  cos_theta_tmp 0.7338  Epoch: 1   Global Step: 15850   Required: 40 hours
Training: 2025-11-30 21:58:00,642-Speed 1102.87 samples/sec   Loss 3.3375 target_logit_mean 0.0008 lma 0.6976  cos_theta_tmp 0.7450  Epoch: 1   Global Step: 15900   Required: 40 hours
Training: 2025-11-30 21:58:18,043-Speed 1103.41 samples/sec   Loss 3.2788 target_logit_mean 0.0016 lma 0.6760  cos_theta_tmp 0.7376  Epoch: 1   Global Step: 15950   Required: 40 hours
Training: 2025-11-30 21:58:35,454-Speed 1102.75 samples/sec   Loss 3.2643 target_logit_mean -0.0011 lma 0.6945  cos_theta_tmp 0.7384  Epoch: 1   Global Step: 16000   Required: 40 hours
Training: 2025-11-30 21:58:52,855-Speed 1103.43 samples/sec   Loss 3.3157 target_logit_mean 0.0003 lma 0.6761  cos_theta_tmp 0.7374  Epoch: 1   Global Step: 16050   Required: 40 hours
Training: 2025-11-30 21:59:10,266-Speed 1102.78 samples/sec   Loss 3.3071 target_logit_mean 0.0009 lma 0.6735  cos_theta_tmp 0.7317  Epoch: 1   Global Step: 16100   Required: 40 hours
Training: 2025-11-30 21:59:27,670-Speed 1103.28 samples/sec   Loss 3.3207 target_logit_mean 0.0022 lma 0.6978  cos_theta_tmp 0.7389  Epoch: 1   Global Step: 16150   Required: 40 hours
Training: 2025-11-30 21:59:45,081-Speed 1102.78 samples/sec   Loss 3.3048 target_logit_mean 0.0007 lma 0.7014  cos_theta_tmp 0.7465  Epoch: 1   Global Step: 16200   Required: 40 hours
Training: 2025-11-30 22:00:02,492-Speed 1102.76 samples/sec   Loss 3.2972 target_logit_mean -0.0004 lma 0.6818  cos_theta_tmp 0.7343  Epoch: 1   Global Step: 16250   Required: 40 hours
Training: 2025-11-30 22:00:19,892-Speed 1103.48 samples/sec   Loss 3.2692 target_logit_mean -0.0001 lma 0.6792  cos_theta_tmp 0.7383  Epoch: 1   Global Step: 16300   Required: 40 hours
Training: 2025-11-30 22:00:37,299-Speed 1103.04 samples/sec   Loss 3.3622 target_logit_mean 0.0024 lma 0.6853  cos_theta_tmp 0.7396  Epoch: 1   Global Step: 16350   Required: 40 hours
Training: 2025-11-30 22:00:54,698-Speed 1103.58 samples/sec   Loss 3.3052 target_logit_mean -0.0008 lma 0.6862  cos_theta_tmp 0.7382  Epoch: 1   Global Step: 16400   Required: 40 hours
Training: 2025-11-30 22:01:12,253-Speed 1093.73 samples/sec   Loss 3.3013 target_logit_mean 0.0011 lma 0.6887  cos_theta_tmp 0.7378  Epoch: 1   Global Step: 16450   Required: 40 hours
Training: 2025-11-30 22:01:29,824-Speed 1092.72 samples/sec   Loss 3.2349 target_logit_mean -0.0001 lma 0.6754  cos_theta_tmp 0.7402  Epoch: 1   Global Step: 16500   Required: 40 hours
Training: 2025-11-30 22:01:47,374-Speed 1094.06 samples/sec   Loss 3.2239 target_logit_mean 0.0013 lma 0.6658  cos_theta_tmp 0.7369  Epoch: 1   Global Step: 16550   Required: 40 hours
Training: 2025-11-30 22:02:04,858-Speed 1098.23 samples/sec   Loss 3.2651 target_logit_mean 0.0023 lma 0.6871  cos_theta_tmp 0.7494  Epoch: 1   Global Step: 16600   Required: 40 hours
Training: 2025-11-30 22:02:22,297-Speed 1100.99 samples/sec   Loss 3.2156 target_logit_mean -0.0007 lma 0.6781  cos_theta_tmp 0.7348  Epoch: 1   Global Step: 16650   Required: 40 hours
Training: 2025-11-30 22:02:39,716-Speed 1102.26 samples/sec   Loss 3.2008 target_logit_mean 0.0001 lma 0.6866  cos_theta_tmp 0.7412  Epoch: 1   Global Step: 16700   Required: 40 hours
Training: 2025-11-30 22:02:57,117-Speed 1103.44 samples/sec   Loss 3.2097 target_logit_mean 0.0001 lma 0.6839  cos_theta_tmp 0.7351  Epoch: 1   Global Step: 16750   Required: 40 hours
Training: 2025-11-30 22:03:14,600-Speed 1098.26 samples/sec   Loss 3.1945 target_logit_mean -0.0018 lma 0.6763  cos_theta_tmp 0.7408  Epoch: 1   Global Step: 16800   Required: 40 hours
Training: 2025-11-30 22:03:32,032-Speed 1101.52 samples/sec   Loss 3.2273 target_logit_mean -0.0007 lma 0.6886  cos_theta_tmp 0.7370  Epoch: 1   Global Step: 16850   Required: 40 hours
Training: 2025-11-30 22:03:49,458-Speed 1101.81 samples/sec   Loss 3.2444 target_logit_mean 0.0000 lma 0.6748  cos_theta_tmp 0.7325  Epoch: 1   Global Step: 16900   Required: 40 hours
Training: 2025-11-30 22:04:06,938-Speed 1098.42 samples/sec   Loss 3.2213 target_logit_mean 0.0026 lma 0.6868  cos_theta_tmp 0.7468  Epoch: 1   Global Step: 16950   Required: 40 hours
Training: 2025-11-30 22:04:24,532-Speed 1091.34 samples/sec   Loss 3.2548 target_logit_mean -0.0012 lma 0.6818  cos_theta_tmp 0.7327  Epoch: 1   Global Step: 17000   Required: 40 hours
Training: 2025-11-30 22:04:42,131-Speed 1090.98 samples/sec   Loss 3.2742 target_logit_mean -0.0005 lma 0.6809  cos_theta_tmp 0.7411  Epoch: 1   Global Step: 17050   Required: 40 hours
Training: 2025-11-30 22:04:59,753-Speed 1089.63 samples/sec   Loss 3.2097 target_logit_mean -0.0019 lma 0.6701  cos_theta_tmp 0.7393  Epoch: 1   Global Step: 17100   Required: 40 hours
Training: 2025-11-30 22:05:17,254-Speed 1097.17 samples/sec   Loss 3.1961 target_logit_mean -0.0013 lma 0.6846  cos_theta_tmp 0.7360  Epoch: 1   Global Step: 17150   Required: 40 hours
Training: 2025-11-30 22:05:34,668-Speed 1102.64 samples/sec   Loss 3.2966 target_logit_mean -0.0021 lma 0.6795  cos_theta_tmp 0.7385  Epoch: 1   Global Step: 17200   Required: 40 hours
Training: 2025-11-30 22:05:52,071-Speed 1103.27 samples/sec   Loss 3.1818 target_logit_mean 0.0014 lma 0.6797  cos_theta_tmp 0.7412  Epoch: 1   Global Step: 17250   Required: 40 hours
Training: 2025-11-30 22:06:09,493-Speed 1102.10 samples/sec   Loss 3.2466 target_logit_mean 0.0009 lma 0.6856  cos_theta_tmp 0.7431  Epoch: 1   Global Step: 17300   Required: 40 hours
Training: 2025-11-30 22:06:26,896-Speed 1103.31 samples/sec   Loss 3.1708 target_logit_mean 0.0013 lma 0.6693  cos_theta_tmp 0.7389  Epoch: 1   Global Step: 17350   Required: 40 hours
Training: 2025-11-30 22:06:44,313-Speed 1102.35 samples/sec   Loss 3.2388 target_logit_mean -0.0002 lma 0.6774  cos_theta_tmp 0.7381  Epoch: 1   Global Step: 17400   Required: 40 hours
Training: 2025-11-30 22:07:01,732-Speed 1102.29 samples/sec   Loss 3.2354 target_logit_mean -0.0008 lma 0.6876  cos_theta_tmp 0.7342  Epoch: 1   Global Step: 17450   Required: 40 hours
Training: 2025-11-30 22:07:19,135-Speed 1103.32 samples/sec   Loss 3.2237 target_logit_mean 0.0002 lma 0.6656  cos_theta_tmp 0.7363  Epoch: 1   Global Step: 17500   Required: 40 hours
Training: 2025-11-30 22:07:36,555-Speed 1102.21 samples/sec   Loss 3.2023 target_logit_mean 0.0010 lma 0.6768  cos_theta_tmp 0.7422  Epoch: 1   Global Step: 17550   Required: 40 hours
Training: 2025-11-30 22:07:53,959-Speed 1103.26 samples/sec   Loss 3.2754 target_logit_mean 0.0008 lma 0.6794  cos_theta_tmp 0.7315  Epoch: 1   Global Step: 17600   Required: 40 hours
Training: 2025-11-30 22:08:11,379-Speed 1102.23 samples/sec   Loss 3.2852 target_logit_mean 0.0026 lma 0.6679  cos_theta_tmp 0.7417  Epoch: 1   Global Step: 17650   Required: 40 hours
Training: 2025-11-30 22:08:28,780-Speed 1103.37 samples/sec   Loss 3.2371 target_logit_mean 0.0000 lma 0.6844  cos_theta_tmp 0.7451  Epoch: 1   Global Step: 17700   Required: 40 hours
Training: 2025-11-30 22:08:46,193-Speed 1102.67 samples/sec   Loss 3.1803 target_logit_mean 0.0000 lma 0.6803  cos_theta_tmp 0.7391  Epoch: 1   Global Step: 17750   Required: 40 hours
Training: 2025-11-30 22:09:03,612-Speed 1102.33 samples/sec   Loss 3.1650 target_logit_mean -0.0014 lma 0.6792  cos_theta_tmp 0.7380  Epoch: 1   Global Step: 17800   Required: 40 hours
Training: 2025-11-30 22:09:21,015-Speed 1103.24 samples/sec   Loss 3.1880 target_logit_mean -0.0009 lma 0.6652  cos_theta_tmp 0.7386  Epoch: 1   Global Step: 17850   Required: 40 hours
Training: 2025-11-30 22:09:38,445-Speed 1101.58 samples/sec   Loss 3.2392 target_logit_mean -0.0001 lma 0.6732  cos_theta_tmp 0.7361  Epoch: 1   Global Step: 17900   Required: 40 hours
Training: 2025-11-30 22:09:55,847-Speed 1103.42 samples/sec   Loss 3.2131 target_logit_mean 0.0000 lma 0.6701  cos_theta_tmp 0.7376  Epoch: 1   Global Step: 17950   Required: 40 hours
Training: 2025-11-30 22:10:13,261-Speed 1102.57 samples/sec   Loss 3.2216 target_logit_mean 0.0016 lma 0.6712  cos_theta_tmp 0.7376  Epoch: 1   Global Step: 18000   Required: 40 hours
Training: 2025-11-30 22:10:30,661-Speed 1103.48 samples/sec   Loss 3.1573 target_logit_mean 0.0012 lma 0.6819  cos_theta_tmp 0.7377  Epoch: 1   Global Step: 18050   Required: 40 hours
Training: 2025-11-30 22:10:48,076-Speed 1102.55 samples/sec   Loss 3.1966 target_logit_mean -0.0012 lma 0.6784  cos_theta_tmp 0.7407  Epoch: 1   Global Step: 18100   Required: 40 hours
Training: 2025-11-30 22:11:05,493-Speed 1102.39 samples/sec   Loss 3.2380 target_logit_mean 0.0021 lma 0.6764  cos_theta_tmp 0.7393  Epoch: 1   Global Step: 18150   Required: 40 hours
Training: 2025-11-30 22:11:22,894-Speed 1103.42 samples/sec   Loss 3.1658 target_logit_mean -0.0008 lma 0.6781  cos_theta_tmp 0.7449  Epoch: 1   Global Step: 18200   Required: 40 hours
Training: 2025-11-30 22:11:40,309-Speed 1102.54 samples/sec   Loss 3.1863 target_logit_mean 0.0039 lma 0.6702  cos_theta_tmp 0.7482  Epoch: 1   Global Step: 18250   Required: 40 hours
Training: 2025-11-30 22:11:57,709-Speed 1103.50 samples/sec   Loss 3.2519 target_logit_mean -0.0005 lma 0.6781  cos_theta_tmp 0.7394  Epoch: 1   Global Step: 18300   Required: 40 hours
Training: 2025-11-30 22:12:15,124-Speed 1102.56 samples/sec   Loss 3.2755 target_logit_mean -0.0012 lma 0.6725  cos_theta_tmp 0.7439  Epoch: 1   Global Step: 18350   Required: 39 hours
Training: 2025-11-30 22:12:32,540-Speed 1102.44 samples/sec   Loss 3.1950 target_logit_mean 0.0024 lma 0.6837  cos_theta_tmp 0.7466  Epoch: 1   Global Step: 18400   Required: 39 hours
Training: 2025-11-30 22:12:49,937-Speed 1103.71 samples/sec   Loss 3.1819 target_logit_mean 0.0006 lma 0.6719  cos_theta_tmp 0.7441  Epoch: 1   Global Step: 18450   Required: 39 hours
Training: 2025-11-30 22:13:07,351-Speed 1102.57 samples/sec   Loss 3.1937 target_logit_mean 0.0029 lma 0.6801  cos_theta_tmp 0.7449  Epoch: 1   Global Step: 18500   Required: 39 hours
Training: 2025-11-30 22:13:24,751-Speed 1103.51 samples/sec   Loss 3.2174 target_logit_mean 0.0007 lma 0.6855  cos_theta_tmp 0.7399  Epoch: 1   Global Step: 18550   Required: 39 hours
Training: 2025-11-30 22:13:42,166-Speed 1102.54 samples/sec   Loss 3.1842 target_logit_mean -0.0004 lma 0.6901  cos_theta_tmp 0.7416  Epoch: 1   Global Step: 18600   Required: 39 hours
Training: 2025-11-30 22:13:59,569-Speed 1103.25 samples/sec   Loss 3.2023 target_logit_mean 0.0027 lma 0.6862  cos_theta_tmp 0.7416  Epoch: 1   Global Step: 18650   Required: 39 hours
Training: 2025-11-30 22:14:16,989-Speed 1102.26 samples/sec   Loss 3.2425 target_logit_mean 0.0005 lma 0.6932  cos_theta_tmp 0.7440  Epoch: 1   Global Step: 18700   Required: 39 hours
Training: 2025-11-30 22:14:34,478-Speed 1097.88 samples/sec   Loss 3.1584 target_logit_mean 0.0019 lma 0.6888  cos_theta_tmp 0.7433  Epoch: 1   Global Step: 18750   Required: 39 hours
Training: 2025-11-30 22:14:51,979-Speed 1097.10 samples/sec   Loss 3.1896 target_logit_mean 0.0010 lma 0.6991  cos_theta_tmp 0.7463  Epoch: 1   Global Step: 18800   Required: 39 hours
Training: 2025-11-30 22:15:09,574-Speed 1091.24 samples/sec   Loss 3.1265 target_logit_mean -0.0016 lma 0.6652  cos_theta_tmp 0.7404  Epoch: 1   Global Step: 18850   Required: 39 hours
Training: 2025-11-30 22:15:27,015-Speed 1100.88 samples/sec   Loss 3.1895 target_logit_mean -0.0025 lma 0.6737  cos_theta_tmp 0.7383  Epoch: 1   Global Step: 18900   Required: 39 hours
Training: 2025-11-30 22:15:44,426-Speed 1102.81 samples/sec   Loss 3.2209 target_logit_mean 0.0003 lma 0.6708  cos_theta_tmp 0.7423  Epoch: 1   Global Step: 18950   Required: 39 hours
Training: 2025-11-30 22:16:01,829-Speed 1103.28 samples/sec   Loss 3.1531 target_logit_mean -0.0002 lma 0.6831  cos_theta_tmp 0.7427  Epoch: 1   Global Step: 19000   Required: 39 hours
Training: 2025-11-30 22:16:19,244-Speed 1102.58 samples/sec   Loss 3.2278 target_logit_mean -0.0013 lma 0.6747  cos_theta_tmp 0.7404  Epoch: 1   Global Step: 19050   Required: 39 hours
Training: 2025-11-30 22:16:36,657-Speed 1102.62 samples/sec   Loss 3.1817 target_logit_mean -0.0020 lma 0.6629  cos_theta_tmp 0.7356  Epoch: 1   Global Step: 19100   Required: 39 hours
Training: 2025-11-30 22:16:54,057-Speed 1103.52 samples/sec   Loss 3.2044 target_logit_mean 0.0026 lma 0.6880  cos_theta_tmp 0.7419  Epoch: 1   Global Step: 19150   Required: 39 hours
Training: 2025-11-30 22:17:11,470-Speed 1102.64 samples/sec   Loss 3.2571 target_logit_mean -0.0000 lma 0.6715  cos_theta_tmp 0.7418  Epoch: 1   Global Step: 19200   Required: 39 hours
Training: 2025-11-30 22:17:28,868-Speed 1103.62 samples/sec   Loss 3.1602 target_logit_mean 0.0006 lma 0.6823  cos_theta_tmp 0.7404  Epoch: 1   Global Step: 19250   Required: 39 hours
Training: 2025-11-30 22:17:46,283-Speed 1102.54 samples/sec   Loss 3.1510 target_logit_mean -0.0004 lma 0.6849  cos_theta_tmp 0.7489  Epoch: 1   Global Step: 19300   Required: 39 hours
Training: 2025-11-30 22:18:03,697-Speed 1102.60 samples/sec   Loss 3.1064 target_logit_mean 0.0001 lma 0.6888  cos_theta_tmp 0.7400  Epoch: 1   Global Step: 19350   Required: 39 hours
Training: 2025-11-30 22:18:21,096-Speed 1103.54 samples/sec   Loss 3.1502 target_logit_mean -0.0019 lma 0.6803  cos_theta_tmp 0.7410  Epoch: 1   Global Step: 19400   Required: 39 hours
Training: 2025-11-30 22:18:38,511-Speed 1102.57 samples/sec   Loss 3.0960 target_logit_mean -0.0004 lma 0.6852  cos_theta_tmp 0.7477  Epoch: 1   Global Step: 19450   Required: 39 hours
Training: 2025-11-30 22:18:55,912-Speed 1103.41 samples/sec   Loss 3.0708 target_logit_mean -0.0017 lma 0.6814  cos_theta_tmp 0.7445  Epoch: 1   Global Step: 19500   Required: 39 hours
Training: 2025-11-30 22:19:13,385-Speed 1098.90 samples/sec   Loss 3.1028 target_logit_mean 0.0008 lma 0.6880  cos_theta_tmp 0.7480  Epoch: 1   Global Step: 19550   Required: 39 hours
Training: 2025-11-30 22:19:30,844-Speed 1099.73 samples/sec   Loss 3.1193 target_logit_mean 0.0003 lma 0.6639  cos_theta_tmp 0.7451  Epoch: 1   Global Step: 19600   Required: 39 hours
Training: 2025-11-30 22:19:48,308-Speed 1099.43 samples/sec   Loss 3.0873 target_logit_mean -0.0008 lma 0.6827  cos_theta_tmp 0.7412  Epoch: 1   Global Step: 19650   Required: 39 hours
Training: 2025-11-30 22:20:05,767-Speed 1099.77 samples/sec   Loss 3.1323 target_logit_mean 0.0001 lma 0.6819  cos_theta_tmp 0.7453  Epoch: 1   Global Step: 19700   Required: 39 hours
Training: 2025-11-30 22:20:23,217-Speed 1100.31 samples/sec   Loss 3.0852 target_logit_mean 0.0025 lma 0.6969  cos_theta_tmp 0.7453  Epoch: 1   Global Step: 19750   Required: 39 hours
Training: 2025-11-30 22:20:40,677-Speed 1099.74 samples/sec   Loss 3.0832 target_logit_mean 0.0004 lma 0.6768  cos_theta_tmp 0.7416  Epoch: 1   Global Step: 19800   Required: 39 hours
Training: 2025-11-30 22:20:58,124-Speed 1100.47 samples/sec   Loss 3.1238 target_logit_mean -0.0011 lma 0.6849  cos_theta_tmp 0.7376  Epoch: 1   Global Step: 19850   Required: 39 hours
Training: 2025-11-30 22:21:15,583-Speed 1099.80 samples/sec   Loss 3.1004 target_logit_mean -0.0025 lma 0.6938  cos_theta_tmp 0.7349  Epoch: 1   Global Step: 19900   Required: 39 hours
Training: 2025-11-30 22:21:33,044-Speed 1099.60 samples/sec   Loss 3.1346 target_logit_mean 0.0002 lma 0.6799  cos_theta_tmp 0.7485  Epoch: 1   Global Step: 19950   Required: 39 hours
Training: 2025-11-30 22:21:50,491-Speed 1100.50 samples/sec   Loss 3.0979 target_logit_mean -0.0021 lma 0.6729  cos_theta_tmp 0.7360  Epoch: 1   Global Step: 20000   Required: 39 hours
Training: 2025-11-30 22:22:07,949-Speed 1099.82 samples/sec   Loss 3.0702 target_logit_mean -0.0014 lma 0.6648  cos_theta_tmp 0.7392  Epoch: 1   Global Step: 20050   Required: 39 hours
Training: 2025-11-30 22:22:25,394-Speed 1100.64 samples/sec   Loss 3.2072 target_logit_mean 0.0005 lma 0.6829  cos_theta_tmp 0.7392  Epoch: 1   Global Step: 20100   Required: 39 hours
Training: 2025-11-30 22:22:42,858-Speed 1099.46 samples/sec   Loss 3.0752 target_logit_mean -0.0027 lma 0.6891  cos_theta_tmp 0.7472  Epoch: 1   Global Step: 20150   Required: 39 hours
Training: 2025-11-30 22:23:00,311-Speed 1100.17 samples/sec   Loss 3.1562 target_logit_mean 0.0000 lma 0.6884  cos_theta_tmp 0.7486  Epoch: 1   Global Step: 20200   Required: 39 hours
Training: 2025-11-30 22:23:17,774-Speed 1099.51 samples/sec   Loss 3.1325 target_logit_mean 0.0020 lma 0.6737  cos_theta_tmp 0.7351  Epoch: 1   Global Step: 20250   Required: 39 hours
Training: 2025-11-30 22:23:35,231-Speed 1099.89 samples/sec   Loss 3.1277 target_logit_mean 0.0015 lma 0.6775  cos_theta_tmp 0.7484  Epoch: 1   Global Step: 20300   Required: 39 hours
Training: 2025-11-30 22:23:52,673-Speed 1100.83 samples/sec   Loss 3.1505 target_logit_mean -0.0026 lma 0.6969  cos_theta_tmp 0.7374  Epoch: 1   Global Step: 20350   Required: 39 hours
Training: 2025-11-30 22:24:10,128-Speed 1100.00 samples/sec   Loss 3.0855 target_logit_mean -0.0007 lma 0.6850  cos_theta_tmp 0.7421  Epoch: 1   Global Step: 20400   Required: 39 hours
Training: 2025-11-30 22:24:27,573-Speed 1100.62 samples/sec   Loss 3.0576 target_logit_mean 0.0000 lma 0.6897  cos_theta_tmp 0.7459  Epoch: 1   Global Step: 20450   Required: 39 hours
Training: 2025-11-30 22:24:45,039-Speed 1099.35 samples/sec   Loss 3.1245 target_logit_mean 0.0020 lma 0.6901  cos_theta_tmp 0.7480  Epoch: 1   Global Step: 20500   Required: 39 hours
Training: 2025-11-30 22:25:02,489-Speed 1100.30 samples/sec   Loss 3.0763 target_logit_mean 0.0017 lma 0.6901  cos_theta_tmp 0.7429  Epoch: 1   Global Step: 20550   Required: 39 hours
Training: 2025-11-30 22:25:19,937-Speed 1100.44 samples/sec   Loss 3.0948 target_logit_mean 0.0005 lma 0.6904  cos_theta_tmp 0.7394  Epoch: 1   Global Step: 20600   Required: 39 hours
Training: 2025-11-30 22:25:37,397-Speed 1099.71 samples/sec   Loss 3.1116 target_logit_mean 0.0003 lma 0.6821  cos_theta_tmp 0.7462  Epoch: 1   Global Step: 20650   Required: 39 hours
Training: 2025-11-30 22:25:54,845-Speed 1100.48 samples/sec   Loss 3.1384 target_logit_mean 0.0015 lma 0.6812  cos_theta_tmp 0.7441  Epoch: 1   Global Step: 20700   Required: 39 hours
Training: 2025-11-30 22:26:12,305-Speed 1099.66 samples/sec   Loss 3.0764 target_logit_mean 0.0009 lma 0.6712  cos_theta_tmp 0.7387  Epoch: 1   Global Step: 20750   Required: 39 hours
Training: 2025-11-30 22:26:29,753-Speed 1100.48 samples/sec   Loss 3.0869 target_logit_mean 0.0019 lma 0.6894  cos_theta_tmp 0.7450  Epoch: 1   Global Step: 20800   Required: 39 hours
Training: 2025-11-30 22:26:47,206-Speed 1100.16 samples/sec   Loss 3.0465 target_logit_mean 0.0008 lma 0.6873  cos_theta_tmp 0.7409  Epoch: 1   Global Step: 20850   Required: 39 hours
Training: 2025-11-30 22:27:04,661-Speed 1100.03 samples/sec   Loss 3.1474 target_logit_mean 0.0034 lma 0.6908  cos_theta_tmp 0.7509  Epoch: 1   Global Step: 20900   Required: 39 hours
Training: 2025-11-30 22:27:22,109-Speed 1100.40 samples/sec   Loss 3.1312 target_logit_mean 0.0015 lma 0.6715  cos_theta_tmp 0.7403  Epoch: 1   Global Step: 20950   Required: 39 hours
Training: 2025-11-30 22:27:39,569-Speed 1099.71 samples/sec   Loss 3.0578 target_logit_mean -0.0004 lma 0.6845  cos_theta_tmp 0.7476  Epoch: 1   Global Step: 21000   Required: 39 hours
Training: 2025-11-30 22:27:57,019-Speed 1100.31 samples/sec   Loss 3.1452 target_logit_mean 0.0002 lma 0.6836  cos_theta_tmp 0.7464  Epoch: 1   Global Step: 21050   Required: 39 hours
Training: 2025-11-30 22:28:14,481-Speed 1099.60 samples/sec   Loss 3.1134 target_logit_mean 0.0012 lma 0.6841  cos_theta_tmp 0.7507  Epoch: 1   Global Step: 21100   Required: 39 hours
Training: 2025-11-30 22:28:31,925-Speed 1100.68 samples/sec   Loss 3.0722 target_logit_mean 0.0007 lma 0.6798  cos_theta_tmp 0.7487  Epoch: 1   Global Step: 21150   Required: 39 hours
Training: 2025-11-30 22:28:49,383-Speed 1099.83 samples/sec   Loss 3.0290 target_logit_mean -0.0008 lma 0.6890  cos_theta_tmp 0.7510  Epoch: 1   Global Step: 21200   Required: 39 hours
Training: 2025-11-30 22:29:06,841-Speed 1099.85 samples/sec   Loss 3.0462 target_logit_mean -0.0040 lma 0.6759  cos_theta_tmp 0.7380  Epoch: 1   Global Step: 21250   Required: 39 hours
Training: 2025-11-30 22:29:24,293-Speed 1100.18 samples/sec   Loss 3.1272 target_logit_mean -0.0024 lma 0.6670  cos_theta_tmp 0.7361  Epoch: 1   Global Step: 21300   Required: 39 hours
Training: 2025-11-30 22:29:41,754-Speed 1099.63 samples/sec   Loss 3.0722 target_logit_mean -0.0016 lma 0.6642  cos_theta_tmp 0.7426  Epoch: 1   Global Step: 21350   Required: 39 hours
Training: 2025-11-30 22:29:59,205-Speed 1100.27 samples/sec   Loss 3.0531 target_logit_mean 0.0006 lma 0.6833  cos_theta_tmp 0.7378  Epoch: 1   Global Step: 21400   Required: 39 hours
Training: 2025-11-30 22:30:16,669-Speed 1099.42 samples/sec   Loss 3.0314 target_logit_mean -0.0035 lma 0.6875  cos_theta_tmp 0.7440  Epoch: 1   Global Step: 21450   Required: 39 hours
Training: 2025-11-30 22:30:34,138-Speed 1099.15 samples/sec   Loss 3.0853 target_logit_mean -0.0001 lma 0.6828  cos_theta_tmp 0.7414  Epoch: 1   Global Step: 21500   Required: 39 hours
Training: 2025-11-30 22:30:51,591-Speed 1100.14 samples/sec   Loss 3.0945 target_logit_mean 0.0015 lma 0.6730  cos_theta_tmp 0.7412  Epoch: 1   Global Step: 21550   Required: 39 hours
Training: 2025-11-30 22:31:09,051-Speed 1099.66 samples/sec   Loss 3.0480 target_logit_mean 0.0009 lma 0.6622  cos_theta_tmp 0.7433  Epoch: 1   Global Step: 21600   Required: 39 hours
Training: 2025-11-30 22:31:26,502-Speed 1100.28 samples/sec   Loss 3.0917 target_logit_mean -0.0032 lma 0.6822  cos_theta_tmp 0.7463  Epoch: 1   Global Step: 21650   Required: 39 hours
Training: 2025-11-30 22:31:43,981-Speed 1098.47 samples/sec   Loss 3.0796 target_logit_mean -0.0001 lma 0.6859  cos_theta_tmp 0.7403  Epoch: 1   Global Step: 21700   Required: 39 hours
Training: 2025-11-30 22:32:01,293-Speed 1109.13 samples/sec   Loss 3.0206 target_logit_mean 0.0004 lma 0.6814  cos_theta_tmp 0.7424  Epoch: 1   Global Step: 21750   Required: 39 hours
Training: 2025-11-30 22:32:18,933-Speed 1088.49 samples/sec   Loss 3.0656 target_logit_mean -0.0011 lma 0.6709  cos_theta_tmp 0.7479  Epoch: 1   Global Step: 21800   Required: 39 hours
Training: 2025-11-30 22:32:36,439-Speed 1096.78 samples/sec   Loss 3.0289 target_logit_mean -0.0006 lma 0.6812  cos_theta_tmp 0.7440  Epoch: 1   Global Step: 21850   Required: 39 hours
Training: 2025-11-30 22:32:53,857-Speed 1102.34 samples/sec   Loss 3.0025 target_logit_mean 0.0008 lma 0.6786  cos_theta_tmp 0.7469  Epoch: 1   Global Step: 21900   Required: 39 hours
Training: 2025-11-30 22:33:11,283-Speed 1101.84 samples/sec   Loss 3.0492 target_logit_mean -0.0023 lma 0.6760  cos_theta_tmp 0.7412  Epoch: 1   Global Step: 21950   Required: 39 hours
Training: 2025-11-30 22:33:28,696-Speed 1102.68 samples/sec   Loss 3.0577 target_logit_mean -0.0006 lma 0.6825  cos_theta_tmp 0.7465  Epoch: 1   Global Step: 22000   Required: 39 hours
Training: 2025-11-30 22:33:46,089-Speed 1103.91 samples/sec   Loss 3.0464 target_logit_mean -0.0016 lma 0.6883  cos_theta_tmp 0.7425  Epoch: 1   Global Step: 22050   Required: 39 hours
Training: 2025-11-30 22:34:03,449-Speed 1106.01 samples/sec   Loss 2.9653 target_logit_mean 0.0005 lma 0.6906  cos_theta_tmp 0.7478  Epoch: 1   Global Step: 22100   Required: 39 hours
Training: 2025-11-30 22:34:20,781-Speed 1107.85 samples/sec   Loss 3.0896 target_logit_mean -0.0009 lma 0.6765  cos_theta_tmp 0.7435  Epoch: 1   Global Step: 22150   Required: 39 hours
Training: 2025-11-30 22:34:38,252-Speed 1098.99 samples/sec   Loss 3.0416 target_logit_mean 0.0004 lma 0.6982  cos_theta_tmp 0.7498  Epoch: 1   Global Step: 22200   Required: 39 hours
Training: 2025-11-30 22:34:55,943-Speed 1085.33 samples/sec   Loss 2.9839 target_logit_mean 0.0012 lma 0.6878  cos_theta_tmp 0.7467  Epoch: 1   Global Step: 22250   Required: 39 hours
Training: 2025-11-30 22:35:13,549-Speed 1090.59 samples/sec   Loss 3.0186 target_logit_mean 0.0026 lma 0.6789  cos_theta_tmp 0.7464  Epoch: 1   Global Step: 22300   Required: 39 hours
Training: 2025-11-30 22:35:30,995-Speed 1100.58 samples/sec   Loss 3.0304 target_logit_mean -0.0027 lma 0.6844  cos_theta_tmp 0.7413  Epoch: 1   Global Step: 22350   Required: 39 hours
Training: 2025-11-30 22:35:48,441-Speed 1100.60 samples/sec   Loss 3.0557 target_logit_mean -0.0020 lma 0.6700  cos_theta_tmp 0.7427  Epoch: 1   Global Step: 22400   Required: 39 hours
Training: 2025-11-30 22:36:05,895-Speed 1100.06 samples/sec   Loss 3.0165 target_logit_mean 0.0003 lma 0.6780  cos_theta_tmp 0.7460  Epoch: 1   Global Step: 22450   Required: 39 hours
Training: 2025-11-30 22:36:23,354-Speed 1099.77 samples/sec   Loss 3.0459 target_logit_mean 0.0002 lma 0.6818  cos_theta_tmp 0.7476  Epoch: 1   Global Step: 22500   Required: 38 hours
Training: 2025-11-30 22:36:40,793-Speed 1100.99 samples/sec   Loss 3.0481 target_logit_mean 0.0006 lma 0.6877  cos_theta_tmp 0.7449  Epoch: 1   Global Step: 22550   Required: 38 hours
Training: 2025-11-30 22:36:58,186-Speed 1103.96 samples/sec   Loss 3.0829 target_logit_mean 0.0009 lma 0.6824  cos_theta_tmp 0.7423  Epoch: 1   Global Step: 22600   Required: 38 hours
Training: 2025-11-30 22:37:15,499-Speed 1109.02 samples/sec   Loss 3.0545 target_logit_mean 0.0032 lma 0.6977  cos_theta_tmp 0.7515  Epoch: 1   Global Step: 22650   Required: 38 hours
Training: 2025-11-30 22:37:32,907-Speed 1102.96 samples/sec   Loss 3.0432 target_logit_mean 0.0009 lma 0.6861  cos_theta_tmp 0.7443  Epoch: 1   Global Step: 22700   Required: 38 hours
Training: 2025-11-30 22:37:50,571-Speed 1086.98 samples/sec   Loss 2.9742 target_logit_mean 0.0023 lma 0.6946  cos_theta_tmp 0.7522  Epoch: 1   Global Step: 22750   Required: 38 hours
Training: 2025-11-30 22:38:08,200-Speed 1089.19 samples/sec   Loss 3.0073 target_logit_mean -0.0005 lma 0.6757  cos_theta_tmp 0.7445  Epoch: 1   Global Step: 22800   Required: 38 hours
Training: 2025-11-30 22:38:25,624-Speed 1101.93 samples/sec   Loss 3.0338 target_logit_mean 0.0012 lma 0.6846  cos_theta_tmp 0.7471  Epoch: 1   Global Step: 22850   Required: 38 hours
Training: 2025-11-30 22:38:43,096-Speed 1098.95 samples/sec   Loss 2.9991 target_logit_mean 0.0002 lma 0.6802  cos_theta_tmp 0.7475  Epoch: 1   Global Step: 22900   Required: 38 hours
Training: 2025-11-30 22:39:00,479-Speed 1104.56 samples/sec   Loss 3.0696 target_logit_mean -0.0016 lma 0.6719  cos_theta_tmp 0.7383  Epoch: 1   Global Step: 22950   Required: 38 hours
Training: 2025-11-30 22:39:17,971-Speed 1097.71 samples/sec   Loss 3.0535 target_logit_mean 0.0002 lma 0.6827  cos_theta_tmp 0.7443  Epoch: 1   Global Step: 23000   Required: 38 hours
Training: 2025-11-30 22:39:35,427-Speed 1099.90 samples/sec   Loss 3.0789 target_logit_mean 0.0005 lma 0.6857  cos_theta_tmp 0.7496  Epoch: 1   Global Step: 23050   Required: 38 hours
Training: 2025-11-30 22:39:52,828-Speed 1103.47 samples/sec   Loss 2.9937 target_logit_mean -0.0010 lma 0.6758  cos_theta_tmp 0.7472  Epoch: 1   Global Step: 23100   Required: 38 hours
Training: 2025-11-30 22:40:10,245-Speed 1102.41 samples/sec   Loss 3.0123 target_logit_mean -0.0001 lma 0.6893  cos_theta_tmp 0.7468  Epoch: 1   Global Step: 23150   Required: 38 hours
Training: 2025-11-30 22:40:27,728-Speed 1098.21 samples/sec   Loss 3.0193 target_logit_mean -0.0004 lma 0.6806  cos_theta_tmp 0.7487  Epoch: 1   Global Step: 23200   Required: 38 hours
Training: 2025-11-30 22:40:45,224-Speed 1097.43 samples/sec   Loss 3.0128 target_logit_mean 0.0017 lma 0.6776  cos_theta_tmp 0.7501  Epoch: 1   Global Step: 23250   Required: 38 hours
Training: 2025-11-30 22:41:02,653-Speed 1101.68 samples/sec   Loss 3.0731 target_logit_mean 0.0026 lma 0.6839  cos_theta_tmp 0.7437  Epoch: 1   Global Step: 23300   Required: 38 hours
Training: 2025-11-30 22:41:20,076-Speed 1102.04 samples/sec   Loss 2.9787 target_logit_mean 0.0007 lma 0.6827  cos_theta_tmp 0.7434  Epoch: 1   Global Step: 23350   Required: 38 hours
Training: 2025-11-30 22:41:37,501-Speed 1101.91 samples/sec   Loss 2.9871 target_logit_mean -0.0013 lma 0.6875  cos_theta_tmp 0.7405  Epoch: 1   Global Step: 23400   Required: 38 hours
Training: 2025-11-30 22:41:54,924-Speed 1102.02 samples/sec   Loss 3.0120 target_logit_mean 0.0019 lma 0.6769  cos_theta_tmp 0.7540  Epoch: 1   Global Step: 23450   Required: 38 hours
Training: 2025-11-30 22:42:12,351-Speed 1101.76 samples/sec   Loss 2.9518 target_logit_mean 0.0007 lma 0.6839  cos_theta_tmp 0.7504  Epoch: 1   Global Step: 23500   Required: 38 hours
Training: 2025-11-30 22:42:29,773-Speed 1102.10 samples/sec   Loss 2.9629 target_logit_mean 0.0002 lma 0.6895  cos_theta_tmp 0.7462  Epoch: 1   Global Step: 23550   Required: 38 hours
Training: 2025-11-30 22:42:47,201-Speed 1101.73 samples/sec   Loss 2.9932 target_logit_mean -0.0014 lma 0.6933  cos_theta_tmp 0.7429  Epoch: 1   Global Step: 23600   Required: 38 hours
Training: 2025-11-30 22:43:04,630-Speed 1101.64 samples/sec   Loss 2.9244 target_logit_mean -0.0006 lma 0.6755  cos_theta_tmp 0.7501  Epoch: 1   Global Step: 23650   Required: 38 hours
Training: 2025-11-30 22:43:22,059-Speed 1101.70 samples/sec   Loss 2.9959 target_logit_mean 0.0029 lma 0.6778  cos_theta_tmp 0.7464  Epoch: 1   Global Step: 23700   Required: 38 hours
Training: 2025-11-30 22:43:39,484-Speed 1101.89 samples/sec   Loss 2.9359 target_logit_mean -0.0030 lma 0.6710  cos_theta_tmp 0.7438  Epoch: 1   Global Step: 23750   Required: 38 hours
Training: 2025-11-30 22:43:56,908-Speed 1101.97 samples/sec   Loss 2.9224 target_logit_mean 0.0014 lma 0.6854  cos_theta_tmp 0.7483  Epoch: 1   Global Step: 23800   Required: 38 hours
Training: 2025-11-30 22:44:14,348-Speed 1100.98 samples/sec   Loss 3.0054 target_logit_mean 0.0025 lma 0.6828  cos_theta_tmp 0.7435  Epoch: 1   Global Step: 23850   Required: 38 hours
Training: 2025-11-30 22:44:31,837-Speed 1097.81 samples/sec   Loss 2.9686 target_logit_mean -0.0001 lma 0.6766  cos_theta_tmp 0.7460  Epoch: 1   Global Step: 23900   Required: 38 hours
Training: 2025-11-30 22:44:49,350-Speed 1096.39 samples/sec   Loss 2.9735 target_logit_mean 0.0007 lma 0.6791  cos_theta_tmp 0.7464  Epoch: 1   Global Step: 23950   Required: 38 hours
Training: 2025-11-30 22:45:06,795-Speed 1100.62 samples/sec   Loss 2.9979 target_logit_mean -0.0017 lma 0.6817  cos_theta_tmp 0.7450  Epoch: 1   Global Step: 24000   Required: 38 hours
Training: 2025-11-30 22:45:24,244-Speed 1100.42 samples/sec   Loss 2.9688 target_logit_mean 0.0003 lma 0.6806  cos_theta_tmp 0.7460  Epoch: 1   Global Step: 24050   Required: 38 hours
Training: 2025-11-30 22:45:41,690-Speed 1100.58 samples/sec   Loss 2.9949 target_logit_mean -0.0038 lma 0.6796  cos_theta_tmp 0.7469  Epoch: 1   Global Step: 24100   Required: 38 hours
Training: 2025-11-30 22:45:59,142-Speed 1100.17 samples/sec   Loss 3.0444 target_logit_mean 0.0017 lma 0.6821  cos_theta_tmp 0.7525  Epoch: 1   Global Step: 24150   Required: 38 hours
Training: 2025-11-30 22:46:16,592-Speed 1100.35 samples/sec   Loss 2.9545 target_logit_mean 0.0025 lma 0.6941  cos_theta_tmp 0.7515  Epoch: 1   Global Step: 24200   Required: 38 hours
Training: 2025-11-30 22:46:34,038-Speed 1100.55 samples/sec   Loss 2.9959 target_logit_mean 0.0005 lma 0.6717  cos_theta_tmp 0.7422  Epoch: 1   Global Step: 24250   Required: 38 hours
Training: 2025-11-30 22:46:51,492-Speed 1100.11 samples/sec   Loss 3.0113 target_logit_mean 0.0009 lma 0.6824  cos_theta_tmp 0.7443  Epoch: 1   Global Step: 24300   Required: 38 hours
Training: 2025-11-30 22:47:08,937-Speed 1100.59 samples/sec   Loss 2.9453 target_logit_mean -0.0017 lma 0.6718  cos_theta_tmp 0.7477  Epoch: 1   Global Step: 24350   Required: 38 hours
Training: 2025-11-30 22:47:26,410-Speed 1098.88 samples/sec   Loss 2.9939 target_logit_mean 0.0011 lma 0.6800  cos_theta_tmp 0.7459  Epoch: 1   Global Step: 24400   Required: 38 hours
Training: 2025-11-30 22:47:43,871-Speed 1099.68 samples/sec   Loss 3.0472 target_logit_mean -0.0006 lma 0.6787  cos_theta_tmp 0.7394  Epoch: 1   Global Step: 24450   Required: 38 hours
Training: 2025-11-30 22:48:01,312-Speed 1100.86 samples/sec   Loss 2.9580 target_logit_mean 0.0017 lma 0.6958  cos_theta_tmp 0.7492  Epoch: 1   Global Step: 24500   Required: 38 hours
Training: 2025-11-30 22:48:18,675-Speed 1105.86 samples/sec   Loss 2.9565 target_logit_mean 0.0003 lma 0.6877  cos_theta_tmp 0.7489  Epoch: 1   Global Step: 24550   Required: 38 hours
Training: 2025-11-30 22:48:36,129-Speed 1100.11 samples/sec   Loss 2.9868 target_logit_mean 0.0005 lma 0.6897  cos_theta_tmp 0.7476  Epoch: 1   Global Step: 24600   Required: 38 hours
Training: 2025-11-30 22:48:53,559-Speed 1101.58 samples/sec   Loss 2.9597 target_logit_mean 0.0014 lma 0.6762  cos_theta_tmp 0.7473  Epoch: 1   Global Step: 24650   Required: 38 hours
Training: 2025-11-30 22:49:10,986-Speed 1101.79 samples/sec   Loss 2.9735 target_logit_mean 0.0006 lma 0.6815  cos_theta_tmp 0.7485  Epoch: 1   Global Step: 24700   Required: 38 hours
Training: 2025-11-30 22:49:28,410-Speed 1101.94 samples/sec   Loss 3.0007 target_logit_mean -0.0006 lma 0.6756  cos_theta_tmp 0.7450  Epoch: 1   Global Step: 24750   Required: 38 hours
Training: 2025-11-30 22:49:45,865-Speed 1100.01 samples/sec   Loss 2.9093 target_logit_mean 0.0010 lma 0.6814  cos_theta_tmp 0.7535  Epoch: 1   Global Step: 24800   Required: 38 hours
Training: 2025-11-30 22:50:03,300-Speed 1101.27 samples/sec   Loss 3.0069 target_logit_mean 0.0022 lma 0.6844  cos_theta_tmp 0.7511  Epoch: 1   Global Step: 24850   Required: 38 hours
Training: 2025-11-30 22:50:20,758-Speed 1099.82 samples/sec   Loss 3.0305 target_logit_mean 0.0025 lma 0.6856  cos_theta_tmp 0.7500  Epoch: 1   Global Step: 24900   Required: 38 hours
Training: 2025-11-30 22:50:38,179-Speed 1102.15 samples/sec   Loss 2.9769 target_logit_mean -0.0045 lma 0.6757  cos_theta_tmp 0.7432  Epoch: 1   Global Step: 24950   Required: 38 hours
Training: 2025-11-30 22:50:55,606-Speed 1101.81 samples/sec   Loss 3.0419 target_logit_mean 0.0007 lma 0.7053  cos_theta_tmp 0.7469  Epoch: 1   Global Step: 25000   Required: 38 hours
Training: 2025-11-30 22:51:13,032-Speed 1101.82 samples/sec   Loss 2.9604 target_logit_mean 0.0004 lma 0.6878  cos_theta_tmp 0.7450  Epoch: 1   Global Step: 25050   Required: 38 hours
Training: 2025-11-30 22:51:30,457-Speed 1101.92 samples/sec   Loss 2.9675 target_logit_mean -0.0012 lma 0.6822  cos_theta_tmp 0.7441  Epoch: 1   Global Step: 25100   Required: 38 hours
Training: 2025-11-30 22:51:47,881-Speed 1101.95 samples/sec   Loss 2.9334 target_logit_mean 0.0020 lma 0.6858  cos_theta_tmp 0.7486  Epoch: 1   Global Step: 25150   Required: 38 hours
Training: 2025-11-30 22:52:05,308-Speed 1101.76 samples/sec   Loss 2.9133 target_logit_mean 0.0005 lma 0.6868  cos_theta_tmp 0.7475  Epoch: 1   Global Step: 25200   Required: 38 hours
Training: 2025-11-30 22:52:22,741-Speed 1101.43 samples/sec   Loss 3.0123 target_logit_mean -0.0032 lma 0.6843  cos_theta_tmp 0.7494  Epoch: 1   Global Step: 25250   Required: 38 hours
Training: 2025-11-30 22:52:40,166-Speed 1101.90 samples/sec   Loss 2.9686 target_logit_mean -0.0030 lma 0.6842  cos_theta_tmp 0.7503  Epoch: 1   Global Step: 25300   Required: 38 hours
Training: 2025-11-30 22:52:57,591-Speed 1101.92 samples/sec   Loss 3.0022 target_logit_mean 0.0017 lma 0.6846  cos_theta_tmp 0.7525  Epoch: 1   Global Step: 25350   Required: 38 hours
Training: 2025-11-30 22:53:15,012-Speed 1102.11 samples/sec   Loss 2.9783 target_logit_mean 0.0000 lma 0.6838  cos_theta_tmp 0.7460  Epoch: 1   Global Step: 25400   Required: 38 hours
Training: 2025-11-30 22:53:32,441-Speed 1101.69 samples/sec   Loss 3.0048 target_logit_mean 0.0014 lma 0.6793  cos_theta_tmp 0.7451  Epoch: 1   Global Step: 25450   Required: 38 hours
Training: 2025-11-30 22:53:49,862-Speed 1102.14 samples/sec   Loss 2.9738 target_logit_mean 0.0021 lma 0.6888  cos_theta_tmp 0.7533  Epoch: 1   Global Step: 25500   Required: 38 hours
Training: 2025-11-30 22:54:07,284-Speed 1102.09 samples/sec   Loss 2.9674 target_logit_mean 0.0010 lma 0.6843  cos_theta_tmp 0.7414  Epoch: 1   Global Step: 25550   Required: 38 hours
Training: 2025-11-30 22:54:24,706-Speed 1102.11 samples/sec   Loss 2.9576 target_logit_mean 0.0006 lma 0.6911  cos_theta_tmp 0.7481  Epoch: 1   Global Step: 25600   Required: 38 hours
Training: 2025-11-30 22:54:42,132-Speed 1101.87 samples/sec   Loss 2.9901 target_logit_mean -0.0004 lma 0.6765  cos_theta_tmp 0.7462  Epoch: 1   Global Step: 25650   Required: 38 hours
Training: 2025-11-30 22:54:59,553-Speed 1102.14 samples/sec   Loss 2.9740 target_logit_mean -0.0012 lma 0.6736  cos_theta_tmp 0.7420  Epoch: 1   Global Step: 25700   Required: 38 hours
Training: 2025-11-30 22:55:16,975-Speed 1102.10 samples/sec   Loss 2.9813 target_logit_mean -0.0012 lma 0.6663  cos_theta_tmp 0.7414  Epoch: 1   Global Step: 25750   Required: 38 hours
Training: 2025-11-30 22:55:34,399-Speed 1101.93 samples/sec   Loss 2.9088 target_logit_mean 0.0012 lma 0.6933  cos_theta_tmp 0.7515  Epoch: 1   Global Step: 25800   Required: 38 hours
Training: 2025-11-30 22:55:51,826-Speed 1101.82 samples/sec   Loss 2.9555 target_logit_mean 0.0016 lma 0.6702  cos_theta_tmp 0.7448  Epoch: 1   Global Step: 25850   Required: 38 hours
Training: 2025-11-30 22:56:09,251-Speed 1101.88 samples/sec   Loss 2.9038 target_logit_mean -0.0010 lma 0.6724  cos_theta_tmp 0.7456  Epoch: 1   Global Step: 25900   Required: 38 hours
Training: 2025-11-30 22:56:26,675-Speed 1101.98 samples/sec   Loss 2.9739 target_logit_mean 0.0025 lma 0.6795  cos_theta_tmp 0.7461  Epoch: 1   Global Step: 25950   Required: 38 hours
Training: 2025-11-30 22:56:44,100-Speed 1101.93 samples/sec   Loss 2.9386 target_logit_mean 0.0003 lma 0.6816  cos_theta_tmp 0.7436  Epoch: 1   Global Step: 26000   Required: 38 hours
Training: 2025-11-30 22:57:01,520-Speed 1102.24 samples/sec   Loss 2.9759 target_logit_mean -0.0009 lma 0.6685  cos_theta_tmp 0.7432  Epoch: 1   Global Step: 26050   Required: 38 hours
Training: 2025-11-30 22:57:18,939-Speed 1102.26 samples/sec   Loss 2.9444 target_logit_mean 0.0001 lma 0.6827  cos_theta_tmp 0.7510  Epoch: 1   Global Step: 26100   Required: 38 hours
Training: 2025-11-30 22:57:36,361-Speed 1102.10 samples/sec   Loss 2.9206 target_logit_mean -0.0015 lma 0.6750  cos_theta_tmp 0.7522  Epoch: 1   Global Step: 26150   Required: 38 hours
Training: 2025-11-30 22:57:53,785-Speed 1101.98 samples/sec   Loss 2.8807 target_logit_mean -0.0003 lma 0.6743  cos_theta_tmp 0.7499  Epoch: 1   Global Step: 26200   Required: 38 hours
Training: 2025-11-30 22:58:11,210-Speed 1101.91 samples/sec   Loss 3.0137 target_logit_mean 0.0008 lma 0.6794  cos_theta_tmp 0.7497  Epoch: 1   Global Step: 26250   Required: 38 hours
Training: 2025-11-30 22:58:28,631-Speed 1102.12 samples/sec   Loss 2.9093 target_logit_mean 0.0018 lma 0.6686  cos_theta_tmp 0.7496  Epoch: 1   Global Step: 26300   Required: 38 hours
Training: 2025-11-30 22:58:46,053-Speed 1102.09 samples/sec   Loss 2.8409 target_logit_mean -0.0015 lma 0.6775  cos_theta_tmp 0.7495  Epoch: 1   Global Step: 26350   Required: 38 hours
Training: 2025-11-30 22:59:03,480-Speed 1101.82 samples/sec   Loss 2.8771 target_logit_mean -0.0003 lma 0.6742  cos_theta_tmp 0.7471  Epoch: 1   Global Step: 26400   Required: 38 hours
Training: 2025-11-30 22:59:20,910-Speed 1101.60 samples/sec   Loss 2.9822 target_logit_mean -0.0011 lma 0.6825  cos_theta_tmp 0.7445  Epoch: 1   Global Step: 26450   Required: 38 hours
Training: 2025-11-30 22:59:38,334-Speed 1101.93 samples/sec   Loss 2.9119 target_logit_mean 0.0027 lma 0.6898  cos_theta_tmp 0.7511  Epoch: 1   Global Step: 26500   Required: 38 hours
Training: 2025-11-30 22:59:55,765-Speed 1101.54 samples/sec   Loss 2.9790 target_logit_mean 0.0002 lma 0.6844  cos_theta_tmp 0.7478  Epoch: 1   Global Step: 26550   Required: 38 hours
Training: 2025-11-30 23:00:13,187-Speed 1102.14 samples/sec   Loss 2.9656 target_logit_mean -0.0012 lma 0.6850  cos_theta_tmp 0.7467  Epoch: 1   Global Step: 26600   Required: 38 hours
Training: 2025-11-30 23:00:30,611-Speed 1101.98 samples/sec   Loss 2.9868 target_logit_mean 0.0000 lma 0.6852  cos_theta_tmp 0.7496  Epoch: 1   Global Step: 26650   Required: 38 hours
Training: 2025-11-30 23:00:48,037-Speed 1101.84 samples/sec   Loss 2.8832 target_logit_mean 0.0012 lma 0.6815  cos_theta_tmp 0.7546  Epoch: 1   Global Step: 26700   Required: 38 hours
Training: 2025-11-30 23:01:05,461-Speed 1101.97 samples/sec   Loss 2.8794 target_logit_mean 0.0036 lma 0.6944  cos_theta_tmp 0.7531  Epoch: 1   Global Step: 26750   Required: 38 hours
Training: 2025-11-30 23:01:22,887-Speed 1101.85 samples/sec   Loss 2.9010 target_logit_mean 0.0004 lma 0.6780  cos_theta_tmp 0.7443  Epoch: 1   Global Step: 26800   Required: 38 hours
Training: 2025-11-30 23:01:40,312-Speed 1101.92 samples/sec   Loss 2.9643 target_logit_mean -0.0012 lma 0.6866  cos_theta_tmp 0.7468  Epoch: 1   Global Step: 26850   Required: 38 hours
Training: 2025-11-30 23:01:57,693-Speed 1104.71 samples/sec   Loss 2.9143 target_logit_mean 0.0010 lma 0.6777  cos_theta_tmp 0.7519  Epoch: 1   Global Step: 26900   Required: 38 hours
Training: 2025-11-30 23:02:15,143-Speed 1100.27 samples/sec   Loss 3.0165 target_logit_mean -0.0006 lma 0.6770  cos_theta_tmp 0.7426  Epoch: 1   Global Step: 26950   Required: 38 hours
Training: 2025-11-30 23:02:32,801-Speed 1087.38 samples/sec   Loss 2.8686 target_logit_mean -0.0008 lma 0.6944  cos_theta_tmp 0.7456  Epoch: 1   Global Step: 27000   Required: 38 hours
Training: 2025-11-30 23:02:50,235-Speed 1101.37 samples/sec   Loss 2.9630 target_logit_mean -0.0010 lma 0.6583  cos_theta_tmp 0.7428  Epoch: 1   Global Step: 27050   Required: 38 hours
Training: 2025-11-30 23:03:07,661-Speed 1101.82 samples/sec   Loss 2.9666 target_logit_mean -0.0005 lma 0.6806  cos_theta_tmp 0.7455  Epoch: 1   Global Step: 27100   Required: 38 hours
Training: 2025-11-30 23:03:25,089-Speed 1101.74 samples/sec   Loss 2.8975 target_logit_mean -0.0011 lma 0.6746  cos_theta_tmp 0.7458  Epoch: 1   Global Step: 27150   Required: 38 hours
Training: 2025-11-30 23:03:42,513-Speed 1101.94 samples/sec   Loss 2.9834 target_logit_mean -0.0005 lma 0.6807  cos_theta_tmp 0.7450  Epoch: 1   Global Step: 27200   Required: 38 hours
Training: 2025-11-30 23:03:59,938-Speed 1101.92 samples/sec   Loss 2.8648 target_logit_mean 0.0004 lma 0.6842  cos_theta_tmp 0.7532  Epoch: 1   Global Step: 27250   Required: 38 hours
Training: 2025-11-30 23:04:17,362-Speed 1101.93 samples/sec   Loss 2.9071 target_logit_mean 0.0004 lma 0.6738  cos_theta_tmp 0.7508  Epoch: 1   Global Step: 27300   Required: 38 hours
Training: 2025-11-30 23:04:34,815-Speed 1100.18 samples/sec   Loss 2.9315 target_logit_mean 0.0003 lma 0.6966  cos_theta_tmp 0.7507  Epoch: 1   Global Step: 27350   Required: 38 hours
Training: 2025-11-30 23:04:52,226-Speed 1102.75 samples/sec   Loss 2.9535 target_logit_mean -0.0004 lma 0.6743  cos_theta_tmp 0.7435  Epoch: 1   Global Step: 27400   Required: 38 hours
Training: 2025-11-30 23:05:09,753-Speed 1095.50 samples/sec   Loss 2.9022 target_logit_mean 0.0009 lma 0.6752  cos_theta_tmp 0.7527  Epoch: 1   Global Step: 27450   Required: 38 hours
Training: 2025-11-30 23:05:27,357-Speed 1090.70 samples/sec   Loss 2.9335 target_logit_mean -0.0004 lma 0.6884  cos_theta_tmp 0.7412  Epoch: 1   Global Step: 27500   Required: 38 hours
Training: 2025-11-30 23:05:44,904-Speed 1094.21 samples/sec   Loss 2.9111 target_logit_mean -0.0022 lma 0.6703  cos_theta_tmp 0.7479  Epoch: 1   Global Step: 27550   Required: 38 hours
Training: 2025-11-30 23:06:02,348-Speed 1100.70 samples/sec   Loss 2.8880 target_logit_mean 0.0020 lma 0.6753  cos_theta_tmp 0.7579  Epoch: 1   Global Step: 27600   Required: 38 hours
Training: 2025-11-30 23:06:19,657-Speed 1109.30 samples/sec   Loss 2.8233 target_logit_mean -0.0006 lma 0.6774  cos_theta_tmp 0.7544  Epoch: 1   Global Step: 27650   Required: 38 hours
Training: 2025-11-30 23:06:37,205-Speed 1094.19 samples/sec   Loss 2.9303 target_logit_mean -0.0000 lma 0.6755  cos_theta_tmp 0.7512  Epoch: 1   Global Step: 27700   Required: 37 hours
Training: 2025-11-30 23:06:54,717-Speed 1096.43 samples/sec   Loss 2.8414 target_logit_mean -0.0018 lma 0.6867  cos_theta_tmp 0.7469  Epoch: 1   Global Step: 27750   Required: 37 hours
Training: 2025-11-30 23:07:12,220-Speed 1096.99 samples/sec   Loss 2.9709 target_logit_mean -0.0003 lma 0.6796  cos_theta_tmp 0.7513  Epoch: 1   Global Step: 27800   Required: 37 hours
Training: 2025-11-30 23:07:29,768-Speed 1094.21 samples/sec   Loss 2.9459 target_logit_mean -0.0010 lma 0.6863  cos_theta_tmp 0.7457  Epoch: 1   Global Step: 27850   Required: 37 hours
Training: 2025-11-30 23:07:47,318-Speed 1094.02 samples/sec   Loss 2.9434 target_logit_mean 0.0015 lma 0.6810  cos_theta_tmp 0.7459  Epoch: 1   Global Step: 27900   Required: 37 hours
Training: 2025-11-30 23:08:04,827-Speed 1096.61 samples/sec   Loss 2.9392 target_logit_mean -0.0019 lma 0.6686  cos_theta_tmp 0.7506  Epoch: 1   Global Step: 27950   Required: 37 hours
Training: 2025-11-30 23:08:22,496-Speed 1086.69 samples/sec   Loss 2.9236 target_logit_mean -0.0014 lma 0.6857  cos_theta_tmp 0.7497  Epoch: 1   Global Step: 28000   Required: 37 hours
Training: 2025-11-30 23:08:40,058-Speed 1093.31 samples/sec   Loss 2.8806 target_logit_mean 0.0008 lma 0.6752  cos_theta_tmp 0.7488  Epoch: 1   Global Step: 28050   Required: 37 hours
Training: 2025-11-30 23:08:57,558-Speed 1097.18 samples/sec   Loss 2.8721 target_logit_mean 0.0006 lma 0.6708  cos_theta_tmp 0.7458  Epoch: 1   Global Step: 28100   Required: 37 hours
Training: 2025-11-30 23:09:14,963-Speed 1103.17 samples/sec   Loss 2.8961 target_logit_mean 0.0017 lma 0.6810  cos_theta_tmp 0.7523  Epoch: 1   Global Step: 28150   Required: 37 hours
Training: 2025-11-30 23:09:32,361-Speed 1103.62 samples/sec   Loss 2.8663 target_logit_mean -0.0019 lma 0.6756  cos_theta_tmp 0.7531  Epoch: 1   Global Step: 28200   Required: 37 hours
Training: 2025-11-30 23:09:49,764-Speed 1103.29 samples/sec   Loss 2.8648 target_logit_mean 0.0003 lma 0.6831  cos_theta_tmp 0.7475  Epoch: 1   Global Step: 28250   Required: 37 hours
Training: 2025-11-30 23:10:07,163-Speed 1103.50 samples/sec   Loss 2.8604 target_logit_mean -0.0020 lma 0.6744  cos_theta_tmp 0.7482  Epoch: 1   Global Step: 28300   Required: 37 hours
Training: 2025-11-30 23:10:24,566-Speed 1103.31 samples/sec   Loss 2.8046 target_logit_mean -0.0008 lma 0.6850  cos_theta_tmp 0.7542  Epoch: 1   Global Step: 28350   Required: 37 hours
Training: 2025-11-30 23:10:42,083-Speed 1096.12 samples/sec   Loss 2.8970 target_logit_mean -0.0014 lma 0.6936  cos_theta_tmp 0.7469  Epoch: 1   Global Step: 28400   Required: 37 hours
Training: 2025-11-30 23:10:59,743-Speed 1087.26 samples/sec   Loss 2.9130 target_logit_mean 0.0016 lma 0.6858  cos_theta_tmp 0.7505  Epoch: 1   Global Step: 28450   Required: 37 hours
Training: 2025-11-30 23:11:17,391-Speed 1087.94 samples/sec   Loss 2.9102 target_logit_mean 0.0011 lma 0.6795  cos_theta_tmp 0.7517  Epoch: 1   Global Step: 28500   Required: 37 hours
Training: 2025-11-30 23:11:35,035-Speed 1088.25 samples/sec   Loss 2.8903 target_logit_mean 0.0028 lma 0.6775  cos_theta_tmp 0.7454  Epoch: 1   Global Step: 28550   Required: 37 hours
Training: 2025-11-30 23:11:52,675-Speed 1088.44 samples/sec   Loss 2.8727 target_logit_mean -0.0010 lma 0.6904  cos_theta_tmp 0.7532  Epoch: 1   Global Step: 28600   Required: 37 hours
Training: 2025-11-30 23:12:10,316-Speed 1088.46 samples/sec   Loss 2.9254 target_logit_mean -0.0014 lma 0.6834  cos_theta_tmp 0.7464  Epoch: 1   Global Step: 28650   Required: 37 hours
Training: 2025-11-30 23:12:27,962-Speed 1088.07 samples/sec   Loss 2.8879 target_logit_mean 0.0026 lma 0.6893  cos_theta_tmp 0.7483  Epoch: 1   Global Step: 28700   Required: 37 hours
Training: 2025-11-30 23:12:45,618-Speed 1087.52 samples/sec   Loss 2.8562 target_logit_mean -0.0004 lma 0.6840  cos_theta_tmp 0.7506  Epoch: 1   Global Step: 28750   Required: 37 hours
Training: 2025-11-30 23:13:03,163-Speed 1094.35 samples/sec   Loss 2.8229 target_logit_mean 0.0003 lma 0.6832  cos_theta_tmp 0.7488  Epoch: 1   Global Step: 28800   Required: 37 hours
Training: 2025-11-30 23:13:20,576-Speed 1102.66 samples/sec   Loss 2.8556 target_logit_mean -0.0017 lma 0.6861  cos_theta_tmp 0.7513  Epoch: 1   Global Step: 28850   Required: 37 hours
Training: 2025-11-30 23:13:37,982-Speed 1103.14 samples/sec   Loss 2.8029 target_logit_mean -0.0013 lma 0.6897  cos_theta_tmp 0.7485  Epoch: 1   Global Step: 28900   Required: 37 hours
Training: 2025-11-30 23:13:55,389-Speed 1103.00 samples/sec   Loss 2.8702 target_logit_mean 0.0009 lma 0.6822  cos_theta_tmp 0.7507  Epoch: 1   Global Step: 28950   Required: 37 hours
Training: 2025-11-30 23:14:12,796-Speed 1103.08 samples/sec   Loss 2.8986 target_logit_mean 0.0017 lma 0.6818  cos_theta_tmp 0.7530  Epoch: 1   Global Step: 29000   Required: 37 hours
Training: 2025-11-30 23:14:30,201-Speed 1103.14 samples/sec   Loss 2.9037 target_logit_mean 0.0019 lma 0.6895  cos_theta_tmp 0.7477  Epoch: 1   Global Step: 29050   Required: 37 hours
Training: 2025-11-30 23:14:47,713-Speed 1096.44 samples/sec   Loss 2.8747 target_logit_mean 0.0018 lma 0.6897  cos_theta_tmp 0.7539  Epoch: 1   Global Step: 29100   Required: 37 hours
Training: 2025-11-30 23:15:05,117-Speed 1103.22 samples/sec   Loss 2.8762 target_logit_mean 0.0010 lma 0.6760  cos_theta_tmp 0.7507  Epoch: 1   Global Step: 29150   Required: 37 hours
Training: 2025-11-30 23:15:22,525-Speed 1102.98 samples/sec   Loss 2.9340 target_logit_mean -0.0005 lma 0.6638  cos_theta_tmp 0.7426  Epoch: 1   Global Step: 29200   Required: 37 hours
Training: 2025-11-30 23:15:39,929-Speed 1103.26 samples/sec   Loss 2.9468 target_logit_mean 0.0034 lma 0.6826  cos_theta_tmp 0.7461  Epoch: 1   Global Step: 29250   Required: 37 hours
Training: 2025-11-30 23:15:57,336-Speed 1103.09 samples/sec   Loss 2.8488 target_logit_mean -0.0025 lma 0.6799  cos_theta_tmp 0.7447  Epoch: 1   Global Step: 29300   Required: 37 hours
Training: 2025-11-30 23:16:14,738-Speed 1103.33 samples/sec   Loss 2.9280 target_logit_mean 0.0014 lma 0.6774  cos_theta_tmp 0.7471  Epoch: 1   Global Step: 29350   Required: 37 hours
Training: 2025-11-30 23:16:32,142-Speed 1103.21 samples/sec   Loss 2.8531 target_logit_mean 0.0018 lma 0.6997  cos_theta_tmp 0.7540  Epoch: 1   Global Step: 29400   Required: 37 hours
Training: 2025-11-30 23:16:49,546-Speed 1103.26 samples/sec   Loss 2.8590 target_logit_mean 0.0003 lma 0.6820  cos_theta_tmp 0.7532  Epoch: 1   Global Step: 29450   Required: 37 hours
Training: 2025-11-30 23:17:06,947-Speed 1103.43 samples/sec   Loss 2.8922 target_logit_mean -0.0015 lma 0.6777  cos_theta_tmp 0.7422  Epoch: 1   Global Step: 29500   Required: 37 hours
Training: 2025-11-30 23:17:24,350-Speed 1103.30 samples/sec   Loss 2.8426 target_logit_mean 0.0001 lma 0.6724  cos_theta_tmp 0.7485  Epoch: 1   Global Step: 29550   Required: 37 hours
Training: 2025-11-30 23:17:41,943-Speed 1091.40 samples/sec   Loss 2.8863 target_logit_mean 0.0002 lma 0.6850  cos_theta_tmp 0.7543  Epoch: 1   Global Step: 29600   Required: 37 hours
Training: 2025-11-30 23:17:59,434-Speed 1097.74 samples/sec   Loss 2.8390 target_logit_mean -0.0014 lma 0.6831  cos_theta_tmp 0.7530  Epoch: 1   Global Step: 29650   Required: 37 hours
Training: 2025-11-30 23:18:16,911-Speed 1098.62 samples/sec   Loss 2.8505 target_logit_mean 0.0024 lma 0.6893  cos_theta_tmp 0.7505  Epoch: 1   Global Step: 29700   Required: 37 hours
Training: 2025-11-30 23:18:34,374-Speed 1099.51 samples/sec   Loss 2.8917 target_logit_mean 0.0037 lma 0.6886  cos_theta_tmp 0.7504  Epoch: 1   Global Step: 29750   Required: 37 hours
Training: 2025-11-30 23:18:51,788-Speed 1102.61 samples/sec   Loss 2.9031 target_logit_mean 0.0014 lma 0.6753  cos_theta_tmp 0.7423  Epoch: 1   Global Step: 29800   Required: 37 hours
Training: 2025-11-30 23:19:09,204-Speed 1102.45 samples/sec   Loss 2.8726 target_logit_mean 0.0005 lma 0.6753  cos_theta_tmp 0.7537  Epoch: 1   Global Step: 29850   Required: 37 hours
Training: 2025-11-30 23:19:26,688-Speed 1098.19 samples/sec   Loss 2.9012 target_logit_mean 0.0007 lma 0.6730  cos_theta_tmp 0.7500  Epoch: 1   Global Step: 29900   Required: 37 hours
Training: 2025-11-30 23:19:44,112-Speed 1102.00 samples/sec   Loss 2.8028 target_logit_mean -0.0006 lma 0.6733  cos_theta_tmp 0.7471  Epoch: 1   Global Step: 29950   Required: 37 hours
Training: 2025-11-30 23:20:01,512-Speed 1103.43 samples/sec   Loss 2.8108 target_logit_mean -0.0011 lma 0.6858  cos_theta_tmp 0.7500  Epoch: 1   Global Step: 30000   Required: 37 hours
Training: 2025-11-30 23:20:18,927-Speed 1102.57 samples/sec   Loss 2.8638 target_logit_mean -0.0005 lma 0.6818  cos_theta_tmp 0.7511  Epoch: 1   Global Step: 30050   Required: 37 hours
Training: 2025-11-30 23:20:36,327-Speed 1103.46 samples/sec   Loss 2.8934 target_logit_mean 0.0026 lma 0.6869  cos_theta_tmp 0.7563  Epoch: 1   Global Step: 30100   Required: 37 hours
Training: 2025-11-30 23:20:53,744-Speed 1102.41 samples/sec   Loss 2.8964 target_logit_mean -0.0002 lma 0.6741  cos_theta_tmp 0.7487  Epoch: 1   Global Step: 30150   Required: 37 hours
Training: 2025-11-30 23:21:11,161-Speed 1102.40 samples/sec   Loss 2.8475 target_logit_mean 0.0018 lma 0.6778  cos_theta_tmp 0.7500  Epoch: 1   Global Step: 30200   Required: 37 hours
Training: 2025-11-30 23:21:28,562-Speed 1103.47 samples/sec   Loss 2.8614 target_logit_mean 0.0022 lma 0.6732  cos_theta_tmp 0.7532  Epoch: 1   Global Step: 30250   Required: 37 hours
Training: 2025-11-30 23:21:46,012-Speed 1100.30 samples/sec   Loss 2.8090 target_logit_mean 0.0009 lma 0.6804  cos_theta_tmp 0.7540  Epoch: 1   Global Step: 30300   Required: 37 hours
Training: 2025-11-30 23:22:09,290-[lfw][30326]XNorm: 23.098249
Training: 2025-11-30 23:22:09,290-[lfw][30326]Accuracy-Flip: 0.99000+-0.00563
Training: 2025-11-30 23:22:09,290-[lfw][30326]Accuracy-Highest: 0.99050
Training: 2025-11-30 23:22:27,882-[cfp_fp][30326]XNorm: 18.752933
Training: 2025-11-30 23:22:27,882-[cfp_fp][30326]Accuracy-Flip: 0.86386+-0.00888
Training: 2025-11-30 23:22:27,882-[cfp_fp][30326]Accuracy-Highest: 0.86386
Training: 2025-11-30 23:22:51,590-[cfp_ff][30326]XNorm: 22.232900
Training: 2025-11-30 23:22:51,591-[cfp_ff][30326]Accuracy-Flip: 0.98971+-0.00349
Training: 2025-11-30 23:22:51,591-[cfp_ff][30326]Accuracy-Highest: 0.98986
Training: 2025-11-30 23:23:08,646-[agedb_30][30326]XNorm: 21.948246
Training: 2025-11-30 23:23:08,646-[agedb_30][30326]Accuracy-Flip: 0.92717+-0.01356
Training: 2025-11-30 23:23:08,646-[agedb_30][30326]Accuracy-Highest: 0.92717
Training: 2025-11-30 23:23:21,999-[calfw][30326]XNorm: 22.923370
Training: 2025-11-30 23:23:21,999-[calfw][30326]Accuracy-Flip: 0.93883+-0.01096
Training: 2025-11-30 23:23:21,999-[calfw][30326]Accuracy-Highest: 0.93883
Training: 2025-11-30 23:23:35,198-[cplfw][30326]XNorm: 18.996670
Training: 2025-11-30 23:23:35,198-[cplfw][30326]Accuracy-Flip: 0.84500+-0.01966
Training: 2025-11-30 23:23:35,198-[cplfw][30326]Accuracy-Highest: 0.84500
Training: 2025-11-30 23:23:48,569-[vgg2_fp][30326]XNorm: 19.358957
Training: 2025-11-30 23:23:48,569-[vgg2_fp][30326]Accuracy-Flip: 0.88080+-0.01321
Training: 2025-11-30 23:23:48,569-[vgg2_fp][30326]Accuracy-Highest: 0.88080
Training: 2025-11-30 23:24:10,745-Speed 132.66 samples/sec   Loss 2.8215 target_logit_mean 0.0018 lma 0.6870  cos_theta_tmp 0.7508  Epoch: 2   Global Step: 30350   Required: 37 hours
Training: 2025-11-30 23:24:28,101-Speed 1106.29 samples/sec   Loss 2.8898 target_logit_mean 0.0008 lma 0.6817  cos_theta_tmp 0.7495  Epoch: 2   Global Step: 30400   Required: 37 hours
Training: 2025-11-30 23:24:45,514-Speed 1102.63 samples/sec   Loss 2.7733 target_logit_mean 0.0012 lma 0.6954  cos_theta_tmp 0.7446  Epoch: 2   Global Step: 30450   Required: 37 hours
Training: 2025-11-30 23:25:02,914-Speed 1103.48 samples/sec   Loss 2.8676 target_logit_mean -0.0000 lma 0.6740  cos_theta_tmp 0.7467  Epoch: 2   Global Step: 30500   Required: 37 hours
Training: 2025-11-30 23:25:20,332-Speed 1102.38 samples/sec   Loss 2.8299 target_logit_mean -0.0001 lma 0.6819  cos_theta_tmp 0.7532  Epoch: 2   Global Step: 30550   Required: 37 hours
Training: 2025-11-30 23:25:37,754-Speed 1102.08 samples/sec   Loss 2.8911 target_logit_mean 0.0011 lma 0.6774  cos_theta_tmp 0.7469  Epoch: 2   Global Step: 30600   Required: 37 hours
Training: 2025-11-30 23:25:55,157-Speed 1103.27 samples/sec   Loss 2.9299 target_logit_mean -0.0028 lma 0.6941  cos_theta_tmp 0.7460  Epoch: 2   Global Step: 30650   Required: 37 hours
Training: 2025-11-30 23:26:12,576-Speed 1102.33 samples/sec   Loss 2.8176 target_logit_mean -0.0006 lma 0.6867  cos_theta_tmp 0.7517  Epoch: 2   Global Step: 30700   Required: 37 hours
Training: 2025-11-30 23:26:30,027-Speed 1100.25 samples/sec   Loss 2.8383 target_logit_mean 0.0017 lma 0.6947  cos_theta_tmp 0.7504  Epoch: 2   Global Step: 30750   Required: 37 hours
Training: 2025-11-30 23:26:47,515-Speed 1097.94 samples/sec   Loss 2.8736 target_logit_mean 0.0014 lma 0.6754  cos_theta_tmp 0.7454  Epoch: 2   Global Step: 30800   Required: 37 hours
Training: 2025-11-30 23:27:04,960-Speed 1100.67 samples/sec   Loss 2.8380 target_logit_mean -0.0002 lma 0.6832  cos_theta_tmp 0.7512  Epoch: 2   Global Step: 30850   Required: 37 hours
Training: 2025-11-30 23:27:22,377-Speed 1102.38 samples/sec   Loss 2.7965 target_logit_mean -0.0014 lma 0.6885  cos_theta_tmp 0.7488  Epoch: 2   Global Step: 30900   Required: 37 hours
Training: 2025-11-30 23:27:39,790-Speed 1102.67 samples/sec   Loss 2.8143 target_logit_mean -0.0002 lma 0.6814  cos_theta_tmp 0.7577  Epoch: 2   Global Step: 30950   Required: 37 hours
Training: 2025-11-30 23:27:57,196-Speed 1103.11 samples/sec   Loss 2.8452 target_logit_mean 0.0004 lma 0.6898  cos_theta_tmp 0.7492  Epoch: 2   Global Step: 31000   Required: 37 hours
Training: 2025-11-30 23:28:14,613-Speed 1102.40 samples/sec   Loss 2.8014 target_logit_mean -0.0014 lma 0.6880  cos_theta_tmp 0.7496  Epoch: 2   Global Step: 31050   Required: 37 hours
Training: 2025-11-30 23:28:32,014-Speed 1103.46 samples/sec   Loss 2.7887 target_logit_mean 0.0008 lma 0.6859  cos_theta_tmp 0.7535  Epoch: 2   Global Step: 31100   Required: 37 hours
Training: 2025-11-30 23:28:49,540-Speed 1095.55 samples/sec   Loss 2.8141 target_logit_mean 0.0002 lma 0.6827  cos_theta_tmp 0.7538  Epoch: 2   Global Step: 31150   Required: 37 hours
Training: 2025-11-30 23:29:06,944-Speed 1103.24 samples/sec   Loss 2.8078 target_logit_mean -0.0000 lma 0.6865  cos_theta_tmp 0.7533  Epoch: 2   Global Step: 31200   Required: 37 hours
Training: 2025-11-30 23:29:24,472-Speed 1095.41 samples/sec   Loss 2.7984 target_logit_mean 0.0003 lma 0.6890  cos_theta_tmp 0.7535  Epoch: 2   Global Step: 31250   Required: 37 hours
Training: 2025-11-30 23:29:42,021-Speed 1094.11 samples/sec   Loss 2.8403 target_logit_mean 0.0000 lma 0.6899  cos_theta_tmp 0.7471  Epoch: 2   Global Step: 31300   Required: 37 hours
Training: 2025-11-30 23:29:59,452-Speed 1101.55 samples/sec   Loss 2.8746 target_logit_mean -0.0002 lma 0.6937  cos_theta_tmp 0.7514  Epoch: 2   Global Step: 31350   Required: 37 hours
Training: 2025-11-30 23:30:16,899-Speed 1100.52 samples/sec   Loss 2.7872 target_logit_mean 0.0016 lma 0.6860  cos_theta_tmp 0.7506  Epoch: 2   Global Step: 31400   Required: 37 hours
Training: 2025-11-30 23:30:34,328-Speed 1101.67 samples/sec   Loss 2.8748 target_logit_mean -0.0001 lma 0.6858  cos_theta_tmp 0.7558  Epoch: 2   Global Step: 31450   Required: 37 hours
Training: 2025-11-30 23:30:51,795-Speed 1099.24 samples/sec   Loss 2.7974 target_logit_mean 0.0014 lma 0.6860  cos_theta_tmp 0.7494  Epoch: 2   Global Step: 31500   Required: 37 hours
Training: 2025-11-30 23:31:09,322-Speed 1095.53 samples/sec   Loss 2.8410 target_logit_mean -0.0007 lma 0.6807  cos_theta_tmp 0.7484  Epoch: 2   Global Step: 31550   Required: 37 hours
Training: 2025-11-30 23:31:26,833-Speed 1096.49 samples/sec   Loss 2.8121 target_logit_mean 0.0008 lma 0.6868  cos_theta_tmp 0.7498  Epoch: 2   Global Step: 31600   Required: 37 hours
Training: 2025-11-30 23:31:44,299-Speed 1099.32 samples/sec   Loss 2.8695 target_logit_mean 0.0000 lma 0.6715  cos_theta_tmp 0.7464  Epoch: 2   Global Step: 31650   Required: 37 hours
Training: 2025-11-30 23:32:01,699-Speed 1103.47 samples/sec   Loss 2.7667 target_logit_mean -0.0007 lma 0.6777  cos_theta_tmp 0.7475  Epoch: 2   Global Step: 31700   Required: 37 hours
Training: 2025-11-30 23:32:19,118-Speed 1102.25 samples/sec   Loss 2.8129 target_logit_mean -0.0003 lma 0.6943  cos_theta_tmp 0.7568  Epoch: 2   Global Step: 31750   Required: 37 hours
Training: 2025-11-30 23:32:36,528-Speed 1102.85 samples/sec   Loss 2.8289 target_logit_mean 0.0023 lma 0.6810  cos_theta_tmp 0.7481  Epoch: 2   Global Step: 31800   Required: 37 hours
Training: 2025-11-30 23:32:53,943-Speed 1102.55 samples/sec   Loss 2.8067 target_logit_mean 0.0007 lma 0.6842  cos_theta_tmp 0.7537  Epoch: 2   Global Step: 31850   Required: 37 hours
Training: 2025-11-30 23:33:11,359-Speed 1102.51 samples/sec   Loss 2.8199 target_logit_mean 0.0000 lma 0.6851  cos_theta_tmp 0.7506  Epoch: 2   Global Step: 31900   Required: 37 hours
Training: 2025-11-30 23:33:28,761-Speed 1103.37 samples/sec   Loss 2.8385 target_logit_mean -0.0022 lma 0.6760  cos_theta_tmp 0.7457  Epoch: 2   Global Step: 31950   Required: 37 hours
Training: 2025-11-30 23:33:46,178-Speed 1102.37 samples/sec   Loss 2.8204 target_logit_mean -0.0006 lma 0.6731  cos_theta_tmp 0.7471  Epoch: 2   Global Step: 32000   Required: 37 hours
Training: 2025-11-30 23:34:03,584-Speed 1103.11 samples/sec   Loss 2.8316 target_logit_mean 0.0017 lma 0.6752  cos_theta_tmp 0.7480  Epoch: 2   Global Step: 32050   Required: 37 hours
Training: 2025-11-30 23:34:21,002-Speed 1102.36 samples/sec   Loss 2.8135 target_logit_mean 0.0014 lma 0.6778  cos_theta_tmp 0.7489  Epoch: 2   Global Step: 32100   Required: 37 hours
Training: 2025-11-30 23:34:38,422-Speed 1102.23 samples/sec   Loss 2.8286 target_logit_mean 0.0004 lma 0.6787  cos_theta_tmp 0.7525  Epoch: 2   Global Step: 32150   Required: 37 hours
Training: 2025-11-30 23:34:55,827-Speed 1103.18 samples/sec   Loss 2.8069 target_logit_mean 0.0010 lma 0.6771  cos_theta_tmp 0.7525  Epoch: 2   Global Step: 32200   Required: 37 hours
Training: 2025-11-30 23:35:13,245-Speed 1102.34 samples/sec   Loss 2.7796 target_logit_mean 0.0005 lma 0.6866  cos_theta_tmp 0.7540  Epoch: 2   Global Step: 32250   Required: 37 hours
Training: 2025-11-30 23:35:30,647-Speed 1103.34 samples/sec   Loss 2.7490 target_logit_mean 0.0022 lma 0.6862  cos_theta_tmp 0.7526  Epoch: 2   Global Step: 32300   Required: 37 hours
Training: 2025-11-30 23:35:48,110-Speed 1099.51 samples/sec   Loss 2.7896 target_logit_mean 0.0009 lma 0.6855  cos_theta_tmp 0.7559  Epoch: 2   Global Step: 32350   Required: 37 hours
Training: 2025-11-30 23:36:05,599-Speed 1097.88 samples/sec   Loss 2.7548 target_logit_mean -0.0006 lma 0.6802  cos_theta_tmp 0.7519  Epoch: 2   Global Step: 32400   Required: 37 hours
Training: 2025-11-30 23:36:23,136-Speed 1094.87 samples/sec   Loss 2.8042 target_logit_mean 0.0011 lma 0.6841  cos_theta_tmp 0.7553  Epoch: 2   Global Step: 32450   Required: 37 hours
Training: 2025-11-30 23:36:40,892-Speed 1081.35 samples/sec   Loss 2.8326 target_logit_mean -0.0017 lma 0.6789  cos_theta_tmp 0.7580  Epoch: 2   Global Step: 32500   Required: 37 hours
Training: 2025-11-30 23:36:58,450-Speed 1093.56 samples/sec   Loss 2.7806 target_logit_mean -0.0016 lma 0.6760  cos_theta_tmp 0.7495  Epoch: 2   Global Step: 32550   Required: 37 hours
Training: 2025-11-30 23:37:15,875-Speed 1101.89 samples/sec   Loss 2.8321 target_logit_mean 0.0012 lma 0.6744  cos_theta_tmp 0.7483  Epoch: 2   Global Step: 32600   Required: 37 hours
Training: 2025-11-30 23:37:33,274-Speed 1103.53 samples/sec   Loss 2.8328 target_logit_mean -0.0031 lma 0.6845  cos_theta_tmp 0.7513  Epoch: 2   Global Step: 32650   Required: 37 hours
Training: 2025-11-30 23:37:50,691-Speed 1102.41 samples/sec   Loss 2.8191 target_logit_mean 0.0024 lma 0.6804  cos_theta_tmp 0.7454  Epoch: 2   Global Step: 32700   Required: 37 hours
Training: 2025-11-30 23:38:08,093-Speed 1103.38 samples/sec   Loss 2.8238 target_logit_mean -0.0016 lma 0.6762  cos_theta_tmp 0.7535  Epoch: 2   Global Step: 32750   Required: 37 hours
Training: 2025-11-30 23:38:25,511-Speed 1102.35 samples/sec   Loss 2.7991 target_logit_mean -0.0017 lma 0.6780  cos_theta_tmp 0.7556  Epoch: 2   Global Step: 32800   Required: 37 hours
Training: 2025-11-30 23:38:42,932-Speed 1102.19 samples/sec   Loss 2.8274 target_logit_mean -0.0020 lma 0.6714  cos_theta_tmp 0.7456  Epoch: 2   Global Step: 32850   Required: 37 hours
Training: 2025-11-30 23:39:00,334-Speed 1103.37 samples/sec   Loss 2.8129 target_logit_mean -0.0006 lma 0.6841  cos_theta_tmp 0.7521  Epoch: 2   Global Step: 32900   Required: 37 hours
Training: 2025-11-30 23:39:17,751-Speed 1102.38 samples/sec   Loss 2.7767 target_logit_mean 0.0018 lma 0.6743  cos_theta_tmp 0.7551  Epoch: 2   Global Step: 32950   Required: 37 hours
Training: 2025-11-30 23:39:35,155-Speed 1103.27 samples/sec   Loss 2.8677 target_logit_mean -0.0007 lma 0.6814  cos_theta_tmp 0.7560  Epoch: 2   Global Step: 33000   Required: 37 hours
Training: 2025-11-30 23:39:52,570-Speed 1102.54 samples/sec   Loss 2.8749 target_logit_mean -0.0031 lma 0.6870  cos_theta_tmp 0.7436  Epoch: 2   Global Step: 33050   Required: 37 hours
Training: 2025-11-30 23:40:09,984-Speed 1102.62 samples/sec   Loss 2.8335 target_logit_mean 0.0010 lma 0.6792  cos_theta_tmp 0.7512  Epoch: 2   Global Step: 33100   Required: 37 hours
Training: 2025-11-30 23:40:27,387-Speed 1103.26 samples/sec   Loss 2.7628 target_logit_mean 0.0013 lma 0.6830  cos_theta_tmp 0.7563  Epoch: 2   Global Step: 33150   Required: 37 hours
Training: 2025-11-30 23:40:44,805-Speed 1102.38 samples/sec   Loss 2.8196 target_logit_mean 0.0034 lma 0.6854  cos_theta_tmp 0.7505  Epoch: 2   Global Step: 33200   Required: 37 hours
Training: 2025-11-30 23:41:02,206-Speed 1103.40 samples/sec   Loss 2.7830 target_logit_mean 0.0019 lma 0.6870  cos_theta_tmp 0.7626  Epoch: 2   Global Step: 33250   Required: 37 hours
Training: 2025-11-30 23:41:19,625-Speed 1102.29 samples/sec   Loss 2.7493 target_logit_mean 0.0028 lma 0.6801  cos_theta_tmp 0.7527  Epoch: 2   Global Step: 33300   Required: 37 hours
Training: 2025-11-30 23:41:37,029-Speed 1103.23 samples/sec   Loss 2.8383 target_logit_mean -0.0002 lma 0.6852  cos_theta_tmp 0.7477  Epoch: 2   Global Step: 33350   Required: 37 hours
Training: 2025-11-30 23:41:54,445-Speed 1102.45 samples/sec   Loss 2.7867 target_logit_mean 0.0020 lma 0.6964  cos_theta_tmp 0.7529  Epoch: 2   Global Step: 33400   Required: 37 hours
Training: 2025-11-30 23:42:11,860-Speed 1102.58 samples/sec   Loss 2.8593 target_logit_mean -0.0010 lma 0.6830  cos_theta_tmp 0.7508  Epoch: 2   Global Step: 33450   Required: 37 hours
Training: 2025-11-30 23:42:29,267-Speed 1103.03 samples/sec   Loss 2.7966 target_logit_mean -0.0009 lma 0.6787  cos_theta_tmp 0.7563  Epoch: 2   Global Step: 33500   Required: 37 hours
Training: 2025-11-30 23:42:46,683-Speed 1102.46 samples/sec   Loss 2.8104 target_logit_mean -0.0012 lma 0.6804  cos_theta_tmp 0.7443  Epoch: 2   Global Step: 33550   Required: 37 hours
Training: 2025-11-30 23:43:04,086-Speed 1103.32 samples/sec   Loss 2.8288 target_logit_mean -0.0023 lma 0.6784  cos_theta_tmp 0.7495  Epoch: 2   Global Step: 33600   Required: 37 hours
Training: 2025-11-30 23:43:21,505-Speed 1102.29 samples/sec   Loss 2.8198 target_logit_mean -0.0025 lma 0.6785  cos_theta_tmp 0.7421  Epoch: 2   Global Step: 33650   Required: 37 hours
Training: 2025-11-30 23:43:38,909-Speed 1103.24 samples/sec   Loss 2.7844 target_logit_mean 0.0009 lma 0.6864  cos_theta_tmp 0.7514  Epoch: 2   Global Step: 33700   Required: 37 hours
Training: 2025-11-30 23:43:56,324-Speed 1102.55 samples/sec   Loss 2.7243 target_logit_mean -0.0009 lma 0.6832  cos_theta_tmp 0.7468  Epoch: 2   Global Step: 33750   Required: 37 hours
Training: 2025-11-30 23:44:13,742-Speed 1102.30 samples/sec   Loss 2.7817 target_logit_mean 0.0017 lma 0.6891  cos_theta_tmp 0.7562  Epoch: 2   Global Step: 33800   Required: 37 hours
Training: 2025-11-30 23:44:31,148-Speed 1103.14 samples/sec   Loss 2.7501 target_logit_mean 0.0000 lma 0.6810  cos_theta_tmp 0.7565  Epoch: 2   Global Step: 33850   Required: 37 hours
Training: 2025-11-30 23:44:48,573-Speed 1101.89 samples/sec   Loss 2.7614 target_logit_mean -0.0007 lma 0.6930  cos_theta_tmp 0.7520  Epoch: 2   Global Step: 33900   Required: 37 hours
Training: 2025-11-30 23:45:05,976-Speed 1103.28 samples/sec   Loss 2.7508 target_logit_mean 0.0008 lma 0.6731  cos_theta_tmp 0.7528  Epoch: 2   Global Step: 33950   Required: 37 hours
Training: 2025-11-30 23:45:23,390-Speed 1102.62 samples/sec   Loss 2.7875 target_logit_mean -0.0005 lma 0.6887  cos_theta_tmp 0.7554  Epoch: 2   Global Step: 34000   Required: 37 hours
Training: 2025-11-30 23:45:40,806-Speed 1102.46 samples/sec   Loss 2.7870 target_logit_mean 0.0013 lma 0.6799  cos_theta_tmp 0.7539  Epoch: 2   Global Step: 34050   Required: 37 hours
Training: 2025-11-30 23:45:58,206-Speed 1103.47 samples/sec   Loss 2.8086 target_logit_mean -0.0014 lma 0.6802  cos_theta_tmp 0.7476  Epoch: 2   Global Step: 34100   Required: 37 hours
Training: 2025-11-30 23:46:15,657-Speed 1100.28 samples/sec   Loss 2.7799 target_logit_mean 0.0017 lma 0.6967  cos_theta_tmp 0.7541  Epoch: 2   Global Step: 34150   Required: 37 hours
Training: 2025-11-30 23:46:33,197-Speed 1094.68 samples/sec   Loss 2.7852 target_logit_mean -0.0001 lma 0.6911  cos_theta_tmp 0.7524  Epoch: 2   Global Step: 34200   Required: 37 hours
Training: 2025-11-30 23:46:50,773-Speed 1092.43 samples/sec   Loss 2.7853 target_logit_mean 0.0003 lma 0.6883  cos_theta_tmp 0.7501  Epoch: 2   Global Step: 34250   Required: 37 hours
Training: 2025-11-30 23:47:08,271-Speed 1097.33 samples/sec   Loss 2.7475 target_logit_mean -0.0000 lma 0.6815  cos_theta_tmp 0.7511  Epoch: 2   Global Step: 34300   Required: 37 hours
Training: 2025-11-30 23:47:25,780-Speed 1096.62 samples/sec   Loss 2.7713 target_logit_mean -0.0011 lma 0.6794  cos_theta_tmp 0.7563  Epoch: 2   Global Step: 34350   Required: 37 hours
Training: 2025-11-30 23:47:43,335-Speed 1093.71 samples/sec   Loss 2.8242 target_logit_mean 0.0031 lma 0.6780  cos_theta_tmp 0.7511  Epoch: 2   Global Step: 34400   Required: 37 hours
Training: 2025-11-30 23:48:00,854-Speed 1096.01 samples/sec   Loss 2.7971 target_logit_mean -0.0011 lma 0.6771  cos_theta_tmp 0.7495  Epoch: 2   Global Step: 34450   Required: 37 hours
Training: 2025-11-30 23:48:18,474-Speed 1089.69 samples/sec   Loss 2.7915 target_logit_mean -0.0003 lma 0.6729  cos_theta_tmp 0.7502  Epoch: 2   Global Step: 34500   Required: 37 hours
Training: 2025-11-30 23:48:35,972-Speed 1097.35 samples/sec   Loss 2.7755 target_logit_mean -0.0009 lma 0.6784  cos_theta_tmp 0.7532  Epoch: 2   Global Step: 34550   Required: 37 hours
Training: 2025-11-30 23:48:53,577-Speed 1090.64 samples/sec   Loss 2.8184 target_logit_mean -0.0007 lma 0.6841  cos_theta_tmp 0.7545  Epoch: 2   Global Step: 34600   Required: 37 hours
Training: 2025-11-30 23:49:11,166-Speed 1091.63 samples/sec   Loss 2.7596 target_logit_mean 0.0005 lma 0.6938  cos_theta_tmp 0.7553  Epoch: 2   Global Step: 34650   Required: 37 hours
Training: 2025-11-30 23:49:28,572-Speed 1103.05 samples/sec   Loss 2.8063 target_logit_mean 0.0017 lma 0.6827  cos_theta_tmp 0.7577  Epoch: 2   Global Step: 34700   Required: 37 hours
Training: 2025-11-30 23:49:45,992-Speed 1102.26 samples/sec   Loss 2.7962 target_logit_mean 0.0000 lma 0.6794  cos_theta_tmp 0.7509  Epoch: 2   Global Step: 34750   Required: 37 hours
Training: 2025-11-30 23:50:03,394-Speed 1103.32 samples/sec   Loss 2.7785 target_logit_mean -0.0010 lma 0.6757  cos_theta_tmp 0.7465  Epoch: 2   Global Step: 34800   Required: 37 hours
Training: 2025-11-30 23:50:20,822-Speed 1102.03 samples/sec   Loss 2.7964 target_logit_mean 0.0014 lma 0.6835  cos_theta_tmp 0.7547  Epoch: 2   Global Step: 34850   Required: 37 hours
Training: 2025-11-30 23:50:38,227-Speed 1103.16 samples/sec   Loss 2.7899 target_logit_mean 0.0001 lma 0.6725  cos_theta_tmp 0.7481  Epoch: 2   Global Step: 34900   Required: 37 hours
Training: 2025-11-30 23:50:55,648-Speed 1102.15 samples/sec   Loss 2.7949 target_logit_mean -0.0013 lma 0.6741  cos_theta_tmp 0.7505  Epoch: 2   Global Step: 34950   Required: 37 hours
Training: 2025-11-30 23:51:13,067-Speed 1102.30 samples/sec   Loss 2.8091 target_logit_mean -0.0011 lma 0.6853  cos_theta_tmp 0.7538  Epoch: 2   Global Step: 35000   Required: 37 hours
Training: 2025-11-30 23:51:30,469-Speed 1103.36 samples/sec   Loss 2.7496 target_logit_mean 0.0009 lma 0.6687  cos_theta_tmp 0.7518  Epoch: 2   Global Step: 35050   Required: 37 hours
Training: 2025-11-30 23:51:47,945-Speed 1098.67 samples/sec   Loss 2.7703 target_logit_mean -0.0008 lma 0.6793  cos_theta_tmp 0.7490  Epoch: 2   Global Step: 35100   Required: 37 hours
Training: 2025-11-30 23:52:05,394-Speed 1100.39 samples/sec   Loss 2.7638 target_logit_mean -0.0004 lma 0.6622  cos_theta_tmp 0.7408  Epoch: 2   Global Step: 35150   Required: 37 hours
Training: 2025-11-30 23:52:22,834-Speed 1100.94 samples/sec   Loss 2.8452 target_logit_mean -0.0012 lma 0.6709  cos_theta_tmp 0.7470  Epoch: 2   Global Step: 35200   Required: 37 hours
Training: 2025-11-30 23:52:40,263-Speed 1101.66 samples/sec   Loss 2.8153 target_logit_mean -0.0010 lma 0.6845  cos_theta_tmp 0.7520  Epoch: 2   Global Step: 35250   Required: 37 hours
Training: 2025-11-30 23:52:57,699-Speed 1101.25 samples/sec   Loss 2.8202 target_logit_mean 0.0005 lma 0.6857  cos_theta_tmp 0.7512  Epoch: 2   Global Step: 35300   Required: 37 hours
Training: 2025-11-30 23:53:15,129-Speed 1101.58 samples/sec   Loss 2.7650 target_logit_mean 0.0002 lma 0.6939  cos_theta_tmp 0.7557  Epoch: 2   Global Step: 35350   Required: 37 hours
Training: 2025-11-30 23:53:32,558-Speed 1101.66 samples/sec   Loss 2.7510 target_logit_mean -0.0009 lma 0.6806  cos_theta_tmp 0.7498  Epoch: 2   Global Step: 35400   Required: 37 hours
Training: 2025-11-30 23:53:49,983-Speed 1101.90 samples/sec   Loss 2.7396 target_logit_mean -0.0004 lma 0.6860  cos_theta_tmp 0.7540  Epoch: 2   Global Step: 35450   Required: 37 hours
Training: 2025-11-30 23:54:07,404-Speed 1102.16 samples/sec   Loss 2.7231 target_logit_mean 0.0002 lma 0.6900  cos_theta_tmp 0.7558  Epoch: 2   Global Step: 35500   Required: 37 hours
Training: 2025-11-30 23:54:24,824-Speed 1102.21 samples/sec   Loss 2.7326 target_logit_mean -0.0032 lma 0.6772  cos_theta_tmp 0.7508  Epoch: 2   Global Step: 35550   Required: 37 hours
Training: 2025-11-30 23:54:42,263-Speed 1101.02 samples/sec   Loss 2.7738 target_logit_mean 0.0002 lma 0.6827  cos_theta_tmp 0.7523  Epoch: 2   Global Step: 35600   Required: 37 hours
Training: 2025-11-30 23:54:59,691-Speed 1101.73 samples/sec   Loss 2.7781 target_logit_mean -0.0012 lma 0.6836  cos_theta_tmp 0.7525  Epoch: 2   Global Step: 35650   Required: 37 hours
Training: 2025-11-30 23:55:17,116-Speed 1101.86 samples/sec   Loss 2.7515 target_logit_mean 0.0007 lma 0.6790  cos_theta_tmp 0.7528  Epoch: 2   Global Step: 35700   Required: 37 hours
Training: 2025-11-30 23:55:34,546-Speed 1101.63 samples/sec   Loss 2.7303 target_logit_mean 0.0011 lma 0.6899  cos_theta_tmp 0.7499  Epoch: 2   Global Step: 35750   Required: 37 hours
Training: 2025-11-30 23:55:51,972-Speed 1101.79 samples/sec   Loss 2.7442 target_logit_mean 0.0001 lma 0.7001  cos_theta_tmp 0.7574  Epoch: 2   Global Step: 35800   Required: 37 hours
Training: 2025-11-30 23:56:09,400-Speed 1101.75 samples/sec   Loss 2.7154 target_logit_mean -0.0005 lma 0.6775  cos_theta_tmp 0.7515  Epoch: 2   Global Step: 35850   Required: 37 hours
Training: 2025-11-30 23:56:26,842-Speed 1100.84 samples/sec   Loss 2.7575 target_logit_mean -0.0021 lma 0.6764  cos_theta_tmp 0.7454  Epoch: 2   Global Step: 35900   Required: 37 hours
Training: 2025-11-30 23:56:44,327-Speed 1098.12 samples/sec   Loss 2.8366 target_logit_mean -0.0015 lma 0.6738  cos_theta_tmp 0.7419  Epoch: 2   Global Step: 35950   Required: 37 hours
Training: 2025-11-30 23:57:01,808-Speed 1098.35 samples/sec   Loss 2.7473 target_logit_mean 0.0023 lma 0.6882  cos_theta_tmp 0.7529  Epoch: 2   Global Step: 36000   Required: 37 hours
Training: 2025-11-30 23:57:19,290-Speed 1098.33 samples/sec   Loss 2.7842 target_logit_mean -0.0004 lma 0.6821  cos_theta_tmp 0.7526  Epoch: 2   Global Step: 36050   Required: 37 hours
Training: 2025-11-30 23:57:36,745-Speed 1100.00 samples/sec   Loss 2.8013 target_logit_mean -0.0016 lma 0.6834  cos_theta_tmp 0.7485  Epoch: 2   Global Step: 36100   Required: 37 hours
Training: 2025-11-30 23:57:54,220-Speed 1098.75 samples/sec   Loss 2.7624 target_logit_mean 0.0012 lma 0.6747  cos_theta_tmp 0.7462  Epoch: 2   Global Step: 36150   Required: 37 hours
Training: 2025-11-30 23:58:11,681-Speed 1099.63 samples/sec   Loss 2.7976 target_logit_mean -0.0015 lma 0.6731  cos_theta_tmp 0.7493  Epoch: 2   Global Step: 36200   Required: 37 hours
Training: 2025-11-30 23:58:29,137-Speed 1100.02 samples/sec   Loss 2.7747 target_logit_mean 0.0009 lma 0.6784  cos_theta_tmp 0.7555  Epoch: 2   Global Step: 36250   Required: 37 hours
Training: 2025-11-30 23:58:46,619-Speed 1098.28 samples/sec   Loss 2.7071 target_logit_mean 0.0007 lma 0.6677  cos_theta_tmp 0.7473  Epoch: 2   Global Step: 36300   Required: 37 hours
Training: 2025-11-30 23:59:04,107-Speed 1097.96 samples/sec   Loss 2.7718 target_logit_mean -0.0008 lma 0.6732  cos_theta_tmp 0.7464  Epoch: 2   Global Step: 36350   Required: 37 hours
Training: 2025-11-30 23:59:21,556-Speed 1100.41 samples/sec   Loss 2.7314 target_logit_mean -0.0003 lma 0.6937  cos_theta_tmp 0.7549  Epoch: 2   Global Step: 36400   Required: 37 hours
Training: 2025-11-30 23:59:39,023-Speed 1099.21 samples/sec   Loss 2.7425 target_logit_mean 0.0004 lma 0.6777  cos_theta_tmp 0.7510  Epoch: 2   Global Step: 36450   Required: 36 hours
Training: 2025-11-30 23:59:56,522-Speed 1097.28 samples/sec   Loss 2.7372 target_logit_mean 0.0012 lma 0.6893  cos_theta_tmp 0.7574  Epoch: 2   Global Step: 36500   Required: 36 hours
Training: 2025-12-01 00:00:13,964-Speed 1100.82 samples/sec   Loss 2.6944 target_logit_mean -0.0012 lma 0.6888  cos_theta_tmp 0.7522  Epoch: 2   Global Step: 36550   Required: 36 hours
Training: 2025-12-01 00:00:31,408-Speed 1100.72 samples/sec   Loss 2.7342 target_logit_mean 0.0022 lma 0.6763  cos_theta_tmp 0.7559  Epoch: 2   Global Step: 36600   Required: 36 hours
Training: 2025-12-01 00:00:48,842-Speed 1101.30 samples/sec   Loss 2.7399 target_logit_mean 0.0009 lma 0.6828  cos_theta_tmp 0.7536  Epoch: 2   Global Step: 36650   Required: 36 hours
Training: 2025-12-01 00:01:06,268-Speed 1101.83 samples/sec   Loss 2.7482 target_logit_mean 0.0015 lma 0.6880  cos_theta_tmp 0.7557  Epoch: 2   Global Step: 36700   Required: 36 hours
Training: 2025-12-01 00:01:23,695-Speed 1101.82 samples/sec   Loss 2.7123 target_logit_mean -0.0009 lma 0.6761  cos_theta_tmp 0.7480  Epoch: 2   Global Step: 36750   Required: 36 hours
Training: 2025-12-01 00:01:41,122-Speed 1101.79 samples/sec   Loss 2.7587 target_logit_mean 0.0020 lma 0.6880  cos_theta_tmp 0.7598  Epoch: 2   Global Step: 36800   Required: 36 hours
Training: 2025-12-01 00:01:58,544-Speed 1102.08 samples/sec   Loss 2.6869 target_logit_mean 0.0011 lma 0.6813  cos_theta_tmp 0.7551  Epoch: 2   Global Step: 36850   Required: 36 hours
Training: 2025-12-01 00:02:15,969-Speed 1101.93 samples/sec   Loss 2.6784 target_logit_mean -0.0008 lma 0.6709  cos_theta_tmp 0.7528  Epoch: 2   Global Step: 36900   Required: 36 hours
Training: 2025-12-01 00:02:33,393-Speed 1101.92 samples/sec   Loss 2.7266 target_logit_mean -0.0002 lma 0.6753  cos_theta_tmp 0.7484  Epoch: 2   Global Step: 36950   Required: 36 hours
Training: 2025-12-01 00:02:50,822-Speed 1101.69 samples/sec   Loss 2.7703 target_logit_mean 0.0000 lma 0.6910  cos_theta_tmp 0.7564  Epoch: 2   Global Step: 37000   Required: 36 hours
Training: 2025-12-01 00:03:08,249-Speed 1101.78 samples/sec   Loss 2.7326 target_logit_mean -0.0010 lma 0.6824  cos_theta_tmp 0.7483  Epoch: 2   Global Step: 37050   Required: 36 hours
Training: 2025-12-01 00:03:25,673-Speed 1101.96 samples/sec   Loss 2.8151 target_logit_mean -0.0018 lma 0.6813  cos_theta_tmp 0.7481  Epoch: 2   Global Step: 37100   Required: 36 hours
Training: 2025-12-01 00:03:43,100-Speed 1101.76 samples/sec   Loss 2.7524 target_logit_mean 0.0030 lma 0.6953  cos_theta_tmp 0.7578  Epoch: 2   Global Step: 37150   Required: 36 hours
Training: 2025-12-01 00:04:00,525-Speed 1101.93 samples/sec   Loss 2.7414 target_logit_mean -0.0006 lma 0.6931  cos_theta_tmp 0.7522  Epoch: 2   Global Step: 37200   Required: 36 hours
Training: 2025-12-01 00:04:17,949-Speed 1101.93 samples/sec   Loss 2.7370 target_logit_mean -0.0029 lma 0.6838  cos_theta_tmp 0.7478  Epoch: 2   Global Step: 37250   Required: 36 hours
Training: 2025-12-01 00:04:35,376-Speed 1101.80 samples/sec   Loss 2.8342 target_logit_mean -0.0004 lma 0.6935  cos_theta_tmp 0.7484  Epoch: 2   Global Step: 37300   Required: 36 hours
Training: 2025-12-01 00:04:52,805-Speed 1101.64 samples/sec   Loss 2.7553 target_logit_mean 0.0014 lma 0.6839  cos_theta_tmp 0.7602  Epoch: 2   Global Step: 37350   Required: 36 hours
Training: 2025-12-01 00:05:10,233-Speed 1101.69 samples/sec   Loss 2.8064 target_logit_mean 0.0020 lma 0.6863  cos_theta_tmp 0.7564  Epoch: 2   Global Step: 37400   Required: 36 hours
Training: 2025-12-01 00:05:27,663-Speed 1101.60 samples/sec   Loss 2.7592 target_logit_mean -0.0013 lma 0.6767  cos_theta_tmp 0.7525  Epoch: 2   Global Step: 37450   Required: 36 hours
Training: 2025-12-01 00:05:45,098-Speed 1101.25 samples/sec   Loss 2.7716 target_logit_mean 0.0003 lma 0.6804  cos_theta_tmp 0.7502  Epoch: 2   Global Step: 37500   Required: 36 hours
Training: 2025-12-01 00:06:02,529-Speed 1101.58 samples/sec   Loss 2.8095 target_logit_mean 0.0014 lma 0.6853  cos_theta_tmp 0.7516  Epoch: 2   Global Step: 37550   Required: 36 hours
Training: 2025-12-01 00:06:20,055-Speed 1095.55 samples/sec   Loss 2.7523 target_logit_mean 0.0011 lma 0.6753  cos_theta_tmp 0.7485  Epoch: 2   Global Step: 37600   Required: 36 hours
Training: 2025-12-01 00:06:37,666-Speed 1090.23 samples/sec   Loss 2.7499 target_logit_mean -0.0039 lma 0.6758  cos_theta_tmp 0.7526  Epoch: 2   Global Step: 37650   Required: 36 hours
Training: 2025-12-01 00:06:55,291-Speed 1089.42 samples/sec   Loss 2.7511 target_logit_mean -0.0006 lma 0.6824  cos_theta_tmp 0.7559  Epoch: 2   Global Step: 37700   Required: 36 hours
Training: 2025-12-01 00:07:12,924-Speed 1088.88 samples/sec   Loss 2.7260 target_logit_mean -0.0056 lma 0.6844  cos_theta_tmp 0.7493  Epoch: 2   Global Step: 37750   Required: 36 hours
Training: 2025-12-01 00:07:30,534-Speed 1090.32 samples/sec   Loss 2.7385 target_logit_mean 0.0002 lma 0.6770  cos_theta_tmp 0.7509  Epoch: 2   Global Step: 37800   Required: 36 hours
Training: 2025-12-01 00:07:48,117-Speed 1092.02 samples/sec   Loss 2.7150 target_logit_mean 0.0002 lma 0.6896  cos_theta_tmp 0.7576  Epoch: 2   Global Step: 37850   Required: 36 hours
Training: 2025-12-01 00:08:05,670-Speed 1093.86 samples/sec   Loss 2.7601 target_logit_mean 0.0027 lma 0.6795  cos_theta_tmp 0.7535  Epoch: 2   Global Step: 37900   Required: 36 hours
Training: 2025-12-01 00:08:23,257-Speed 1091.76 samples/sec   Loss 2.7462 target_logit_mean -0.0002 lma 0.6906  cos_theta_tmp 0.7561  Epoch: 2   Global Step: 37950   Required: 36 hours
Training: 2025-12-01 00:08:40,865-Speed 1090.48 samples/sec   Loss 2.7521 target_logit_mean -0.0000 lma 0.6849  cos_theta_tmp 0.7516  Epoch: 2   Global Step: 38000   Required: 36 hours
Training: 2025-12-01 00:08:58,479-Speed 1090.10 samples/sec   Loss 2.6867 target_logit_mean -0.0010 lma 0.6875  cos_theta_tmp 0.7560  Epoch: 2   Global Step: 38050   Required: 36 hours
Training: 2025-12-01 00:09:16,130-Speed 1087.80 samples/sec   Loss 2.6996 target_logit_mean 0.0021 lma 0.6782  cos_theta_tmp 0.7499  Epoch: 2   Global Step: 38100   Required: 36 hours
Training: 2025-12-01 00:09:33,732-Speed 1090.79 samples/sec   Loss 2.6585 target_logit_mean -0.0010 lma 0.6863  cos_theta_tmp 0.7574  Epoch: 2   Global Step: 38150   Required: 36 hours
Training: 2025-12-01 00:09:51,206-Speed 1098.85 samples/sec   Loss 2.7390 target_logit_mean -0.0001 lma 0.6855  cos_theta_tmp 0.7567  Epoch: 2   Global Step: 38200   Required: 36 hours
Training: 2025-12-01 00:10:08,731-Speed 1095.61 samples/sec   Loss 2.8036 target_logit_mean -0.0033 lma 0.6760  cos_theta_tmp 0.7451  Epoch: 2   Global Step: 38250   Required: 36 hours
Training: 2025-12-01 00:10:26,157-Speed 1101.81 samples/sec   Loss 2.7112 target_logit_mean -0.0000 lma 0.6909  cos_theta_tmp 0.7634  Epoch: 2   Global Step: 38300   Required: 36 hours
Training: 2025-12-01 00:10:43,582-Speed 1101.96 samples/sec   Loss 2.7695 target_logit_mean -0.0013 lma 0.6753  cos_theta_tmp 0.7534  Epoch: 2   Global Step: 38350   Required: 36 hours
Training: 2025-12-01 00:11:01,011-Speed 1101.62 samples/sec   Loss 2.7193 target_logit_mean 0.0017 lma 0.6886  cos_theta_tmp 0.7627  Epoch: 2   Global Step: 38400   Required: 36 hours
Training: 2025-12-01 00:11:18,437-Speed 1101.82 samples/sec   Loss 2.7217 target_logit_mean 0.0012 lma 0.6872  cos_theta_tmp 0.7600  Epoch: 2   Global Step: 38450   Required: 36 hours
Training: 2025-12-01 00:11:35,887-Speed 1100.35 samples/sec   Loss 2.7446 target_logit_mean -0.0004 lma 0.6718  cos_theta_tmp 0.7447  Epoch: 2   Global Step: 38500   Required: 36 hours
Training: 2025-12-01 00:11:53,495-Speed 1090.44 samples/sec   Loss 2.7211 target_logit_mean -0.0019 lma 0.6910  cos_theta_tmp 0.7533  Epoch: 2   Global Step: 38550   Required: 36 hours
Training: 2025-12-01 00:12:11,010-Speed 1096.27 samples/sec   Loss 2.7601 target_logit_mean 0.0018 lma 0.6704  cos_theta_tmp 0.7515  Epoch: 2   Global Step: 38600   Required: 36 hours
Training: 2025-12-01 00:12:28,680-Speed 1086.61 samples/sec   Loss 2.7005 target_logit_mean 0.0019 lma 0.6724  cos_theta_tmp 0.7440  Epoch: 2   Global Step: 38650   Required: 36 hours
Training: 2025-12-01 00:12:46,274-Speed 1091.30 samples/sec   Loss 2.7168 target_logit_mean 0.0018 lma 0.6777  cos_theta_tmp 0.7561  Epoch: 2   Global Step: 38700   Required: 36 hours
Training: 2025-12-01 00:13:03,887-Speed 1090.16 samples/sec   Loss 2.7584 target_logit_mean 0.0004 lma 0.6794  cos_theta_tmp 0.7565  Epoch: 2   Global Step: 38750   Required: 36 hours
Training: 2025-12-01 00:13:21,324-Speed 1101.16 samples/sec   Loss 2.7062 target_logit_mean 0.0011 lma 0.6802  cos_theta_tmp 0.7528  Epoch: 2   Global Step: 38800   Required: 36 hours
Training: 2025-12-01 00:13:38,845-Speed 1095.82 samples/sec   Loss 2.7372 target_logit_mean -0.0022 lma 0.6742  cos_theta_tmp 0.7470  Epoch: 2   Global Step: 38850   Required: 36 hours
Training: 2025-12-01 00:13:56,482-Speed 1088.66 samples/sec   Loss 2.7754 target_logit_mean 0.0009 lma 0.6870  cos_theta_tmp 0.7480  Epoch: 2   Global Step: 38900   Required: 36 hours
Training: 2025-12-01 00:14:14,198-Speed 1083.83 samples/sec   Loss 2.7381 target_logit_mean -0.0010 lma 0.6903  cos_theta_tmp 0.7521  Epoch: 2   Global Step: 38950   Required: 36 hours
Training: 2025-12-01 00:14:31,956-Speed 1081.20 samples/sec   Loss 2.7397 target_logit_mean 0.0017 lma 0.6797  cos_theta_tmp 0.7568  Epoch: 2   Global Step: 39000   Required: 36 hours
Training: 2025-12-01 00:14:49,496-Speed 1094.69 samples/sec   Loss 2.7658 target_logit_mean -0.0033 lma 0.6863  cos_theta_tmp 0.7566  Epoch: 2   Global Step: 39050   Required: 36 hours
Training: 2025-12-01 00:15:06,998-Speed 1097.09 samples/sec   Loss 2.7361 target_logit_mean 0.0020 lma 0.6829  cos_theta_tmp 0.7591  Epoch: 2   Global Step: 39100   Required: 36 hours
Training: 2025-12-01 00:15:24,432-Speed 1101.29 samples/sec   Loss 2.7067 target_logit_mean 0.0002 lma 0.6801  cos_theta_tmp 0.7539  Epoch: 2   Global Step: 39150   Required: 36 hours
Training: 2025-12-01 00:15:41,852-Speed 1102.23 samples/sec   Loss 2.7412 target_logit_mean 0.0009 lma 0.6879  cos_theta_tmp 0.7582  Epoch: 2   Global Step: 39200   Required: 36 hours
Training: 2025-12-01 00:15:59,363-Speed 1096.53 samples/sec   Loss 2.7712 target_logit_mean -0.0008 lma 0.6754  cos_theta_tmp 0.7463  Epoch: 2   Global Step: 39250   Required: 36 hours
Training: 2025-12-01 00:16:16,863-Speed 1097.16 samples/sec   Loss 2.7203 target_logit_mean 0.0011 lma 0.7008  cos_theta_tmp 0.7559  Epoch: 2   Global Step: 39300   Required: 36 hours
Training: 2025-12-01 00:16:34,392-Speed 1095.36 samples/sec   Loss 2.7331 target_logit_mean 0.0001 lma 0.6755  cos_theta_tmp 0.7448  Epoch: 2   Global Step: 39350   Required: 36 hours
Training: 2025-12-01 00:16:52,116-Speed 1083.32 samples/sec   Loss 2.6733 target_logit_mean 0.0010 lma 0.6862  cos_theta_tmp 0.7548  Epoch: 2   Global Step: 39400   Required: 36 hours
Training: 2025-12-01 00:17:09,702-Speed 1091.82 samples/sec   Loss 2.7267 target_logit_mean -0.0002 lma 0.6879  cos_theta_tmp 0.7531  Epoch: 2   Global Step: 39450   Required: 36 hours
Training: 2025-12-01 00:17:27,391-Speed 1085.49 samples/sec   Loss 2.6927 target_logit_mean 0.0003 lma 0.6795  cos_theta_tmp 0.7538  Epoch: 2   Global Step: 39500   Required: 36 hours
Training: 2025-12-01 00:17:45,009-Speed 1089.81 samples/sec   Loss 2.7264 target_logit_mean 0.0011 lma 0.6925  cos_theta_tmp 0.7615  Epoch: 2   Global Step: 39550   Required: 36 hours
Training: 2025-12-01 00:18:02,569-Speed 1093.43 samples/sec   Loss 2.7049 target_logit_mean 0.0003 lma 0.6706  cos_theta_tmp 0.7541  Epoch: 2   Global Step: 39600   Required: 36 hours
Training: 2025-12-01 00:18:19,974-Speed 1103.17 samples/sec   Loss 2.6879 target_logit_mean -0.0004 lma 0.6909  cos_theta_tmp 0.7556  Epoch: 2   Global Step: 39650   Required: 36 hours
Training: 2025-12-01 00:18:37,499-Speed 1095.62 samples/sec   Loss 2.7266 target_logit_mean -0.0003 lma 0.6755  cos_theta_tmp 0.7542  Epoch: 2   Global Step: 39700   Required: 36 hours
Training: 2025-12-01 00:18:55,107-Speed 1090.44 samples/sec   Loss 2.6567 target_logit_mean 0.0032 lma 0.6920  cos_theta_tmp 0.7509  Epoch: 2   Global Step: 39750   Required: 36 hours
Training: 2025-12-01 00:19:12,725-Speed 1089.84 samples/sec   Loss 2.6665 target_logit_mean 0.0016 lma 0.6930  cos_theta_tmp 0.7528  Epoch: 2   Global Step: 39800   Required: 36 hours
Training: 2025-12-01 00:19:30,329-Speed 1090.72 samples/sec   Loss 2.7009 target_logit_mean -0.0006 lma 0.6831  cos_theta_tmp 0.7498  Epoch: 2   Global Step: 39850   Required: 36 hours
Training: 2025-12-01 00:19:47,933-Speed 1090.67 samples/sec   Loss 2.7111 target_logit_mean 0.0006 lma 0.6937  cos_theta_tmp 0.7538  Epoch: 2   Global Step: 39900   Required: 36 hours
Training: 2025-12-01 00:20:05,407-Speed 1098.82 samples/sec   Loss 2.7301 target_logit_mean 0.0019 lma 0.6904  cos_theta_tmp 0.7553  Epoch: 2   Global Step: 39950   Required: 36 hours
Training: 2025-12-01 00:20:22,918-Speed 1096.48 samples/sec   Loss 2.7028 target_logit_mean -0.0015 lma 0.6772  cos_theta_tmp 0.7568  Epoch: 2   Global Step: 40000   Required: 36 hours
Training: 2025-12-01 00:20:40,360-Speed 1100.88 samples/sec   Loss 2.7543 target_logit_mean 0.0031 lma 0.6799  cos_theta_tmp 0.7495  Epoch: 2   Global Step: 40050   Required: 36 hours
Training: 2025-12-01 00:20:57,867-Speed 1096.71 samples/sec   Loss 2.7001 target_logit_mean -0.0001 lma 0.6693  cos_theta_tmp 0.7582  Epoch: 2   Global Step: 40100   Required: 36 hours
Training: 2025-12-01 00:21:15,498-Speed 1089.02 samples/sec   Loss 2.7102 target_logit_mean 0.0018 lma 0.6850  cos_theta_tmp 0.7581  Epoch: 2   Global Step: 40150   Required: 36 hours
Training: 2025-12-01 00:21:33,020-Speed 1095.81 samples/sec   Loss 2.6740 target_logit_mean 0.0019 lma 0.6946  cos_theta_tmp 0.7575  Epoch: 2   Global Step: 40200   Required: 36 hours
Training: 2025-12-01 00:21:50,583-Speed 1093.23 samples/sec   Loss 2.6955 target_logit_mean 0.0012 lma 0.6884  cos_theta_tmp 0.7530  Epoch: 2   Global Step: 40250   Required: 36 hours
Training: 2025-12-01 00:22:08,240-Speed 1087.45 samples/sec   Loss 2.6450 target_logit_mean -0.0004 lma 0.6920  cos_theta_tmp 0.7479  Epoch: 2   Global Step: 40300   Required: 36 hours
Training: 2025-12-01 00:22:25,959-Speed 1083.61 samples/sec   Loss 2.7233 target_logit_mean -0.0012 lma 0.6852  cos_theta_tmp 0.7578  Epoch: 2   Global Step: 40350   Required: 36 hours
Training: 2025-12-01 00:22:43,516-Speed 1093.63 samples/sec   Loss 2.6403 target_logit_mean 0.0007 lma 0.6912  cos_theta_tmp 0.7534  Epoch: 2   Global Step: 40400   Required: 36 hours
Training: 2025-12-01 00:23:01,110-Speed 1091.29 samples/sec   Loss 2.6746 target_logit_mean 0.0021 lma 0.6774  cos_theta_tmp 0.7493  Epoch: 2   Global Step: 40450   Required: 36 hours
Training: 2025-12-01 00:23:18,685-Speed 1092.52 samples/sec   Loss 2.7437 target_logit_mean 0.0000 lma 0.6799  cos_theta_tmp 0.7486  Epoch: 2   Global Step: 40500   Required: 36 hours
Training: 2025-12-01 00:23:36,264-Speed 1092.27 samples/sec   Loss 2.7437 target_logit_mean -0.0035 lma 0.6813  cos_theta_tmp 0.7500  Epoch: 2   Global Step: 40550   Required: 36 hours
Training: 2025-12-01 00:23:53,798-Speed 1095.04 samples/sec   Loss 2.7045 target_logit_mean -0.0018 lma 0.6860  cos_theta_tmp 0.7545  Epoch: 2   Global Step: 40600   Required: 36 hours
Training: 2025-12-01 00:24:11,202-Speed 1103.19 samples/sec   Loss 2.6748 target_logit_mean 0.0018 lma 0.6799  cos_theta_tmp 0.7459  Epoch: 2   Global Step: 40650   Required: 36 hours
Training: 2025-12-01 00:24:28,698-Speed 1097.44 samples/sec   Loss 2.7057 target_logit_mean 0.0011 lma 0.6766  cos_theta_tmp 0.7525  Epoch: 2   Global Step: 40700   Required: 36 hours
Training: 2025-12-01 00:24:46,100-Speed 1103.37 samples/sec   Loss 2.7282 target_logit_mean 0.0017 lma 0.6778  cos_theta_tmp 0.7572  Epoch: 2   Global Step: 40750   Required: 36 hours
Training: 2025-12-01 00:25:03,503-Speed 1103.30 samples/sec   Loss 2.7227 target_logit_mean -0.0003 lma 0.6959  cos_theta_tmp 0.7575  Epoch: 2   Global Step: 40800   Required: 36 hours
Training: 2025-12-01 00:25:20,905-Speed 1103.32 samples/sec   Loss 2.6979 target_logit_mean 0.0045 lma 0.6831  cos_theta_tmp 0.7566  Epoch: 2   Global Step: 40850   Required: 36 hours
Training: 2025-12-01 00:25:38,310-Speed 1103.22 samples/sec   Loss 2.7009 target_logit_mean 0.0007 lma 0.6683  cos_theta_tmp 0.7532  Epoch: 2   Global Step: 40900   Required: 36 hours
Training: 2025-12-01 00:25:55,819-Speed 1096.61 samples/sec   Loss 2.7403 target_logit_mean -0.0036 lma 0.6821  cos_theta_tmp 0.7521  Epoch: 2   Global Step: 40950   Required: 36 hours
Training: 2025-12-01 00:26:13,451-Speed 1088.95 samples/sec   Loss 2.7229 target_logit_mean -0.0030 lma 0.6853  cos_theta_tmp 0.7579  Epoch: 2   Global Step: 41000   Required: 36 hours
Training: 2025-12-01 00:26:31,008-Speed 1093.62 samples/sec   Loss 2.6977 target_logit_mean 0.0003 lma 0.6849  cos_theta_tmp 0.7512  Epoch: 2   Global Step: 41050   Required: 36 hours
Training: 2025-12-01 00:26:48,555-Speed 1094.22 samples/sec   Loss 2.6789 target_logit_mean -0.0004 lma 0.6783  cos_theta_tmp 0.7513  Epoch: 2   Global Step: 41100   Required: 36 hours
Training: 2025-12-01 00:27:06,130-Speed 1092.49 samples/sec   Loss 2.7061 target_logit_mean -0.0003 lma 0.6718  cos_theta_tmp 0.7528  Epoch: 2   Global Step: 41150   Required: 36 hours
Training: 2025-12-01 00:27:23,664-Speed 1095.07 samples/sec   Loss 2.7043 target_logit_mean 0.0020 lma 0.6842  cos_theta_tmp 0.7567  Epoch: 2   Global Step: 41200   Required: 36 hours
Training: 2025-12-01 00:27:41,070-Speed 1103.09 samples/sec   Loss 2.6929 target_logit_mean 0.0034 lma 0.6827  cos_theta_tmp 0.7586  Epoch: 2   Global Step: 41250   Required: 36 hours
Training: 2025-12-01 00:27:58,480-Speed 1102.83 samples/sec   Loss 2.7263 target_logit_mean -0.0021 lma 0.6790  cos_theta_tmp 0.7539  Epoch: 2   Global Step: 41300   Required: 36 hours
Training: 2025-12-01 00:28:15,917-Speed 1101.20 samples/sec   Loss 2.7642 target_logit_mean -0.0002 lma 0.6859  cos_theta_tmp 0.7520  Epoch: 2   Global Step: 41350   Required: 36 hours
Training: 2025-12-01 00:28:33,562-Speed 1088.12 samples/sec   Loss 2.6929 target_logit_mean 0.0018 lma 0.6806  cos_theta_tmp 0.7620  Epoch: 2   Global Step: 41400   Required: 36 hours
Training: 2025-12-01 00:28:51,127-Speed 1093.16 samples/sec   Loss 2.6389 target_logit_mean 0.0017 lma 0.6882  cos_theta_tmp 0.7609  Epoch: 2   Global Step: 41450   Required: 36 hours
Training: 2025-12-01 00:29:08,692-Speed 1093.07 samples/sec   Loss 2.7320 target_logit_mean -0.0007 lma 0.6871  cos_theta_tmp 0.7600  Epoch: 2   Global Step: 41500   Required: 36 hours
Training: 2025-12-01 00:29:26,258-Speed 1093.07 samples/sec   Loss 2.7054 target_logit_mean 0.0008 lma 0.6929  cos_theta_tmp 0.7602  Epoch: 2   Global Step: 41550   Required: 36 hours
Training: 2025-12-01 00:29:43,868-Speed 1090.32 samples/sec   Loss 2.7392 target_logit_mean 0.0028 lma 0.6777  cos_theta_tmp 0.7516  Epoch: 2   Global Step: 41600   Required: 36 hours
Training: 2025-12-01 00:30:01,486-Speed 1089.83 samples/sec   Loss 2.7178 target_logit_mean -0.0002 lma 0.6829  cos_theta_tmp 0.7564  Epoch: 2   Global Step: 41650   Required: 36 hours
Training: 2025-12-01 00:30:19,056-Speed 1092.83 samples/sec   Loss 2.6894 target_logit_mean -0.0002 lma 0.6747  cos_theta_tmp 0.7543  Epoch: 2   Global Step: 41700   Required: 36 hours
Training: 2025-12-01 00:30:36,651-Speed 1091.28 samples/sec   Loss 2.6645 target_logit_mean 0.0011 lma 0.6848  cos_theta_tmp 0.7609  Epoch: 2   Global Step: 41750   Required: 36 hours
Training: 2025-12-01 00:30:54,278-Speed 1089.26 samples/sec   Loss 2.6450 target_logit_mean -0.0009 lma 0.6895  cos_theta_tmp 0.7582  Epoch: 2   Global Step: 41800   Required: 36 hours
Training: 2025-12-01 00:31:11,842-Speed 1093.15 samples/sec   Loss 2.7312 target_logit_mean -0.0017 lma 0.6745  cos_theta_tmp 0.7529  Epoch: 2   Global Step: 41850   Required: 36 hours
Training: 2025-12-01 00:31:29,247-Speed 1103.22 samples/sec   Loss 2.6880 target_logit_mean 0.0006 lma 0.6848  cos_theta_tmp 0.7551  Epoch: 2   Global Step: 41900   Required: 36 hours
Training: 2025-12-01 00:31:46,664-Speed 1102.43 samples/sec   Loss 2.6743 target_logit_mean 0.0020 lma 0.6824  cos_theta_tmp 0.7578  Epoch: 2   Global Step: 41950   Required: 36 hours
Training: 2025-12-01 00:32:04,071-Speed 1102.99 samples/sec   Loss 2.6350 target_logit_mean 0.0009 lma 0.6828  cos_theta_tmp 0.7551  Epoch: 2   Global Step: 42000   Required: 36 hours
Training: 2025-12-01 00:32:21,601-Speed 1095.29 samples/sec   Loss 2.6685 target_logit_mean 0.0029 lma 0.6936  cos_theta_tmp 0.7603  Epoch: 2   Global Step: 42050   Required: 36 hours
Training: 2025-12-01 00:32:39,136-Speed 1095.03 samples/sec   Loss 2.7369 target_logit_mean 0.0014 lma 0.6769  cos_theta_tmp 0.7519  Epoch: 2   Global Step: 42100   Required: 36 hours
Training: 2025-12-01 00:32:56,718-Speed 1092.00 samples/sec   Loss 2.6780 target_logit_mean 0.0005 lma 0.6767  cos_theta_tmp 0.7543  Epoch: 2   Global Step: 42150   Required: 36 hours
Training: 2025-12-01 00:33:14,255-Speed 1094.87 samples/sec   Loss 2.6745 target_logit_mean 0.0013 lma 0.6813  cos_theta_tmp 0.7589  Epoch: 2   Global Step: 42200   Required: 36 hours
Training: 2025-12-01 00:33:31,660-Speed 1103.21 samples/sec   Loss 2.7248 target_logit_mean 0.0000 lma 0.6711  cos_theta_tmp 0.7517  Epoch: 2   Global Step: 42250   Required: 36 hours
Training: 2025-12-01 00:33:49,063-Speed 1103.31 samples/sec   Loss 2.7262 target_logit_mean -0.0008 lma 0.6821  cos_theta_tmp 0.7578  Epoch: 2   Global Step: 42300   Required: 36 hours
Training: 2025-12-01 00:34:06,473-Speed 1102.83 samples/sec   Loss 2.7060 target_logit_mean -0.0005 lma 0.6847  cos_theta_tmp 0.7567  Epoch: 2   Global Step: 42350   Required: 36 hours
Training: 2025-12-01 00:34:23,882-Speed 1102.90 samples/sec   Loss 2.6819 target_logit_mean -0.0000 lma 0.6772  cos_theta_tmp 0.7530  Epoch: 2   Global Step: 42400   Required: 36 hours
Training: 2025-12-01 00:34:41,300-Speed 1102.37 samples/sec   Loss 2.7046 target_logit_mean -0.0016 lma 0.6900  cos_theta_tmp 0.7534  Epoch: 2   Global Step: 42450   Required: 36 hours
Training: 2025-12-01 00:34:58,712-Speed 1102.74 samples/sec   Loss 2.6740 target_logit_mean 0.0005 lma 0.6848  cos_theta_tmp 0.7596  Epoch: 2   Global Step: 42500   Required: 36 hours
Training: 2025-12-01 00:35:16,266-Speed 1093.79 samples/sec   Loss 2.7435 target_logit_mean 0.0020 lma 0.6862  cos_theta_tmp 0.7510  Epoch: 2   Global Step: 42550   Required: 36 hours
Training: 2025-12-01 00:35:33,835-Speed 1092.84 samples/sec   Loss 2.6594 target_logit_mean 0.0010 lma 0.6778  cos_theta_tmp 0.7507  Epoch: 2   Global Step: 42600   Required: 36 hours
Training: 2025-12-01 00:35:51,427-Speed 1091.47 samples/sec   Loss 2.6632 target_logit_mean -0.0010 lma 0.6771  cos_theta_tmp 0.7580  Epoch: 2   Global Step: 42650   Required: 36 hours
Training: 2025-12-01 00:36:09,069-Speed 1088.36 samples/sec   Loss 2.6810 target_logit_mean -0.0019 lma 0.6750  cos_theta_tmp 0.7517  Epoch: 2   Global Step: 42700   Required: 36 hours
Training: 2025-12-01 00:36:26,787-Speed 1083.64 samples/sec   Loss 2.6810 target_logit_mean -0.0016 lma 0.6854  cos_theta_tmp 0.7568  Epoch: 2   Global Step: 42750   Required: 36 hours
Training: 2025-12-01 00:36:44,460-Speed 1086.48 samples/sec   Loss 2.7113 target_logit_mean 0.0007 lma 0.6909  cos_theta_tmp 0.7541  Epoch: 2   Global Step: 42800   Required: 36 hours
Training: 2025-12-01 00:37:02,282-Speed 1077.35 samples/sec   Loss 2.6599 target_logit_mean -0.0013 lma 0.6818  cos_theta_tmp 0.7511  Epoch: 2   Global Step: 42850   Required: 36 hours
Training: 2025-12-01 00:37:19,984-Speed 1084.63 samples/sec   Loss 2.6438 target_logit_mean 0.0007 lma 0.6809  cos_theta_tmp 0.7606  Epoch: 2   Global Step: 42900   Required: 36 hours
Training: 2025-12-01 00:37:37,717-Speed 1082.79 samples/sec   Loss 2.7000 target_logit_mean -0.0020 lma 0.6853  cos_theta_tmp 0.7551  Epoch: 2   Global Step: 42950   Required: 36 hours
Training: 2025-12-01 00:37:55,484-Speed 1080.68 samples/sec   Loss 2.6867 target_logit_mean 0.0000 lma 0.6816  cos_theta_tmp 0.7543  Epoch: 2   Global Step: 43000   Required: 36 hours
Training: 2025-12-01 00:38:13,462-Speed 1068.00 samples/sec   Loss 2.6082 target_logit_mean -0.0003 lma 0.6573  cos_theta_tmp 0.7469  Epoch: 2   Global Step: 43050   Required: 36 hours
Training: 2025-12-01 00:38:31,445-Speed 1067.69 samples/sec   Loss 2.6790 target_logit_mean 0.0018 lma 0.6867  cos_theta_tmp 0.7553  Epoch: 2   Global Step: 43100   Required: 36 hours
Training: 2025-12-01 00:38:49,315-Speed 1074.48 samples/sec   Loss 2.6816 target_logit_mean -0.0005 lma 0.6897  cos_theta_tmp 0.7572  Epoch: 2   Global Step: 43150   Required: 36 hours
Training: 2025-12-01 00:39:07,247-Speed 1070.78 samples/sec   Loss 2.7659 target_logit_mean -0.0005 lma 0.6787  cos_theta_tmp 0.7562  Epoch: 2   Global Step: 43200   Required: 36 hours
Training: 2025-12-01 00:39:25,031-Speed 1079.65 samples/sec   Loss 2.6667 target_logit_mean 0.0023 lma 0.6863  cos_theta_tmp 0.7625  Epoch: 2   Global Step: 43250   Required: 36 hours
Training: 2025-12-01 00:39:42,927-Speed 1072.86 samples/sec   Loss 2.7188 target_logit_mean -0.0021 lma 0.6704  cos_theta_tmp 0.7559  Epoch: 2   Global Step: 43300   Required: 36 hours
Training: 2025-12-01 00:40:00,703-Speed 1080.14 samples/sec   Loss 2.7143 target_logit_mean -0.0005 lma 0.6717  cos_theta_tmp 0.7517  Epoch: 2   Global Step: 43350   Required: 36 hours
Training: 2025-12-01 00:40:18,681-Speed 1068.61 samples/sec   Loss 2.6921 target_logit_mean -0.0031 lma 0.6915  cos_theta_tmp 0.7548  Epoch: 2   Global Step: 43400   Required: 36 hours
Training: 2025-12-01 00:40:36,663-Speed 1068.41 samples/sec   Loss 2.7108 target_logit_mean 0.0008 lma 0.6796  cos_theta_tmp 0.7553  Epoch: 2   Global Step: 43450   Required: 36 hours
Training: 2025-12-01 00:40:54,616-Speed 1069.46 samples/sec   Loss 2.6512 target_logit_mean 0.0032 lma 0.6854  cos_theta_tmp 0.7569  Epoch: 2   Global Step: 43500   Required: 36 hours
Training: 2025-12-01 00:41:12,503-Speed 1073.45 samples/sec   Loss 2.6744 target_logit_mean 0.0023 lma 0.6791  cos_theta_tmp 0.7535  Epoch: 2   Global Step: 43550   Required: 36 hours
Training: 2025-12-01 00:41:30,199-Speed 1085.03 samples/sec   Loss 2.6936 target_logit_mean 0.0024 lma 0.6911  cos_theta_tmp 0.7564  Epoch: 2   Global Step: 43600   Required: 36 hours
Training: 2025-12-01 00:41:47,747-Speed 1094.16 samples/sec   Loss 2.6737 target_logit_mean 0.0003 lma 0.6771  cos_theta_tmp 0.7560  Epoch: 2   Global Step: 43650   Required: 36 hours
Training: 2025-12-01 00:42:05,361-Speed 1090.10 samples/sec   Loss 2.6605 target_logit_mean 0.0009 lma 0.6957  cos_theta_tmp 0.7595  Epoch: 2   Global Step: 43700   Required: 35 hours
Training: 2025-12-01 00:42:22,974-Speed 1090.14 samples/sec   Loss 2.6479 target_logit_mean -0.0020 lma 0.6820  cos_theta_tmp 0.7617  Epoch: 2   Global Step: 43750   Required: 35 hours
Training: 2025-12-01 00:42:40,500-Speed 1095.53 samples/sec   Loss 2.6451 target_logit_mean -0.0009 lma 0.6929  cos_theta_tmp 0.7606  Epoch: 2   Global Step: 43800   Required: 35 hours
Training: 2025-12-01 00:42:58,121-Speed 1089.65 samples/sec   Loss 2.6764 target_logit_mean -0.0013 lma 0.6804  cos_theta_tmp 0.7470  Epoch: 2   Global Step: 43850   Required: 35 hours
Training: 2025-12-01 00:43:15,750-Speed 1089.12 samples/sec   Loss 2.6791 target_logit_mean 0.0003 lma 0.6810  cos_theta_tmp 0.7515  Epoch: 2   Global Step: 43900   Required: 35 hours
Training: 2025-12-01 00:43:33,292-Speed 1094.57 samples/sec   Loss 2.6508 target_logit_mean -0.0019 lma 0.6822  cos_theta_tmp 0.7515  Epoch: 2   Global Step: 43950   Required: 35 hours
Training: 2025-12-01 00:43:50,711-Speed 1102.26 samples/sec   Loss 2.7129 target_logit_mean 0.0008 lma 0.6835  cos_theta_tmp 0.7632  Epoch: 2   Global Step: 44000   Required: 35 hours
Training: 2025-12-01 00:44:08,122-Speed 1102.81 samples/sec   Loss 2.6591 target_logit_mean -0.0015 lma 0.6745  cos_theta_tmp 0.7494  Epoch: 2   Global Step: 44050   Required: 35 hours
Training: 2025-12-01 00:44:25,535-Speed 1102.63 samples/sec   Loss 2.6758 target_logit_mean 0.0012 lma 0.6803  cos_theta_tmp 0.7574  Epoch: 2   Global Step: 44100   Required: 35 hours
Training: 2025-12-01 00:44:42,961-Speed 1101.84 samples/sec   Loss 2.7075 target_logit_mean 0.0010 lma 0.6853  cos_theta_tmp 0.7544  Epoch: 2   Global Step: 44150   Required: 35 hours
Training: 2025-12-01 00:45:00,370-Speed 1102.96 samples/sec   Loss 2.6114 target_logit_mean 0.0027 lma 0.6742  cos_theta_tmp 0.7567  Epoch: 2   Global Step: 44200   Required: 35 hours
Training: 2025-12-01 00:45:17,785-Speed 1102.52 samples/sec   Loss 2.6298 target_logit_mean -0.0026 lma 0.6888  cos_theta_tmp 0.7519  Epoch: 2   Global Step: 44250   Required: 35 hours
Training: 2025-12-01 00:45:35,193-Speed 1102.96 samples/sec   Loss 2.6757 target_logit_mean 0.0025 lma 0.6692  cos_theta_tmp 0.7609  Epoch: 2   Global Step: 44300   Required: 35 hours
Training: 2025-12-01 00:45:52,722-Speed 1095.36 samples/sec   Loss 2.6435 target_logit_mean 0.0025 lma 0.6904  cos_theta_tmp 0.7535  Epoch: 2   Global Step: 44350   Required: 35 hours
Training: 2025-12-01 00:46:10,373-Speed 1087.79 samples/sec   Loss 2.6993 target_logit_mean -0.0014 lma 0.6797  cos_theta_tmp 0.7478  Epoch: 2   Global Step: 44400   Required: 35 hours
Training: 2025-12-01 00:46:27,965-Speed 1091.45 samples/sec   Loss 2.6811 target_logit_mean -0.0000 lma 0.6786  cos_theta_tmp 0.7521  Epoch: 2   Global Step: 44450   Required: 35 hours
Training: 2025-12-01 00:46:45,547-Speed 1092.02 samples/sec   Loss 2.6801 target_logit_mean 0.0006 lma 0.6799  cos_theta_tmp 0.7576  Epoch: 2   Global Step: 44500   Required: 35 hours
Training: 2025-12-01 00:47:03,157-Speed 1090.33 samples/sec   Loss 2.6817 target_logit_mean 0.0015 lma 0.6802  cos_theta_tmp 0.7542  Epoch: 2   Global Step: 44550   Required: 35 hours
Training: 2025-12-01 00:47:20,727-Speed 1092.83 samples/sec   Loss 2.6530 target_logit_mean -0.0006 lma 0.6798  cos_theta_tmp 0.7566  Epoch: 2   Global Step: 44600   Required: 35 hours
Training: 2025-12-01 00:47:38,283-Speed 1093.70 samples/sec   Loss 2.6504 target_logit_mean -0.0016 lma 0.6862  cos_theta_tmp 0.7556  Epoch: 2   Global Step: 44650   Required: 35 hours
Training: 2025-12-01 00:47:55,880-Speed 1091.15 samples/sec   Loss 2.7053 target_logit_mean 0.0030 lma 0.6826  cos_theta_tmp 0.7555  Epoch: 2   Global Step: 44700   Required: 35 hours
Training: 2025-12-01 00:48:13,467-Speed 1091.71 samples/sec   Loss 2.6685 target_logit_mean -0.0008 lma 0.6876  cos_theta_tmp 0.7572  Epoch: 2   Global Step: 44750   Required: 35 hours
Training: 2025-12-01 00:48:31,071-Speed 1090.70 samples/sec   Loss 2.6862 target_logit_mean 0.0008 lma 0.6821  cos_theta_tmp 0.7541  Epoch: 2   Global Step: 44800   Required: 35 hours
Training: 2025-12-01 00:48:48,693-Speed 1089.60 samples/sec   Loss 2.6745 target_logit_mean -0.0002 lma 0.6771  cos_theta_tmp 0.7548  Epoch: 2   Global Step: 44850   Required: 35 hours
Training: 2025-12-01 00:49:06,268-Speed 1092.48 samples/sec   Loss 2.6716 target_logit_mean 0.0014 lma 0.6843  cos_theta_tmp 0.7618  Epoch: 2   Global Step: 44900   Required: 35 hours
Training: 2025-12-01 00:49:23,883-Speed 1090.04 samples/sec   Loss 2.6838 target_logit_mean 0.0006 lma 0.6842  cos_theta_tmp 0.7552  Epoch: 2   Global Step: 44950   Required: 35 hours
Training: 2025-12-01 00:49:41,475-Speed 1091.41 samples/sec   Loss 2.6747 target_logit_mean -0.0013 lma 0.6857  cos_theta_tmp 0.7579  Epoch: 2   Global Step: 45000   Required: 35 hours
Training: 2025-12-01 00:49:59,110-Speed 1088.81 samples/sec   Loss 2.7183 target_logit_mean 0.0013 lma 0.6829  cos_theta_tmp 0.7594  Epoch: 2   Global Step: 45050   Required: 35 hours
Training: 2025-12-01 00:50:16,737-Speed 1089.30 samples/sec   Loss 2.6378 target_logit_mean -0.0011 lma 0.6853  cos_theta_tmp 0.7526  Epoch: 2   Global Step: 45100   Required: 35 hours
Training: 2025-12-01 00:50:34,340-Speed 1090.76 samples/sec   Loss 2.6886 target_logit_mean -0.0009 lma 0.6854  cos_theta_tmp 0.7573  Epoch: 2   Global Step: 45150   Required: 35 hours
Training: 2025-12-01 00:50:51,896-Speed 1093.63 samples/sec   Loss 2.6218 target_logit_mean -0.0007 lma 0.6789  cos_theta_tmp 0.7549  Epoch: 2   Global Step: 45200   Required: 35 hours
Training: 2025-12-01 00:51:09,460-Speed 1093.23 samples/sec   Loss 2.6477 target_logit_mean 0.0007 lma 0.6901  cos_theta_tmp 0.7603  Epoch: 2   Global Step: 45250   Required: 35 hours
Training: 2025-12-01 00:51:26,973-Speed 1096.34 samples/sec   Loss 2.6622 target_logit_mean -0.0020 lma 0.6738  cos_theta_tmp 0.7493  Epoch: 2   Global Step: 45300   Required: 35 hours
Training: 2025-12-01 00:51:44,604-Speed 1089.04 samples/sec   Loss 2.6918 target_logit_mean 0.0005 lma 0.6856  cos_theta_tmp 0.7506  Epoch: 2   Global Step: 45350   Required: 35 hours
Training: 2025-12-01 00:52:02,191-Speed 1091.71 samples/sec   Loss 2.6468 target_logit_mean -0.0016 lma 0.6824  cos_theta_tmp 0.7577  Epoch: 2   Global Step: 45400   Required: 35 hours
Training: 2025-12-01 00:52:19,779-Speed 1091.71 samples/sec   Loss 2.7065 target_logit_mean -0.0005 lma 0.6771  cos_theta_tmp 0.7517  Epoch: 2   Global Step: 45450   Required: 35 hours
Training: 2025-12-01 00:52:45,784-[lfw][45489]XNorm: 23.695317
Training: 2025-12-01 00:52:45,784-[lfw][45489]Accuracy-Flip: 0.99050+-0.00448
Training: 2025-12-01 00:52:45,784-[lfw][45489]Accuracy-Highest: 0.99050
Training: 2025-12-01 00:52:59,955-[cfp_fp][45489]XNorm: 19.108880
Training: 2025-12-01 00:52:59,955-[cfp_fp][45489]Accuracy-Flip: 0.88071+-0.01625
Training: 2025-12-01 00:52:59,955-[cfp_fp][45489]Accuracy-Highest: 0.88071
Training: 2025-12-01 00:53:14,179-[cfp_ff][45489]XNorm: 22.951574
Training: 2025-12-01 00:53:14,179-[cfp_ff][45489]Accuracy-Flip: 0.98786+-0.00434
Training: 2025-12-01 00:53:14,179-[cfp_ff][45489]Accuracy-Highest: 0.98986
Training: 2025-12-01 00:53:26,317-[agedb_30][45489]XNorm: 22.756836
Training: 2025-12-01 00:53:26,317-[agedb_30][45489]Accuracy-Flip: 0.92417+-0.01385
Training: 2025-12-01 00:53:26,317-[agedb_30][45489]Accuracy-Highest: 0.92717
Training: 2025-12-01 00:53:39,912-[calfw][45489]XNorm: 23.639580
Training: 2025-12-01 00:53:39,912-[calfw][45489]Accuracy-Flip: 0.93317+-0.01201
Training: 2025-12-01 00:53:39,912-[calfw][45489]Accuracy-Highest: 0.93883
Training: 2025-12-01 00:53:52,324-[cplfw][45489]XNorm: 19.335570
Training: 2025-12-01 00:53:52,325-[cplfw][45489]Accuracy-Flip: 0.85333+-0.01624
Training: 2025-12-01 00:53:52,325-[cplfw][45489]Accuracy-Highest: 0.85333
Training: 2025-12-01 00:54:02,694-[vgg2_fp][45489]XNorm: 19.791638
Training: 2025-12-01 00:54:02,695-[vgg2_fp][45489]Accuracy-Flip: 0.88220+-0.01060
Training: 2025-12-01 00:54:02,695-[vgg2_fp][45489]Accuracy-Highest: 0.88220
Training: 2025-12-01 00:54:24,504-Speed 153.94 samples/sec   Loss 2.6749 target_logit_mean -0.0006 lma 0.6869  cos_theta_tmp 0.7589  Epoch: 3   Global Step: 45500   Required: 35 hours
Training: 2025-12-01 00:54:41,852-Speed 1106.82 samples/sec   Loss 2.6344 target_logit_mean -0.0039 lma 0.6863  cos_theta_tmp 0.7541  Epoch: 3   Global Step: 45550   Required: 35 hours
Training: 2025-12-01 00:54:59,353-Speed 1097.10 samples/sec   Loss 2.6875 target_logit_mean -0.0020 lma 0.6890  cos_theta_tmp 0.7517  Epoch: 3   Global Step: 45600   Required: 35 hours
Training: 2025-12-01 00:55:16,908-Speed 1093.76 samples/sec   Loss 2.6424 target_logit_mean 0.0020 lma 0.6917  cos_theta_tmp 0.7516  Epoch: 3   Global Step: 45650   Required: 35 hours
Training: 2025-12-01 00:55:34,400-Speed 1097.67 samples/sec   Loss 2.6330 target_logit_mean -0.0001 lma 0.6783  cos_theta_tmp 0.7470  Epoch: 3   Global Step: 45700   Required: 35 hours
Training: 2025-12-01 00:55:51,865-Speed 1099.39 samples/sec   Loss 2.7061 target_logit_mean -0.0013 lma 0.6899  cos_theta_tmp 0.7531  Epoch: 3   Global Step: 45750   Required: 35 hours
Training: 2025-12-01 00:56:09,496-Speed 1089.00 samples/sec   Loss 2.7278 target_logit_mean 0.0015 lma 0.6862  cos_theta_tmp 0.7550  Epoch: 3   Global Step: 45800   Required: 35 hours
Training: 2025-12-01 00:56:27,010-Speed 1096.31 samples/sec   Loss 2.6065 target_logit_mean -0.0016 lma 0.6728  cos_theta_tmp 0.7544  Epoch: 3   Global Step: 45850   Required: 35 hours
Training: 2025-12-01 00:56:44,638-Speed 1089.21 samples/sec   Loss 2.6756 target_logit_mean 0.0025 lma 0.6900  cos_theta_tmp 0.7582  Epoch: 3   Global Step: 45900   Required: 35 hours
Training: 2025-12-01 00:57:02,256-Speed 1089.83 samples/sec   Loss 2.6962 target_logit_mean 0.0011 lma 0.6775  cos_theta_tmp 0.7523  Epoch: 3   Global Step: 45950   Required: 35 hours
Training: 2025-12-01 00:57:19,719-Speed 1099.52 samples/sec   Loss 2.6873 target_logit_mean 0.0016 lma 0.6971  cos_theta_tmp 0.7583  Epoch: 3   Global Step: 46000   Required: 35 hours
Training: 2025-12-01 00:57:37,217-Speed 1097.32 samples/sec   Loss 2.6959 target_logit_mean 0.0021 lma 0.6916  cos_theta_tmp 0.7568  Epoch: 3   Global Step: 46050   Required: 35 hours
Training: 2025-12-01 00:57:54,637-Speed 1102.23 samples/sec   Loss 2.6857 target_logit_mean 0.0008 lma 0.6839  cos_theta_tmp 0.7524  Epoch: 3   Global Step: 46100   Required: 35 hours
Training: 2025-12-01 00:58:12,045-Speed 1102.98 samples/sec   Loss 2.6689 target_logit_mean 0.0012 lma 0.6775  cos_theta_tmp 0.7559  Epoch: 3   Global Step: 46150   Required: 35 hours
Training: 2025-12-01 00:58:29,540-Speed 1097.48 samples/sec   Loss 2.6768 target_logit_mean 0.0011 lma 0.6806  cos_theta_tmp 0.7531  Epoch: 3   Global Step: 46200   Required: 35 hours
Training: 2025-12-01 00:58:46,975-Speed 1101.26 samples/sec   Loss 2.6595 target_logit_mean 0.0028 lma 0.6771  cos_theta_tmp 0.7576  Epoch: 3   Global Step: 46250   Required: 35 hours
Training: 2025-12-01 00:59:04,436-Speed 1099.67 samples/sec   Loss 2.6466 target_logit_mean 0.0014 lma 0.6833  cos_theta_tmp 0.7583  Epoch: 3   Global Step: 46300   Required: 35 hours
Training: 2025-12-01 00:59:21,907-Speed 1099.00 samples/sec   Loss 2.6871 target_logit_mean -0.0010 lma 0.6816  cos_theta_tmp 0.7610  Epoch: 3   Global Step: 46350   Required: 35 hours
Training: 2025-12-01 00:59:39,311-Speed 1103.18 samples/sec   Loss 2.6245 target_logit_mean 0.0023 lma 0.6813  cos_theta_tmp 0.7543  Epoch: 3   Global Step: 46400   Required: 35 hours
Training: 2025-12-01 00:59:56,782-Speed 1099.02 samples/sec   Loss 2.6781 target_logit_mean -0.0017 lma 0.6683  cos_theta_tmp 0.7484  Epoch: 3   Global Step: 46450   Required: 35 hours
Training: 2025-12-01 01:00:14,254-Speed 1098.98 samples/sec   Loss 2.6484 target_logit_mean 0.0008 lma 0.6790  cos_theta_tmp 0.7489  Epoch: 3   Global Step: 46500   Required: 35 hours
Training: 2025-12-01 01:00:31,727-Speed 1098.87 samples/sec   Loss 2.6788 target_logit_mean -0.0008 lma 0.6807  cos_theta_tmp 0.7534  Epoch: 3   Global Step: 46550   Required: 35 hours
Training: 2025-12-01 01:00:49,304-Speed 1092.34 samples/sec   Loss 2.6119 target_logit_mean 0.0005 lma 0.6956  cos_theta_tmp 0.7577  Epoch: 3   Global Step: 46600   Required: 35 hours
Training: 2025-12-01 01:01:06,709-Speed 1103.20 samples/sec   Loss 2.6029 target_logit_mean -0.0011 lma 0.6773  cos_theta_tmp 0.7570  Epoch: 3   Global Step: 46650   Required: 35 hours
Training: 2025-12-01 01:01:24,128-Speed 1102.29 samples/sec   Loss 2.5449 target_logit_mean 0.0002 lma 0.6963  cos_theta_tmp 0.7628  Epoch: 3   Global Step: 46700   Required: 35 hours
Training: 2025-12-01 01:01:41,539-Speed 1102.75 samples/sec   Loss 2.5786 target_logit_mean -0.0003 lma 0.6820  cos_theta_tmp 0.7609  Epoch: 3   Global Step: 46750   Required: 35 hours
Training: 2025-12-01 01:01:58,955-Speed 1102.46 samples/sec   Loss 2.6613 target_logit_mean -0.0009 lma 0.6909  cos_theta_tmp 0.7469  Epoch: 3   Global Step: 46800   Required: 35 hours
Training: 2025-12-01 01:02:16,374-Speed 1102.29 samples/sec   Loss 2.6375 target_logit_mean -0.0031 lma 0.6804  cos_theta_tmp 0.7561  Epoch: 3   Global Step: 46850   Required: 35 hours
Training: 2025-12-01 01:02:33,782-Speed 1103.02 samples/sec   Loss 2.6600 target_logit_mean 0.0005 lma 0.6866  cos_theta_tmp 0.7538  Epoch: 3   Global Step: 46900   Required: 35 hours
Training: 2025-12-01 01:02:51,202-Speed 1102.24 samples/sec   Loss 2.6266 target_logit_mean 0.0027 lma 0.6852  cos_theta_tmp 0.7602  Epoch: 3   Global Step: 46950   Required: 35 hours
Training: 2025-12-01 01:03:08,610-Speed 1102.93 samples/sec   Loss 2.6610 target_logit_mean 0.0009 lma 0.6776  cos_theta_tmp 0.7541  Epoch: 3   Global Step: 47000   Required: 35 hours
Training: 2025-12-01 01:03:26,023-Speed 1102.68 samples/sec   Loss 2.6378 target_logit_mean -0.0005 lma 0.6899  cos_theta_tmp 0.7569  Epoch: 3   Global Step: 47050   Required: 35 hours
Training: 2025-12-01 01:03:43,430-Speed 1103.06 samples/sec   Loss 2.6678 target_logit_mean 0.0016 lma 0.6739  cos_theta_tmp 0.7565  Epoch: 3   Global Step: 47100   Required: 35 hours
Training: 2025-12-01 01:04:00,845-Speed 1102.54 samples/sec   Loss 2.6421 target_logit_mean 0.0004 lma 0.6786  cos_theta_tmp 0.7460  Epoch: 3   Global Step: 47150   Required: 35 hours
Training: 2025-12-01 01:04:18,265-Speed 1102.26 samples/sec   Loss 2.6168 target_logit_mean 0.0016 lma 0.6772  cos_theta_tmp 0.7503  Epoch: 3   Global Step: 47200   Required: 35 hours
Training: 2025-12-01 01:04:35,671-Speed 1103.10 samples/sec   Loss 2.6444 target_logit_mean -0.0004 lma 0.6876  cos_theta_tmp 0.7545  Epoch: 3   Global Step: 47250   Required: 35 hours
Training: 2025-12-01 01:04:53,102-Speed 1101.51 samples/sec   Loss 2.6690 target_logit_mean 0.0023 lma 0.6786  cos_theta_tmp 0.7473  Epoch: 3   Global Step: 47300   Required: 35 hours
Training: 2025-12-01 01:05:10,509-Speed 1103.02 samples/sec   Loss 2.6612 target_logit_mean -0.0020 lma 0.6836  cos_theta_tmp 0.7450  Epoch: 3   Global Step: 47350   Required: 35 hours
Training: 2025-12-01 01:05:27,925-Speed 1102.46 samples/sec   Loss 2.6788 target_logit_mean -0.0007 lma 0.6904  cos_theta_tmp 0.7525  Epoch: 3   Global Step: 47400   Required: 35 hours
Training: 2025-12-01 01:05:45,327-Speed 1103.34 samples/sec   Loss 2.6214 target_logit_mean 0.0010 lma 0.6840  cos_theta_tmp 0.7595  Epoch: 3   Global Step: 47450   Required: 35 hours
Training: 2025-12-01 01:06:02,744-Speed 1102.43 samples/sec   Loss 2.6198 target_logit_mean -0.0001 lma 0.6846  cos_theta_tmp 0.7569  Epoch: 3   Global Step: 47500   Required: 35 hours
Training: 2025-12-01 01:06:20,164-Speed 1102.28 samples/sec   Loss 2.6624 target_logit_mean -0.0001 lma 0.6883  cos_theta_tmp 0.7560  Epoch: 3   Global Step: 47550   Required: 35 hours
Training: 2025-12-01 01:06:37,654-Speed 1097.80 samples/sec   Loss 2.6634 target_logit_mean 0.0020 lma 0.6943  cos_theta_tmp 0.7607  Epoch: 3   Global Step: 47600   Required: 35 hours
Training: 2025-12-01 01:06:55,275-Speed 1089.63 samples/sec   Loss 2.6845 target_logit_mean 0.0023 lma 0.6774  cos_theta_tmp 0.7508  Epoch: 3   Global Step: 47650   Required: 35 hours
Training: 2025-12-01 01:07:12,865-Speed 1091.58 samples/sec   Loss 2.6552 target_logit_mean -0.0001 lma 0.6836  cos_theta_tmp 0.7532  Epoch: 3   Global Step: 47700   Required: 35 hours
Training: 2025-12-01 01:07:30,277-Speed 1102.72 samples/sec   Loss 2.7202 target_logit_mean -0.0033 lma 0.6780  cos_theta_tmp 0.7559  Epoch: 3   Global Step: 47750   Required: 35 hours
Training: 2025-12-01 01:07:47,690-Speed 1102.67 samples/sec   Loss 2.6517 target_logit_mean 0.0011 lma 0.6786  cos_theta_tmp 0.7525  Epoch: 3   Global Step: 47800   Required: 35 hours
Training: 2025-12-01 01:08:05,098-Speed 1102.92 samples/sec   Loss 2.7070 target_logit_mean 0.0019 lma 0.6826  cos_theta_tmp 0.7534  Epoch: 3   Global Step: 47850   Required: 35 hours
Training: 2025-12-01 01:08:22,511-Speed 1102.69 samples/sec   Loss 2.6257 target_logit_mean 0.0010 lma 0.6848  cos_theta_tmp 0.7578  Epoch: 3   Global Step: 47900   Required: 35 hours
Training: 2025-12-01 01:08:39,919-Speed 1103.00 samples/sec   Loss 2.6581 target_logit_mean 0.0004 lma 0.6761  cos_theta_tmp 0.7485  Epoch: 3   Global Step: 47950   Required: 35 hours
Training: 2025-12-01 01:08:57,329-Speed 1102.88 samples/sec   Loss 2.6471 target_logit_mean -0.0005 lma 0.6857  cos_theta_tmp 0.7588  Epoch: 3   Global Step: 48000   Required: 35 hours
Training: 2025-12-01 01:09:14,736-Speed 1103.00 samples/sec   Loss 2.6702 target_logit_mean 0.0001 lma 0.6841  cos_theta_tmp 0.7590  Epoch: 3   Global Step: 48050   Required: 35 hours
Training: 2025-12-01 01:09:32,149-Speed 1102.67 samples/sec   Loss 2.6175 target_logit_mean -0.0023 lma 0.6768  cos_theta_tmp 0.7539  Epoch: 3   Global Step: 48100   Required: 35 hours
Training: 2025-12-01 01:09:49,559-Speed 1102.87 samples/sec   Loss 2.5798 target_logit_mean 0.0025 lma 0.6826  cos_theta_tmp 0.7583  Epoch: 3   Global Step: 48150   Required: 35 hours
Training: 2025-12-01 01:10:06,965-Speed 1103.13 samples/sec   Loss 2.6042 target_logit_mean 0.0016 lma 0.6774  cos_theta_tmp 0.7591  Epoch: 3   Global Step: 48200   Required: 35 hours
Training: 2025-12-01 01:10:24,376-Speed 1102.78 samples/sec   Loss 2.6622 target_logit_mean 0.0016 lma 0.6949  cos_theta_tmp 0.7566  Epoch: 3   Global Step: 48250   Required: 35 hours
Training: 2025-12-01 01:10:41,786-Speed 1102.88 samples/sec   Loss 2.6869 target_logit_mean -0.0024 lma 0.6862  cos_theta_tmp 0.7510  Epoch: 3   Global Step: 48300   Required: 35 hours
Training: 2025-12-01 01:10:59,198-Speed 1102.74 samples/sec   Loss 2.6256 target_logit_mean 0.0039 lma 0.6784  cos_theta_tmp 0.7655  Epoch: 3   Global Step: 48350   Required: 35 hours
Training: 2025-12-01 01:11:16,607-Speed 1102.87 samples/sec   Loss 2.6237 target_logit_mean 0.0032 lma 0.6777  cos_theta_tmp 0.7576  Epoch: 3   Global Step: 48400   Required: 35 hours
Training: 2025-12-01 01:11:34,014-Speed 1103.07 samples/sec   Loss 2.6447 target_logit_mean -0.0021 lma 0.6779  cos_theta_tmp 0.7525  Epoch: 3   Global Step: 48450   Required: 35 hours
Training: 2025-12-01 01:11:51,420-Speed 1103.11 samples/sec   Loss 2.6892 target_logit_mean -0.0007 lma 0.6699  cos_theta_tmp 0.7493  Epoch: 3   Global Step: 48500   Required: 35 hours
Training: 2025-12-01 01:12:08,830-Speed 1102.82 samples/sec   Loss 2.6093 target_logit_mean 0.0003 lma 0.6847  cos_theta_tmp 0.7607  Epoch: 3   Global Step: 48550   Required: 35 hours
Training: 2025-12-01 01:12:26,242-Speed 1102.73 samples/sec   Loss 2.6917 target_logit_mean 0.0004 lma 0.6725  cos_theta_tmp 0.7487  Epoch: 3   Global Step: 48600   Required: 35 hours
Training: 2025-12-01 01:12:43,652-Speed 1102.90 samples/sec   Loss 2.6124 target_logit_mean 0.0012 lma 0.6950  cos_theta_tmp 0.7594  Epoch: 3   Global Step: 48650   Required: 35 hours
Training: 2025-12-01 01:13:01,063-Speed 1102.76 samples/sec   Loss 2.6851 target_logit_mean 0.0003 lma 0.6736  cos_theta_tmp 0.7561  Epoch: 3   Global Step: 48700   Required: 35 hours
Training: 2025-12-01 01:13:18,472-Speed 1102.94 samples/sec   Loss 2.6428 target_logit_mean 0.0006 lma 0.6820  cos_theta_tmp 0.7571  Epoch: 3   Global Step: 48750   Required: 35 hours
Training: 2025-12-01 01:13:35,878-Speed 1103.09 samples/sec   Loss 2.7110 target_logit_mean 0.0006 lma 0.6769  cos_theta_tmp 0.7537  Epoch: 3   Global Step: 48800   Required: 35 hours
Training: 2025-12-01 01:13:53,287-Speed 1102.93 samples/sec   Loss 2.6196 target_logit_mean 0.0031 lma 0.6818  cos_theta_tmp 0.7579  Epoch: 3   Global Step: 48850   Required: 35 hours
Training: 2025-12-01 01:14:10,696-Speed 1102.91 samples/sec   Loss 2.6376 target_logit_mean -0.0006 lma 0.6728  cos_theta_tmp 0.7499  Epoch: 3   Global Step: 48900   Required: 35 hours
Training: 2025-12-01 01:14:28,100-Speed 1103.21 samples/sec   Loss 2.6315 target_logit_mean -0.0034 lma 0.6855  cos_theta_tmp 0.7556  Epoch: 3   Global Step: 48950   Required: 35 hours
Training: 2025-12-01 01:14:45,558-Speed 1099.83 samples/sec   Loss 2.6686 target_logit_mean 0.0004 lma 0.6782  cos_theta_tmp 0.7489  Epoch: 3   Global Step: 49000   Required: 35 hours
Training: 2025-12-01 01:15:02,967-Speed 1102.89 samples/sec   Loss 2.6123 target_logit_mean -0.0023 lma 0.6854  cos_theta_tmp 0.7572  Epoch: 3   Global Step: 49050   Required: 35 hours
Training: 2025-12-01 01:15:20,380-Speed 1102.67 samples/sec   Loss 2.5997 target_logit_mean 0.0016 lma 0.6818  cos_theta_tmp 0.7608  Epoch: 3   Global Step: 49100   Required: 35 hours
Training: 2025-12-01 01:15:37,788-Speed 1102.94 samples/sec   Loss 2.6206 target_logit_mean 0.0028 lma 0.6912  cos_theta_tmp 0.7591  Epoch: 3   Global Step: 49150   Required: 35 hours
Training: 2025-12-01 01:15:55,197-Speed 1102.92 samples/sec   Loss 2.5868 target_logit_mean 0.0015 lma 0.6815  cos_theta_tmp 0.7577  Epoch: 3   Global Step: 49200   Required: 35 hours
Training: 2025-12-01 01:16:12,603-Speed 1103.12 samples/sec   Loss 2.6082 target_logit_mean -0.0001 lma 0.6748  cos_theta_tmp 0.7596  Epoch: 3   Global Step: 49250   Required: 35 hours
Training: 2025-12-01 01:16:30,193-Speed 1091.57 samples/sec   Loss 2.6447 target_logit_mean 0.0000 lma 0.6795  cos_theta_tmp 0.7589  Epoch: 3   Global Step: 49300   Required: 35 hours
Training: 2025-12-01 01:16:47,624-Speed 1101.55 samples/sec   Loss 2.6510 target_logit_mean -0.0026 lma 0.6834  cos_theta_tmp 0.7489  Epoch: 3   Global Step: 49350   Required: 35 hours
Training: 2025-12-01 01:17:05,061-Speed 1101.15 samples/sec   Loss 2.6529 target_logit_mean 0.0011 lma 0.6852  cos_theta_tmp 0.7609  Epoch: 3   Global Step: 49400   Required: 35 hours
Training: 2025-12-01 01:17:22,480-Speed 1102.31 samples/sec   Loss 2.6350 target_logit_mean 0.0020 lma 0.6825  cos_theta_tmp 0.7600  Epoch: 3   Global Step: 49450   Required: 35 hours
Training: 2025-12-01 01:17:39,886-Speed 1103.06 samples/sec   Loss 2.6955 target_logit_mean 0.0013 lma 0.6912  cos_theta_tmp 0.7534  Epoch: 3   Global Step: 49500   Required: 35 hours
Training: 2025-12-01 01:17:57,305-Speed 1102.31 samples/sec   Loss 2.6471 target_logit_mean -0.0020 lma 0.6785  cos_theta_tmp 0.7559  Epoch: 3   Global Step: 49550   Required: 35 hours
Training: 2025-12-01 01:18:14,710-Speed 1103.20 samples/sec   Loss 2.5821 target_logit_mean 0.0025 lma 0.6773  cos_theta_tmp 0.7553  Epoch: 3   Global Step: 49600   Required: 35 hours
Training: 2025-12-01 01:18:32,126-Speed 1102.48 samples/sec   Loss 2.5900 target_logit_mean 0.0013 lma 0.6706  cos_theta_tmp 0.7557  Epoch: 3   Global Step: 49650   Required: 35 hours
Training: 2025-12-01 01:18:49,532-Speed 1103.07 samples/sec   Loss 2.6095 target_logit_mean -0.0009 lma 0.6721  cos_theta_tmp 0.7532  Epoch: 3   Global Step: 49700   Required: 35 hours
Training: 2025-12-01 01:19:06,946-Speed 1102.63 samples/sec   Loss 2.6261 target_logit_mean 0.0022 lma 0.6821  cos_theta_tmp 0.7598  Epoch: 3   Global Step: 49750   Required: 35 hours
Training: 2025-12-01 01:19:24,364-Speed 1102.33 samples/sec   Loss 2.6437 target_logit_mean 0.0007 lma 0.6806  cos_theta_tmp 0.7563  Epoch: 3   Global Step: 49800   Required: 35 hours
Training: 2025-12-01 01:19:41,770-Speed 1103.14 samples/sec   Loss 2.6054 target_logit_mean 0.0020 lma 0.6738  cos_theta_tmp 0.7630  Epoch: 3   Global Step: 49850   Required: 35 hours
Training: 2025-12-01 01:19:59,189-Speed 1102.28 samples/sec   Loss 2.6448 target_logit_mean 0.0018 lma 0.6788  cos_theta_tmp 0.7592  Epoch: 3   Global Step: 49900   Required: 35 hours
Training: 2025-12-01 01:20:16,594-Speed 1103.14 samples/sec   Loss 2.6209 target_logit_mean 0.0009 lma 0.6961  cos_theta_tmp 0.7622  Epoch: 3   Global Step: 49950   Required: 35 hours
Training: 2025-12-01 01:20:34,012-Speed 1102.38 samples/sec   Loss 2.6160 target_logit_mean 0.0002 lma 0.6891  cos_theta_tmp 0.7587  Epoch: 3   Global Step: 50000   Required: 35 hours
Training: 2025-12-01 01:20:51,434-Speed 1102.10 samples/sec   Loss 2.5837 target_logit_mean 0.0019 lma 0.6871  cos_theta_tmp 0.7573  Epoch: 3   Global Step: 50050   Required: 35 hours
Training: 2025-12-01 01:21:08,841-Speed 1102.99 samples/sec   Loss 2.6192 target_logit_mean 0.0004 lma 0.6706  cos_theta_tmp 0.7549  Epoch: 3   Global Step: 50100   Required: 35 hours
Training: 2025-12-01 01:21:26,260-Speed 1102.29 samples/sec   Loss 2.5630 target_logit_mean -0.0002 lma 0.6776  cos_theta_tmp 0.7616  Epoch: 3   Global Step: 50150   Required: 35 hours
Training: 2025-12-01 01:21:43,673-Speed 1102.68 samples/sec   Loss 2.5696 target_logit_mean -0.0009 lma 0.6861  cos_theta_tmp 0.7619  Epoch: 3   Global Step: 50200   Required: 35 hours
Training: 2025-12-01 01:22:01,090-Speed 1102.37 samples/sec   Loss 2.6200 target_logit_mean -0.0004 lma 0.6817  cos_theta_tmp 0.7548  Epoch: 3   Global Step: 50250   Required: 35 hours
Training: 2025-12-01 01:22:18,493-Speed 1103.36 samples/sec   Loss 2.6413 target_logit_mean 0.0001 lma 0.6774  cos_theta_tmp 0.7572  Epoch: 3   Global Step: 50300   Required: 35 hours
Training: 2025-12-01 01:22:35,917-Speed 1101.91 samples/sec   Loss 2.6664 target_logit_mean -0.0001 lma 0.6819  cos_theta_tmp 0.7582  Epoch: 3   Global Step: 50350   Required: 35 hours
Training: 2025-12-01 01:22:53,335-Speed 1102.36 samples/sec   Loss 2.6193 target_logit_mean 0.0016 lma 0.6956  cos_theta_tmp 0.7587  Epoch: 3   Global Step: 50400   Required: 35 hours
Training: 2025-12-01 01:23:10,741-Speed 1103.12 samples/sec   Loss 2.6348 target_logit_mean 0.0014 lma 0.6888  cos_theta_tmp 0.7634  Epoch: 3   Global Step: 50450   Required: 35 hours
Training: 2025-12-01 01:23:28,158-Speed 1102.37 samples/sec   Loss 2.6547 target_logit_mean -0.0009 lma 0.6850  cos_theta_tmp 0.7606  Epoch: 3   Global Step: 50500   Required: 35 hours
Training: 2025-12-01 01:23:45,567-Speed 1102.93 samples/sec   Loss 2.6138 target_logit_mean -0.0001 lma 0.6684  cos_theta_tmp 0.7509  Epoch: 3   Global Step: 50550   Required: 35 hours
Training: 2025-12-01 01:24:02,984-Speed 1102.45 samples/sec   Loss 2.6010 target_logit_mean -0.0019 lma 0.6770  cos_theta_tmp 0.7570  Epoch: 3   Global Step: 50600   Required: 35 hours
Training: 2025-12-01 01:24:20,403-Speed 1102.27 samples/sec   Loss 2.6063 target_logit_mean -0.0010 lma 0.6791  cos_theta_tmp 0.7537  Epoch: 3   Global Step: 50650   Required: 35 hours
Training: 2025-12-01 01:24:37,808-Speed 1103.18 samples/sec   Loss 2.6078 target_logit_mean 0.0002 lma 0.6877  cos_theta_tmp 0.7569  Epoch: 3   Global Step: 50700   Required: 35 hours
Training: 2025-12-01 01:24:55,231-Speed 1102.04 samples/sec   Loss 2.5751 target_logit_mean 0.0029 lma 0.6870  cos_theta_tmp 0.7588  Epoch: 3   Global Step: 50750   Required: 35 hours
Training: 2025-12-01 01:25:12,633-Speed 1103.37 samples/sec   Loss 2.5518 target_logit_mean -0.0002 lma 0.6782  cos_theta_tmp 0.7593  Epoch: 3   Global Step: 50800   Required: 35 hours
Training: 2025-12-01 01:25:30,050-Speed 1102.37 samples/sec   Loss 2.6922 target_logit_mean -0.0012 lma 0.6763  cos_theta_tmp 0.7580  Epoch: 3   Global Step: 50850   Required: 35 hours
Training: 2025-12-01 01:25:47,455-Speed 1103.21 samples/sec   Loss 2.6289 target_logit_mean 0.0017 lma 0.6919  cos_theta_tmp 0.7603  Epoch: 3   Global Step: 50900   Required: 35 hours
Training: 2025-12-01 01:26:04,876-Speed 1102.16 samples/sec   Loss 2.5949 target_logit_mean 0.0015 lma 0.6858  cos_theta_tmp 0.7614  Epoch: 3   Global Step: 50950   Required: 35 hours
Training: 2025-12-01 01:26:22,294-Speed 1102.29 samples/sec   Loss 2.6611 target_logit_mean 0.0005 lma 0.6729  cos_theta_tmp 0.7521  Epoch: 3   Global Step: 51000   Required: 35 hours
Training: 2025-12-01 01:26:39,697-Speed 1103.33 samples/sec   Loss 2.6840 target_logit_mean 0.0001 lma 0.6708  cos_theta_tmp 0.7544  Epoch: 3   Global Step: 51050   Required: 35 hours
Training: 2025-12-01 01:26:57,113-Speed 1102.46 samples/sec   Loss 2.6275 target_logit_mean 0.0001 lma 0.6795  cos_theta_tmp 0.7583  Epoch: 3   Global Step: 51100   Required: 35 hours
Training: 2025-12-01 01:27:14,516-Speed 1103.29 samples/sec   Loss 2.6562 target_logit_mean 0.0003 lma 0.6909  cos_theta_tmp 0.7619  Epoch: 3   Global Step: 51150   Required: 35 hours
Training: 2025-12-01 01:27:31,936-Speed 1102.18 samples/sec   Loss 2.6008 target_logit_mean -0.0018 lma 0.6772  cos_theta_tmp 0.7541  Epoch: 3   Global Step: 51200   Required: 35 hours
Training: 2025-12-01 01:27:49,342-Speed 1103.11 samples/sec   Loss 2.6388 target_logit_mean -0.0019 lma 0.6916  cos_theta_tmp 0.7533  Epoch: 3   Global Step: 51250   Required: 35 hours
Training: 2025-12-01 01:28:06,758-Speed 1102.46 samples/sec   Loss 2.5992 target_logit_mean -0.0006 lma 0.6885  cos_theta_tmp 0.7608  Epoch: 3   Global Step: 51300   Required: 35 hours
Training: 2025-12-01 01:28:24,179-Speed 1102.17 samples/sec   Loss 2.5651 target_logit_mean -0.0012 lma 0.6751  cos_theta_tmp 0.7521  Epoch: 3   Global Step: 51350   Required: 35 hours
Training: 2025-12-01 01:28:41,587-Speed 1103.01 samples/sec   Loss 2.6197 target_logit_mean 0.0024 lma 0.6939  cos_theta_tmp 0.7615  Epoch: 3   Global Step: 51400   Required: 35 hours
Training: 2025-12-01 01:28:59,031-Speed 1100.71 samples/sec   Loss 2.6171 target_logit_mean 0.0007 lma 0.6774  cos_theta_tmp 0.7583  Epoch: 3   Global Step: 51450   Required: 35 hours
Training: 2025-12-01 01:29:16,538-Speed 1096.74 samples/sec   Loss 2.6992 target_logit_mean 0.0003 lma 0.6776  cos_theta_tmp 0.7523  Epoch: 3   Global Step: 51500   Required: 35 hours
Training: 2025-12-01 01:29:33,962-Speed 1101.91 samples/sec   Loss 2.6228 target_logit_mean -0.0003 lma 0.6845  cos_theta_tmp 0.7584  Epoch: 3   Global Step: 51550   Required: 35 hours
Training: 2025-12-01 01:29:51,382-Speed 1102.28 samples/sec   Loss 2.6439 target_logit_mean 0.0000 lma 0.6875  cos_theta_tmp 0.7567  Epoch: 3   Global Step: 51600   Required: 35 hours
Training: 2025-12-01 01:30:08,791-Speed 1102.91 samples/sec   Loss 2.6660 target_logit_mean 0.0004 lma 0.7005  cos_theta_tmp 0.7596  Epoch: 3   Global Step: 51650   Required: 35 hours
Training: 2025-12-01 01:30:26,215-Speed 1101.93 samples/sec   Loss 2.6871 target_logit_mean 0.0010 lma 0.6843  cos_theta_tmp 0.7571  Epoch: 3   Global Step: 51700   Required: 35 hours
Training: 2025-12-01 01:30:43,622-Speed 1103.03 samples/sec   Loss 2.6719 target_logit_mean 0.0010 lma 0.6861  cos_theta_tmp 0.7609  Epoch: 3   Global Step: 51750   Required: 35 hours
Training: 2025-12-01 01:31:01,046-Speed 1101.99 samples/sec   Loss 2.6658 target_logit_mean 0.0024 lma 0.6853  cos_theta_tmp 0.7547  Epoch: 3   Global Step: 51800   Required: 35 hours
Training: 2025-12-01 01:31:18,457-Speed 1102.77 samples/sec   Loss 2.5835 target_logit_mean -0.0009 lma 0.6750  cos_theta_tmp 0.7551  Epoch: 3   Global Step: 51850   Required: 35 hours
Training: 2025-12-01 01:31:35,878-Speed 1102.15 samples/sec   Loss 2.5847 target_logit_mean 0.0004 lma 0.6856  cos_theta_tmp 0.7599  Epoch: 3   Global Step: 51900   Required: 35 hours
Training: 2025-12-01 01:31:53,301-Speed 1102.02 samples/sec   Loss 2.5892 target_logit_mean 0.0005 lma 0.6717  cos_theta_tmp 0.7590  Epoch: 3   Global Step: 51950   Required: 35 hours
Training: 2025-12-01 01:32:10,708-Speed 1103.09 samples/sec   Loss 2.5397 target_logit_mean -0.0010 lma 0.6849  cos_theta_tmp 0.7567  Epoch: 3   Global Step: 52000   Required: 35 hours
Training: 2025-12-01 01:32:28,124-Speed 1102.43 samples/sec   Loss 2.6168 target_logit_mean 0.0009 lma 0.6869  cos_theta_tmp 0.7565  Epoch: 3   Global Step: 52050   Required: 35 hours
Training: 2025-12-01 01:32:45,534-Speed 1102.88 samples/sec   Loss 2.5846 target_logit_mean -0.0003 lma 0.6782  cos_theta_tmp 0.7566  Epoch: 3   Global Step: 52100   Required: 35 hours
Training: 2025-12-01 01:33:02,951-Speed 1102.42 samples/sec   Loss 2.5814 target_logit_mean 0.0016 lma 0.6854  cos_theta_tmp 0.7656  Epoch: 3   Global Step: 52150   Required: 35 hours
Training: 2025-12-01 01:33:20,362-Speed 1102.74 samples/sec   Loss 2.5909 target_logit_mean 0.0016 lma 0.6824  cos_theta_tmp 0.7553  Epoch: 3   Global Step: 52200   Required: 35 hours
Training: 2025-12-01 01:33:37,786-Speed 1101.99 samples/sec   Loss 2.5960 target_logit_mean 0.0027 lma 0.6768  cos_theta_tmp 0.7605  Epoch: 3   Global Step: 52250   Required: 35 hours
Training: 2025-12-01 01:33:55,208-Speed 1102.14 samples/sec   Loss 2.6380 target_logit_mean -0.0017 lma 0.6786  cos_theta_tmp 0.7579  Epoch: 3   Global Step: 52300   Required: 35 hours
Training: 2025-12-01 01:34:12,617-Speed 1102.90 samples/sec   Loss 2.6230 target_logit_mean 0.0019 lma 0.6869  cos_theta_tmp 0.7566  Epoch: 3   Global Step: 52350   Required: 35 hours
Training: 2025-12-01 01:34:30,041-Speed 1101.96 samples/sec   Loss 2.6346 target_logit_mean -0.0022 lma 0.6801  cos_theta_tmp 0.7532  Epoch: 3   Global Step: 52400   Required: 35 hours
Training: 2025-12-01 01:34:47,457-Speed 1102.48 samples/sec   Loss 2.6114 target_logit_mean -0.0001 lma 0.6954  cos_theta_tmp 0.7590  Epoch: 3   Global Step: 52450   Required: 35 hours
Training: 2025-12-01 01:35:04,879-Speed 1102.08 samples/sec   Loss 2.6280 target_logit_mean 0.0013 lma 0.6869  cos_theta_tmp 0.7641  Epoch: 3   Global Step: 52500   Required: 35 hours
Training: 2025-12-01 01:35:22,301-Speed 1102.08 samples/sec   Loss 2.5934 target_logit_mean 0.0015 lma 0.6856  cos_theta_tmp 0.7520  Epoch: 3   Global Step: 52550   Required: 35 hours
Training: 2025-12-01 01:35:39,728-Speed 1102.99 samples/sec   Loss 2.6076 target_logit_mean -0.0013 lma 0.6865  cos_theta_tmp 0.7568  Epoch: 3   Global Step: 52600   Required: 35 hours
Training: 2025-12-01 01:35:57,151-Speed 1102.02 samples/sec   Loss 2.6256 target_logit_mean 0.0001 lma 0.6841  cos_theta_tmp 0.7528  Epoch: 3   Global Step: 52650   Required: 35 hours
Training: 2025-12-01 01:36:14,561-Speed 1102.88 samples/sec   Loss 2.5449 target_logit_mean 0.0022 lma 0.6816  cos_theta_tmp 0.7531  Epoch: 3   Global Step: 52700   Required: 35 hours
Training: 2025-12-01 01:36:31,984-Speed 1102.02 samples/sec   Loss 2.6089 target_logit_mean 0.0012 lma 0.6760  cos_theta_tmp 0.7555  Epoch: 3   Global Step: 52750   Required: 35 hours
Training: 2025-12-01 01:36:49,394-Speed 1102.85 samples/sec   Loss 2.6224 target_logit_mean -0.0001 lma 0.6813  cos_theta_tmp 0.7602  Epoch: 3   Global Step: 52800   Required: 35 hours
Training: 2025-12-01 01:37:06,822-Speed 1101.73 samples/sec   Loss 2.6428 target_logit_mean 0.0003 lma 0.6760  cos_theta_tmp 0.7528  Epoch: 3   Global Step: 52850   Required: 35 hours
Training: 2025-12-01 01:37:24,246-Speed 1101.97 samples/sec   Loss 2.6179 target_logit_mean -0.0014 lma 0.6909  cos_theta_tmp 0.7647  Epoch: 3   Global Step: 52900   Required: 35 hours
Training: 2025-12-01 01:37:41,657-Speed 1102.82 samples/sec   Loss 2.6017 target_logit_mean 0.0007 lma 0.6626  cos_theta_tmp 0.7579  Epoch: 3   Global Step: 52950   Required: 34 hours
Training: 2025-12-01 01:37:59,082-Speed 1101.89 samples/sec   Loss 2.6226 target_logit_mean 0.0010 lma 0.6812  cos_theta_tmp 0.7526  Epoch: 3   Global Step: 53000   Required: 34 hours
Training: 2025-12-01 01:38:16,490-Speed 1102.92 samples/sec   Loss 2.5968 target_logit_mean 0.0028 lma 0.6805  cos_theta_tmp 0.7576  Epoch: 3   Global Step: 53050   Required: 34 hours
Training: 2025-12-01 01:38:33,918-Speed 1101.78 samples/sec   Loss 2.5865 target_logit_mean -0.0007 lma 0.6944  cos_theta_tmp 0.7647  Epoch: 3   Global Step: 53100   Required: 34 hours
Training: 2025-12-01 01:38:51,327-Speed 1102.88 samples/sec   Loss 2.6118 target_logit_mean 0.0002 lma 0.6827  cos_theta_tmp 0.7551  Epoch: 3   Global Step: 53150   Required: 34 hours
Training: 2025-12-01 01:39:08,750-Speed 1102.05 samples/sec   Loss 2.6130 target_logit_mean 0.0015 lma 0.6872  cos_theta_tmp 0.7596  Epoch: 3   Global Step: 53200   Required: 34 hours
Training: 2025-12-01 01:39:26,174-Speed 1101.92 samples/sec   Loss 2.5506 target_logit_mean 0.0026 lma 0.6805  cos_theta_tmp 0.7586  Epoch: 3   Global Step: 53250   Required: 34 hours
Training: 2025-12-01 01:39:43,587-Speed 1102.73 samples/sec   Loss 2.6374 target_logit_mean -0.0003 lma 0.6859  cos_theta_tmp 0.7548  Epoch: 3   Global Step: 53300   Required: 34 hours
Training: 2025-12-01 01:40:01,013-Speed 1101.80 samples/sec   Loss 2.6043 target_logit_mean 0.0007 lma 0.6803  cos_theta_tmp 0.7571  Epoch: 3   Global Step: 53350   Required: 34 hours
Training: 2025-12-01 01:40:18,422-Speed 1102.95 samples/sec   Loss 2.5753 target_logit_mean 0.0005 lma 0.6858  cos_theta_tmp 0.7575  Epoch: 3   Global Step: 53400   Required: 34 hours
Training: 2025-12-01 01:40:35,842-Speed 1102.19 samples/sec   Loss 2.6045 target_logit_mean -0.0004 lma 0.6778  cos_theta_tmp 0.7520  Epoch: 3   Global Step: 53450   Required: 34 hours
Training: 2025-12-01 01:40:53,268-Speed 1101.89 samples/sec   Loss 2.6367 target_logit_mean -0.0025 lma 0.6705  cos_theta_tmp 0.7485  Epoch: 3   Global Step: 53500   Required: 34 hours
Training: 2025-12-01 01:41:10,675-Speed 1103.06 samples/sec   Loss 2.5590 target_logit_mean -0.0017 lma 0.6928  cos_theta_tmp 0.7577  Epoch: 3   Global Step: 53550   Required: 34 hours
Training: 2025-12-01 01:41:28,105-Speed 1101.58 samples/sec   Loss 2.5862 target_logit_mean -0.0004 lma 0.6912  cos_theta_tmp 0.7632  Epoch: 3   Global Step: 53600   Required: 34 hours
Training: 2025-12-01 01:41:45,517-Speed 1102.74 samples/sec   Loss 2.5881 target_logit_mean 0.0004 lma 0.6668  cos_theta_tmp 0.7545  Epoch: 3   Global Step: 53650   Required: 34 hours
Training: 2025-12-01 01:42:02,941-Speed 1101.96 samples/sec   Loss 2.5758 target_logit_mean 0.0031 lma 0.6938  cos_theta_tmp 0.7640  Epoch: 3   Global Step: 53700   Required: 34 hours
Training: 2025-12-01 01:42:20,346-Speed 1103.13 samples/sec   Loss 2.5960 target_logit_mean 0.0007 lma 0.6759  cos_theta_tmp 0.7560  Epoch: 3   Global Step: 53750   Required: 34 hours
Training: 2025-12-01 01:42:37,772-Speed 1101.84 samples/sec   Loss 2.6772 target_logit_mean 0.0033 lma 0.6794  cos_theta_tmp 0.7573  Epoch: 3   Global Step: 53800   Required: 34 hours
Training: 2025-12-01 01:42:55,194-Speed 1102.12 samples/sec   Loss 2.6774 target_logit_mean -0.0008 lma 0.6870  cos_theta_tmp 0.7564  Epoch: 3   Global Step: 53850   Required: 34 hours
Training: 2025-12-01 01:43:12,606-Speed 1102.76 samples/sec   Loss 2.6161 target_logit_mean 0.0020 lma 0.6756  cos_theta_tmp 0.7465  Epoch: 3   Global Step: 53900   Required: 34 hours
Training: 2025-12-01 01:43:30,032-Speed 1101.84 samples/sec   Loss 2.5295 target_logit_mean -0.0022 lma 0.6822  cos_theta_tmp 0.7585  Epoch: 3   Global Step: 53950   Required: 34 hours
Training: 2025-12-01 01:43:47,440-Speed 1102.99 samples/sec   Loss 2.5779 target_logit_mean -0.0002 lma 0.6876  cos_theta_tmp 0.7597  Epoch: 3   Global Step: 54000   Required: 34 hours
Training: 2025-12-01 01:44:04,860-Speed 1102.19 samples/sec   Loss 2.5705 target_logit_mean 0.0007 lma 0.6891  cos_theta_tmp 0.7565  Epoch: 3   Global Step: 54050   Required: 34 hours
Training: 2025-12-01 01:44:22,286-Speed 1101.86 samples/sec   Loss 2.5522 target_logit_mean -0.0003 lma 0.6933  cos_theta_tmp 0.7595  Epoch: 3   Global Step: 54100   Required: 34 hours
Training: 2025-12-01 01:44:39,692-Speed 1103.05 samples/sec   Loss 2.5285 target_logit_mean -0.0006 lma 0.6918  cos_theta_tmp 0.7592  Epoch: 3   Global Step: 54150   Required: 34 hours
Training: 2025-12-01 01:44:57,120-Speed 1101.77 samples/sec   Loss 2.5702 target_logit_mean 0.0009 lma 0.6766  cos_theta_tmp 0.7557  Epoch: 3   Global Step: 54200   Required: 34 hours
Training: 2025-12-01 01:45:14,530-Speed 1102.80 samples/sec   Loss 2.6016 target_logit_mean -0.0001 lma 0.6843  cos_theta_tmp 0.7578  Epoch: 3   Global Step: 54250   Required: 34 hours
Training: 2025-12-01 01:45:31,960-Speed 1101.61 samples/sec   Loss 2.5691 target_logit_mean -0.0009 lma 0.6823  cos_theta_tmp 0.7599  Epoch: 3   Global Step: 54300   Required: 34 hours
Training: 2025-12-01 01:45:49,363-Speed 1103.29 samples/sec   Loss 2.4916 target_logit_mean 0.0026 lma 0.6827  cos_theta_tmp 0.7545  Epoch: 3   Global Step: 54350   Required: 34 hours
Training: 2025-12-01 01:46:06,782-Speed 1102.28 samples/sec   Loss 2.5724 target_logit_mean -0.0027 lma 0.6749  cos_theta_tmp 0.7490  Epoch: 3   Global Step: 54400   Required: 34 hours
Training: 2025-12-01 01:46:24,196-Speed 1102.60 samples/sec   Loss 2.5779 target_logit_mean 0.0011 lma 0.6846  cos_theta_tmp 0.7596  Epoch: 3   Global Step: 54450   Required: 34 hours
Training: 2025-12-01 01:46:41,619-Speed 1102.06 samples/sec   Loss 2.6031 target_logit_mean -0.0026 lma 0.6799  cos_theta_tmp 0.7592  Epoch: 3   Global Step: 54500   Required: 34 hours
Training: 2025-12-01 01:46:59,042-Speed 1102.04 samples/sec   Loss 2.5810 target_logit_mean 0.0013 lma 0.6864  cos_theta_tmp 0.7571  Epoch: 3   Global Step: 54550   Required: 34 hours
Training: 2025-12-01 01:47:16,448-Speed 1103.07 samples/sec   Loss 2.6243 target_logit_mean -0.0005 lma 0.6752  cos_theta_tmp 0.7483  Epoch: 3   Global Step: 54600   Required: 34 hours
Training: 2025-12-01 01:47:33,867-Speed 1102.31 samples/sec   Loss 2.5143 target_logit_mean 0.0010 lma 0.6942  cos_theta_tmp 0.7637  Epoch: 3   Global Step: 54650   Required: 34 hours
Training: 2025-12-01 01:47:51,281-Speed 1102.60 samples/sec   Loss 2.5497 target_logit_mean 0.0016 lma 0.6805  cos_theta_tmp 0.7629  Epoch: 3   Global Step: 54700   Required: 34 hours
Training: 2025-12-01 01:48:08,705-Speed 1101.95 samples/sec   Loss 2.5576 target_logit_mean -0.0002 lma 0.6869  cos_theta_tmp 0.7595  Epoch: 3   Global Step: 54750   Required: 34 hours
Training: 2025-12-01 01:48:26,128-Speed 1102.03 samples/sec   Loss 2.5660 target_logit_mean 0.0018 lma 0.6849  cos_theta_tmp 0.7592  Epoch: 3   Global Step: 54800   Required: 34 hours
Training: 2025-12-01 01:48:43,541-Speed 1102.68 samples/sec   Loss 2.6167 target_logit_mean 0.0002 lma 0.6805  cos_theta_tmp 0.7577  Epoch: 3   Global Step: 54850   Required: 34 hours
Training: 2025-12-01 01:49:00,962-Speed 1102.19 samples/sec   Loss 2.5776 target_logit_mean -0.0005 lma 0.6842  cos_theta_tmp 0.7578  Epoch: 3   Global Step: 54900   Required: 34 hours
Training: 2025-12-01 01:49:18,372-Speed 1102.86 samples/sec   Loss 2.6208 target_logit_mean -0.0022 lma 0.6611  cos_theta_tmp 0.7520  Epoch: 3   Global Step: 54950   Required: 34 hours
Training: 2025-12-01 01:49:35,798-Speed 1101.81 samples/sec   Loss 2.6596 target_logit_mean -0.0014 lma 0.6808  cos_theta_tmp 0.7548  Epoch: 3   Global Step: 55000   Required: 34 hours
Training: 2025-12-01 01:49:53,205-Speed 1103.09 samples/sec   Loss 2.6785 target_logit_mean -0.0008 lma 0.6801  cos_theta_tmp 0.7500  Epoch: 3   Global Step: 55050   Required: 34 hours
Training: 2025-12-01 01:50:10,628-Speed 1102.00 samples/sec   Loss 2.5861 target_logit_mean -0.0021 lma 0.6741  cos_theta_tmp 0.7536  Epoch: 3   Global Step: 55100   Required: 34 hours
Training: 2025-12-01 01:50:28,052-Speed 1102.01 samples/sec   Loss 2.5993 target_logit_mean 0.0012 lma 0.6845  cos_theta_tmp 0.7669  Epoch: 3   Global Step: 55150   Required: 34 hours
Training: 2025-12-01 01:50:45,466-Speed 1102.57 samples/sec   Loss 2.6192 target_logit_mean -0.0022 lma 0.6889  cos_theta_tmp 0.7524  Epoch: 3   Global Step: 55200   Required: 34 hours
Training: 2025-12-01 01:51:02,887-Speed 1102.14 samples/sec   Loss 2.6189 target_logit_mean -0.0003 lma 0.6927  cos_theta_tmp 0.7576  Epoch: 3   Global Step: 55250   Required: 34 hours
Training: 2025-12-01 01:51:20,294-Speed 1103.02 samples/sec   Loss 2.6337 target_logit_mean 0.0015 lma 0.6734  cos_theta_tmp 0.7575  Epoch: 3   Global Step: 55300   Required: 34 hours
Training: 2025-12-01 01:51:37,713-Speed 1102.28 samples/sec   Loss 2.6176 target_logit_mean 0.0004 lma 0.6763  cos_theta_tmp 0.7568  Epoch: 3   Global Step: 55350   Required: 34 hours
Training: 2025-12-01 01:51:55,137-Speed 1101.98 samples/sec   Loss 2.5183 target_logit_mean 0.0019 lma 0.6872  cos_theta_tmp 0.7585  Epoch: 3   Global Step: 55400   Required: 34 hours
Training: 2025-12-01 01:52:12,552-Speed 1102.58 samples/sec   Loss 2.5804 target_logit_mean 0.0003 lma 0.6879  cos_theta_tmp 0.7631  Epoch: 3   Global Step: 55450   Required: 34 hours
Training: 2025-12-01 01:52:29,972-Speed 1102.23 samples/sec   Loss 2.5764 target_logit_mean 0.0011 lma 0.6839  cos_theta_tmp 0.7602  Epoch: 3   Global Step: 55500   Required: 34 hours
Training: 2025-12-01 01:52:47,380-Speed 1102.94 samples/sec   Loss 2.6034 target_logit_mean -0.0014 lma 0.6742  cos_theta_tmp 0.7538  Epoch: 3   Global Step: 55550   Required: 34 hours
Training: 2025-12-01 01:53:04,804-Speed 1102.02 samples/sec   Loss 2.5953 target_logit_mean 0.0001 lma 0.6820  cos_theta_tmp 0.7618  Epoch: 3   Global Step: 55600   Required: 34 hours
Training: 2025-12-01 01:53:22,213-Speed 1102.90 samples/sec   Loss 2.5397 target_logit_mean -0.0008 lma 0.6715  cos_theta_tmp 0.7575  Epoch: 3   Global Step: 55650   Required: 34 hours
Training: 2025-12-01 01:53:39,631-Speed 1102.34 samples/sec   Loss 2.6223 target_logit_mean 0.0007 lma 0.6759  cos_theta_tmp 0.7553  Epoch: 3   Global Step: 55700   Required: 34 hours
Training: 2025-12-01 01:53:57,053-Speed 1102.06 samples/sec   Loss 2.5485 target_logit_mean 0.0013 lma 0.6877  cos_theta_tmp 0.7595  Epoch: 3   Global Step: 55750   Required: 34 hours
Training: 2025-12-01 01:54:14,461-Speed 1103.00 samples/sec   Loss 2.6004 target_logit_mean 0.0010 lma 0.6833  cos_theta_tmp 0.7590  Epoch: 3   Global Step: 55800   Required: 34 hours
Training: 2025-12-01 01:54:31,886-Speed 1101.91 samples/sec   Loss 2.6456 target_logit_mean 0.0012 lma 0.6768  cos_theta_tmp 0.7526  Epoch: 3   Global Step: 55850   Required: 34 hours
Training: 2025-12-01 01:54:49,300-Speed 1102.62 samples/sec   Loss 2.5393 target_logit_mean 0.0004 lma 0.6906  cos_theta_tmp 0.7615  Epoch: 3   Global Step: 55900   Required: 34 hours
Training: 2025-12-01 01:55:06,723-Speed 1102.02 samples/sec   Loss 2.5389 target_logit_mean 0.0032 lma 0.6795  cos_theta_tmp 0.7573  Epoch: 3   Global Step: 55950   Required: 34 hours
Training: 2025-12-01 01:55:24,134-Speed 1102.78 samples/sec   Loss 2.5624 target_logit_mean 0.0018 lma 0.6799  cos_theta_tmp 0.7603  Epoch: 3   Global Step: 56000   Required: 34 hours
Training: 2025-12-01 01:55:41,555-Speed 1102.19 samples/sec   Loss 2.5069 target_logit_mean 0.0025 lma 0.6906  cos_theta_tmp 0.7638  Epoch: 3   Global Step: 56050   Required: 34 hours
Training: 2025-12-01 01:55:58,979-Speed 1101.90 samples/sec   Loss 2.5983 target_logit_mean 0.0032 lma 0.6847  cos_theta_tmp 0.7620  Epoch: 3   Global Step: 56100   Required: 34 hours
Training: 2025-12-01 01:56:16,389-Speed 1102.91 samples/sec   Loss 2.6460 target_logit_mean 0.0003 lma 0.6742  cos_theta_tmp 0.7572  Epoch: 3   Global Step: 56150   Required: 34 hours
Training: 2025-12-01 01:56:33,807-Speed 1102.31 samples/sec   Loss 2.6353 target_logit_mean -0.0022 lma 0.6631  cos_theta_tmp 0.7511  Epoch: 3   Global Step: 56200   Required: 34 hours
Training: 2025-12-01 01:56:51,222-Speed 1102.54 samples/sec   Loss 2.5475 target_logit_mean -0.0021 lma 0.6903  cos_theta_tmp 0.7611  Epoch: 3   Global Step: 56250   Required: 34 hours
Training: 2025-12-01 01:57:08,652-Speed 1101.62 samples/sec   Loss 2.5855 target_logit_mean -0.0015 lma 0.6785  cos_theta_tmp 0.7522  Epoch: 3   Global Step: 56300   Required: 34 hours
Training: 2025-12-01 01:57:26,076-Speed 1101.95 samples/sec   Loss 2.5926 target_logit_mean -0.0002 lma 0.6808  cos_theta_tmp 0.7604  Epoch: 3   Global Step: 56350   Required: 34 hours
Training: 2025-12-01 01:57:43,483-Speed 1103.03 samples/sec   Loss 2.5489 target_logit_mean -0.0002 lma 0.7001  cos_theta_tmp 0.7591  Epoch: 3   Global Step: 56400   Required: 34 hours
Training: 2025-12-01 01:58:00,909-Speed 1101.89 samples/sec   Loss 2.5999 target_logit_mean -0.0003 lma 0.6799  cos_theta_tmp 0.7523  Epoch: 3   Global Step: 56450   Required: 34 hours
Training: 2025-12-01 01:58:18,323-Speed 1102.61 samples/sec   Loss 2.6319 target_logit_mean -0.0004 lma 0.6910  cos_theta_tmp 0.7522  Epoch: 3   Global Step: 56500   Required: 34 hours
Training: 2025-12-01 01:58:35,744-Speed 1102.11 samples/sec   Loss 2.5802 target_logit_mean 0.0029 lma 0.6832  cos_theta_tmp 0.7629  Epoch: 3   Global Step: 56550   Required: 34 hours
Training: 2025-12-01 01:58:53,157-Speed 1102.66 samples/sec   Loss 2.6087 target_logit_mean -0.0018 lma 0.6833  cos_theta_tmp 0.7554  Epoch: 3   Global Step: 56600   Required: 34 hours
Training: 2025-12-01 01:59:10,578-Speed 1102.14 samples/sec   Loss 2.5529 target_logit_mean 0.0013 lma 0.6857  cos_theta_tmp 0.7557  Epoch: 3   Global Step: 56650   Required: 34 hours
Training: 2025-12-01 01:59:28,005-Speed 1101.83 samples/sec   Loss 2.6331 target_logit_mean 0.0013 lma 0.6723  cos_theta_tmp 0.7534  Epoch: 3   Global Step: 56700   Required: 34 hours
Training: 2025-12-01 01:59:45,414-Speed 1102.92 samples/sec   Loss 2.5432 target_logit_mean -0.0003 lma 0.6763  cos_theta_tmp 0.7516  Epoch: 3   Global Step: 56750   Required: 34 hours
Training: 2025-12-01 02:00:02,841-Speed 1101.77 samples/sec   Loss 2.5605 target_logit_mean -0.0001 lma 0.6758  cos_theta_tmp 0.7533  Epoch: 3   Global Step: 56800   Required: 34 hours
Training: 2025-12-01 02:00:20,250-Speed 1102.91 samples/sec   Loss 2.5641 target_logit_mean -0.0020 lma 0.6871  cos_theta_tmp 0.7605  Epoch: 3   Global Step: 56850   Required: 34 hours
Training: 2025-12-01 02:00:37,671-Speed 1102.13 samples/sec   Loss 2.6304 target_logit_mean 0.0010 lma 0.6831  cos_theta_tmp 0.7570  Epoch: 3   Global Step: 56900   Required: 34 hours
Training: 2025-12-01 02:00:55,089-Speed 1102.37 samples/sec   Loss 2.5332 target_logit_mean 0.0007 lma 0.6875  cos_theta_tmp 0.7586  Epoch: 3   Global Step: 56950   Required: 34 hours
Training: 2025-12-01 02:01:12,504-Speed 1102.54 samples/sec   Loss 2.5564 target_logit_mean -0.0001 lma 0.6830  cos_theta_tmp 0.7528  Epoch: 3   Global Step: 57000   Required: 34 hours
Training: 2025-12-01 02:01:29,920-Speed 1102.46 samples/sec   Loss 2.5929 target_logit_mean 0.0027 lma 0.6775  cos_theta_tmp 0.7594  Epoch: 3   Global Step: 57050   Required: 34 hours
Training: 2025-12-01 02:01:47,328-Speed 1102.96 samples/sec   Loss 2.5828 target_logit_mean 0.0008 lma 0.6851  cos_theta_tmp 0.7639  Epoch: 3   Global Step: 57100   Required: 34 hours
Training: 2025-12-01 02:02:04,749-Speed 1102.15 samples/sec   Loss 2.5119 target_logit_mean 0.0007 lma 0.6812  cos_theta_tmp 0.7613  Epoch: 3   Global Step: 57150   Required: 34 hours
Training: 2025-12-01 02:02:22,155-Speed 1103.11 samples/sec   Loss 2.5050 target_logit_mean 0.0015 lma 0.6773  cos_theta_tmp 0.7546  Epoch: 3   Global Step: 57200   Required: 34 hours
Training: 2025-12-01 02:02:39,576-Speed 1102.17 samples/sec   Loss 2.6190 target_logit_mean -0.0005 lma 0.6746  cos_theta_tmp 0.7571  Epoch: 3   Global Step: 57250   Required: 34 hours
Training: 2025-12-01 02:02:56,990-Speed 1102.59 samples/sec   Loss 2.5563 target_logit_mean -0.0005 lma 0.6734  cos_theta_tmp 0.7568  Epoch: 3   Global Step: 57300   Required: 34 hours
Training: 2025-12-01 02:03:14,400-Speed 1102.85 samples/sec   Loss 2.5902 target_logit_mean -0.0004 lma 0.6882  cos_theta_tmp 0.7546  Epoch: 3   Global Step: 57350   Required: 34 hours
Training: 2025-12-01 02:03:31,822-Speed 1102.12 samples/sec   Loss 2.5918 target_logit_mean -0.0003 lma 0.6739  cos_theta_tmp 0.7612  Epoch: 3   Global Step: 57400   Required: 34 hours
Training: 2025-12-01 02:03:49,232-Speed 1102.80 samples/sec   Loss 2.5797 target_logit_mean 0.0016 lma 0.6832  cos_theta_tmp 0.7573  Epoch: 3   Global Step: 57450   Required: 34 hours
Training: 2025-12-01 02:04:06,657-Speed 1101.92 samples/sec   Loss 2.6402 target_logit_mean -0.0006 lma 0.6868  cos_theta_tmp 0.7525  Epoch: 3   Global Step: 57500   Required: 34 hours
Training: 2025-12-01 02:04:24,063-Speed 1103.08 samples/sec   Loss 2.5119 target_logit_mean 0.0009 lma 0.6857  cos_theta_tmp 0.7623  Epoch: 3   Global Step: 57550   Required: 34 hours
Training: 2025-12-01 02:04:41,488-Speed 1101.92 samples/sec   Loss 2.5367 target_logit_mean 0.0004 lma 0.6883  cos_theta_tmp 0.7611  Epoch: 3   Global Step: 57600   Required: 34 hours
Training: 2025-12-01 02:04:58,917-Speed 1101.68 samples/sec   Loss 2.6275 target_logit_mean 0.0005 lma 0.6809  cos_theta_tmp 0.7572  Epoch: 3   Global Step: 57650   Required: 34 hours
Training: 2025-12-01 02:05:16,328-Speed 1102.78 samples/sec   Loss 2.5887 target_logit_mean 0.0023 lma 0.6784  cos_theta_tmp 0.7541  Epoch: 3   Global Step: 57700   Required: 34 hours
Training: 2025-12-01 02:05:33,747-Speed 1102.27 samples/sec   Loss 2.5970 target_logit_mean -0.0001 lma 0.6786  cos_theta_tmp 0.7553  Epoch: 3   Global Step: 57750   Required: 34 hours
Training: 2025-12-01 02:05:51,156-Speed 1102.88 samples/sec   Loss 2.5416 target_logit_mean -0.0015 lma 0.6756  cos_theta_tmp 0.7559  Epoch: 3   Global Step: 57800   Required: 34 hours
Training: 2025-12-01 02:06:08,579-Speed 1102.07 samples/sec   Loss 2.5350 target_logit_mean 0.0017 lma 0.6889  cos_theta_tmp 0.7670  Epoch: 3   Global Step: 57850   Required: 34 hours
Training: 2025-12-01 02:06:26,000-Speed 1102.14 samples/sec   Loss 2.6044 target_logit_mean -0.0003 lma 0.6760  cos_theta_tmp 0.7551  Epoch: 3   Global Step: 57900   Required: 34 hours
Training: 2025-12-01 02:06:43,406-Speed 1103.07 samples/sec   Loss 2.5909 target_logit_mean -0.0009 lma 0.6844  cos_theta_tmp 0.7592  Epoch: 3   Global Step: 57950   Required: 34 hours
Training: 2025-12-01 02:07:00,828-Speed 1102.15 samples/sec   Loss 2.5843 target_logit_mean -0.0019 lma 0.6816  cos_theta_tmp 0.7540  Epoch: 3   Global Step: 58000   Required: 34 hours
Training: 2025-12-01 02:07:18,240-Speed 1102.73 samples/sec   Loss 2.5393 target_logit_mean 0.0002 lma 0.6723  cos_theta_tmp 0.7487  Epoch: 3   Global Step: 58050   Required: 34 hours
Training: 2025-12-01 02:07:35,666-Speed 1101.85 samples/sec   Loss 2.5727 target_logit_mean 0.0004 lma 0.6819  cos_theta_tmp 0.7608  Epoch: 3   Global Step: 58100   Required: 34 hours
Training: 2025-12-01 02:07:53,074-Speed 1102.97 samples/sec   Loss 2.5595 target_logit_mean 0.0003 lma 0.6862  cos_theta_tmp 0.7555  Epoch: 3   Global Step: 58150   Required: 34 hours
Training: 2025-12-01 02:08:10,499-Speed 1101.90 samples/sec   Loss 2.6040 target_logit_mean 0.0023 lma 0.6900  cos_theta_tmp 0.7554  Epoch: 3   Global Step: 58200   Required: 34 hours
Training: 2025-12-01 02:08:27,918-Speed 1102.28 samples/sec   Loss 2.5189 target_logit_mean 0.0010 lma 0.6838  cos_theta_tmp 0.7628  Epoch: 3   Global Step: 58250   Required: 34 hours
Training: 2025-12-01 02:08:45,326-Speed 1102.94 samples/sec   Loss 2.5836 target_logit_mean 0.0023 lma 0.6931  cos_theta_tmp 0.7595  Epoch: 3   Global Step: 58300   Required: 34 hours
Training: 2025-12-01 02:09:02,750-Speed 1101.98 samples/sec   Loss 2.6006 target_logit_mean 0.0003 lma 0.6728  cos_theta_tmp 0.7586  Epoch: 3   Global Step: 58350   Required: 34 hours
Training: 2025-12-01 02:09:20,161-Speed 1102.82 samples/sec   Loss 2.5179 target_logit_mean 0.0016 lma 0.7001  cos_theta_tmp 0.7630  Epoch: 3   Global Step: 58400   Required: 34 hours
Training: 2025-12-01 02:09:37,586-Speed 1101.93 samples/sec   Loss 2.5864 target_logit_mean 0.0011 lma 0.6770  cos_theta_tmp 0.7582  Epoch: 3   Global Step: 58450   Required: 34 hours
Training: 2025-12-01 02:09:54,998-Speed 1102.72 samples/sec   Loss 2.5970 target_logit_mean 0.0013 lma 0.6864  cos_theta_tmp 0.7611  Epoch: 3   Global Step: 58500   Required: 34 hours
Training: 2025-12-01 02:10:12,420-Speed 1102.14 samples/sec   Loss 2.5695 target_logit_mean 0.0004 lma 0.6874  cos_theta_tmp 0.7555  Epoch: 3   Global Step: 58550   Required: 34 hours
Training: 2025-12-01 02:10:29,843-Speed 1102.02 samples/sec   Loss 2.5902 target_logit_mean -0.0003 lma 0.6772  cos_theta_tmp 0.7604  Epoch: 3   Global Step: 58600   Required: 34 hours
Training: 2025-12-01 02:10:47,251-Speed 1102.95 samples/sec   Loss 2.6206 target_logit_mean -0.0020 lma 0.6833  cos_theta_tmp 0.7569  Epoch: 3   Global Step: 58650   Required: 34 hours
Training: 2025-12-01 02:11:04,682-Speed 1101.56 samples/sec   Loss 2.5500 target_logit_mean -0.0025 lma 0.6773  cos_theta_tmp 0.7564  Epoch: 3   Global Step: 58700   Required: 34 hours
Training: 2025-12-01 02:11:22,091-Speed 1102.91 samples/sec   Loss 2.5486 target_logit_mean 0.0002 lma 0.6935  cos_theta_tmp 0.7591  Epoch: 3   Global Step: 58750   Required: 34 hours
Training: 2025-12-01 02:11:39,515-Speed 1101.96 samples/sec   Loss 2.6317 target_logit_mean -0.0016 lma 0.6765  cos_theta_tmp 0.7624  Epoch: 3   Global Step: 58800   Required: 34 hours
Training: 2025-12-01 02:11:56,937-Speed 1102.11 samples/sec   Loss 2.5893 target_logit_mean -0.0031 lma 0.6896  cos_theta_tmp 0.7537  Epoch: 3   Global Step: 58850   Required: 34 hours
Training: 2025-12-01 02:12:14,351-Speed 1102.58 samples/sec   Loss 2.5048 target_logit_mean 0.0017 lma 0.6839  cos_theta_tmp 0.7617  Epoch: 3   Global Step: 58900   Required: 34 hours
Training: 2025-12-01 02:12:31,774-Speed 1102.07 samples/sec   Loss 2.5248 target_logit_mean 0.0021 lma 0.6850  cos_theta_tmp 0.7612  Epoch: 3   Global Step: 58950   Required: 34 hours
Training: 2025-12-01 02:12:49,183-Speed 1102.92 samples/sec   Loss 2.5394 target_logit_mean -0.0020 lma 0.6890  cos_theta_tmp 0.7572  Epoch: 3   Global Step: 59000   Required: 34 hours
Training: 2025-12-01 02:13:06,608-Speed 1101.90 samples/sec   Loss 2.6187 target_logit_mean 0.0010 lma 0.6991  cos_theta_tmp 0.7632  Epoch: 3   Global Step: 59050   Required: 34 hours
Training: 2025-12-01 02:13:24,015-Speed 1103.06 samples/sec   Loss 2.5209 target_logit_mean -0.0010 lma 0.6940  cos_theta_tmp 0.7653  Epoch: 3   Global Step: 59100   Required: 34 hours
Training: 2025-12-01 02:13:41,436-Speed 1102.14 samples/sec   Loss 2.5709 target_logit_mean -0.0008 lma 0.6629  cos_theta_tmp 0.7554  Epoch: 3   Global Step: 59150   Required: 34 hours
Training: 2025-12-01 02:13:58,858-Speed 1102.07 samples/sec   Loss 2.5727 target_logit_mean -0.0009 lma 0.6870  cos_theta_tmp 0.7595  Epoch: 3   Global Step: 59200   Required: 34 hours
Training: 2025-12-01 02:14:16,268-Speed 1102.89 samples/sec   Loss 2.5257 target_logit_mean 0.0028 lma 0.6841  cos_theta_tmp 0.7655  Epoch: 3   Global Step: 59250   Required: 34 hours
Training: 2025-12-01 02:14:33,690-Speed 1102.08 samples/sec   Loss 2.5889 target_logit_mean 0.0005 lma 0.6976  cos_theta_tmp 0.7638  Epoch: 3   Global Step: 59300   Required: 34 hours
Training: 2025-12-01 02:14:51,105-Speed 1102.58 samples/sec   Loss 2.5986 target_logit_mean -0.0016 lma 0.6693  cos_theta_tmp 0.7566  Epoch: 3   Global Step: 59350   Required: 34 hours
Training: 2025-12-01 02:15:08,516-Speed 1102.79 samples/sec   Loss 2.6115 target_logit_mean -0.0027 lma 0.6751  cos_theta_tmp 0.7535  Epoch: 3   Global Step: 59400   Required: 34 hours
Training: 2025-12-01 02:15:25,934-Speed 1102.33 samples/sec   Loss 2.5995 target_logit_mean 0.0004 lma 0.6778  cos_theta_tmp 0.7513  Epoch: 3   Global Step: 59450   Required: 34 hours
Training: 2025-12-01 02:15:43,345-Speed 1102.81 samples/sec   Loss 2.5630 target_logit_mean -0.0000 lma 0.6803  cos_theta_tmp 0.7570  Epoch: 3   Global Step: 59500   Required: 34 hours
Training: 2025-12-01 02:16:00,767-Speed 1102.09 samples/sec   Loss 2.5545 target_logit_mean -0.0022 lma 0.6741  cos_theta_tmp 0.7534  Epoch: 3   Global Step: 59550   Required: 34 hours
Training: 2025-12-01 02:16:18,178-Speed 1102.79 samples/sec   Loss 2.5697 target_logit_mean 0.0023 lma 0.6909  cos_theta_tmp 0.7553  Epoch: 3   Global Step: 59600   Required: 34 hours
Training: 2025-12-01 02:16:35,603-Speed 1101.93 samples/sec   Loss 2.6398 target_logit_mean 0.0031 lma 0.6830  cos_theta_tmp 0.7602  Epoch: 3   Global Step: 59650   Required: 34 hours
Training: 2025-12-01 02:16:53,014-Speed 1102.77 samples/sec   Loss 2.5820 target_logit_mean 0.0002 lma 0.6856  cos_theta_tmp 0.7613  Epoch: 3   Global Step: 59700   Required: 34 hours
Training: 2025-12-01 02:17:10,440-Speed 1101.84 samples/sec   Loss 2.5862 target_logit_mean 0.0023 lma 0.6822  cos_theta_tmp 0.7646  Epoch: 3   Global Step: 59750   Required: 34 hours
Training: 2025-12-01 02:17:27,861-Speed 1102.16 samples/sec   Loss 2.5835 target_logit_mean 0.0012 lma 0.6718  cos_theta_tmp 0.7601  Epoch: 3   Global Step: 59800   Required: 34 hours
Training: 2025-12-01 02:17:45,274-Speed 1102.62 samples/sec   Loss 2.6096 target_logit_mean -0.0002 lma 0.6808  cos_theta_tmp 0.7581  Epoch: 3   Global Step: 59850   Required: 34 hours
Training: 2025-12-01 02:18:02,697-Speed 1102.03 samples/sec   Loss 2.5897 target_logit_mean 0.0021 lma 0.6909  cos_theta_tmp 0.7628  Epoch: 3   Global Step: 59900   Required: 34 hours
Training: 2025-12-01 02:18:20,110-Speed 1102.65 samples/sec   Loss 2.5141 target_logit_mean 0.0018 lma 0.6832  cos_theta_tmp 0.7612  Epoch: 3   Global Step: 59950   Required: 34 hours
Training: 2025-12-01 02:18:37,536-Speed 1101.88 samples/sec   Loss 2.6295 target_logit_mean -0.0002 lma 0.6828  cos_theta_tmp 0.7570  Epoch: 3   Global Step: 60000   Required: 34 hours
Training: 2025-12-01 02:18:54,942-Speed 1103.07 samples/sec   Loss 2.5266 target_logit_mean 0.0015 lma 0.6822  cos_theta_tmp 0.7557  Epoch: 3   Global Step: 60050   Required: 34 hours
Training: 2025-12-01 02:19:12,369-Speed 1101.77 samples/sec   Loss 2.5143 target_logit_mean 0.0004 lma 0.6930  cos_theta_tmp 0.7634  Epoch: 3   Global Step: 60100   Required: 34 hours
Training: 2025-12-01 02:19:29,793-Speed 1102.02 samples/sec   Loss 2.5383 target_logit_mean 0.0006 lma 0.6880  cos_theta_tmp 0.7587  Epoch: 3   Global Step: 60150   Required: 34 hours
Training: 2025-12-01 02:19:47,207-Speed 1102.55 samples/sec   Loss 2.5533 target_logit_mean 0.0027 lma 0.6796  cos_theta_tmp 0.7644  Epoch: 3   Global Step: 60200   Required: 34 hours
Training: 2025-12-01 02:20:04,629-Speed 1102.13 samples/sec   Loss 2.5575 target_logit_mean -0.0017 lma 0.6787  cos_theta_tmp 0.7555  Epoch: 3   Global Step: 60250   Required: 34 hours
Training: 2025-12-01 02:20:22,043-Speed 1102.61 samples/sec   Loss 2.5263 target_logit_mean -0.0022 lma 0.6814  cos_theta_tmp 0.7573  Epoch: 3   Global Step: 60300   Required: 34 hours
Training: 2025-12-01 02:20:39,465-Speed 1102.08 samples/sec   Loss 2.6307 target_logit_mean -0.0002 lma 0.6772  cos_theta_tmp 0.7586  Epoch: 3   Global Step: 60350   Required: 34 hours
Training: 2025-12-01 02:20:56,892-Speed 1101.77 samples/sec   Loss 2.5942 target_logit_mean -0.0000 lma 0.6822  cos_theta_tmp 0.7539  Epoch: 3   Global Step: 60400   Required: 34 hours
Training: 2025-12-01 02:21:14,302-Speed 1102.86 samples/sec   Loss 2.5510 target_logit_mean -0.0018 lma 0.6845  cos_theta_tmp 0.7599  Epoch: 3   Global Step: 60450   Required: 34 hours
Training: 2025-12-01 02:21:31,724-Speed 1102.10 samples/sec   Loss 2.5536 target_logit_mean -0.0002 lma 0.6822  cos_theta_tmp 0.7615  Epoch: 3   Global Step: 60500   Required: 34 hours
Training: 2025-12-01 02:21:49,128-Speed 1103.19 samples/sec   Loss 2.5967 target_logit_mean 0.0010 lma 0.6825  cos_theta_tmp 0.7615  Epoch: 3   Global Step: 60550   Required: 34 hours
Training: 2025-12-01 02:22:06,554-Speed 1101.87 samples/sec   Loss 2.5375 target_logit_mean 0.0002 lma 0.6781  cos_theta_tmp 0.7605  Epoch: 3   Global Step: 60600   Required: 34 hours
Training: 2025-12-01 02:22:24,025-Speed 1098.97 samples/sec   Loss 2.6006 target_logit_mean 0.0026 lma 0.6849  cos_theta_tmp 0.7653  Epoch: 3   Global Step: 60650   Required: 34 hours
Training: 2025-12-01 02:22:37,958-[lfw][60652]XNorm: 23.143393
Training: 2025-12-01 02:22:37,959-[lfw][60652]Accuracy-Flip: 0.99083+-0.00410
Training: 2025-12-01 02:22:37,959-[lfw][60652]Accuracy-Highest: 0.99083
Training: 2025-12-01 02:22:52,202-[cfp_fp][60652]XNorm: 18.910872
Training: 2025-12-01 02:22:52,202-[cfp_fp][60652]Accuracy-Flip: 0.88429+-0.01298
Training: 2025-12-01 02:22:52,203-[cfp_fp][60652]Accuracy-Highest: 0.88429
Training: 2025-12-01 02:23:07,031-[cfp_ff][60652]XNorm: 22.518054
Training: 2025-12-01 02:23:07,032-[cfp_ff][60652]Accuracy-Flip: 0.98871+-0.00484
Training: 2025-12-01 02:23:07,032-[cfp_ff][60652]Accuracy-Highest: 0.98986
Training: 2025-12-01 02:23:19,636-[agedb_30][60652]XNorm: 22.162073
Training: 2025-12-01 02:23:19,636-[agedb_30][60652]Accuracy-Flip: 0.92300+-0.01100
Training: 2025-12-01 02:23:19,637-[agedb_30][60652]Accuracy-Highest: 0.92717
Training: 2025-12-01 02:23:32,933-[calfw][60652]XNorm: 23.140559
Training: 2025-12-01 02:23:32,933-[calfw][60652]Accuracy-Flip: 0.93117+-0.00986
Training: 2025-12-01 02:23:32,933-[calfw][60652]Accuracy-Highest: 0.93883
Training: 2025-12-01 02:23:45,282-[cplfw][60652]XNorm: 18.978892
Training: 2025-12-01 02:23:45,282-[cplfw][60652]Accuracy-Flip: 0.85200+-0.02397
Training: 2025-12-01 02:23:45,282-[cplfw][60652]Accuracy-Highest: 0.85333
Training: 2025-12-01 02:23:56,005-[vgg2_fp][60652]XNorm: 19.420907
Training: 2025-12-01 02:23:56,006-[vgg2_fp][60652]Accuracy-Flip: 0.88500+-0.01318
Training: 2025-12-01 02:23:56,006-[vgg2_fp][60652]Accuracy-Highest: 0.88500
Training: 2025-12-01 02:25:55,234-[IJB][IJBB_gt_aligned] {'Norm:True_Det:True_tpr_at_fpr_1e-06': 30.214216163583252, 'Norm:True_Det:True_thresh_at_fpr_1e-06': 0.759253703058451, 'Norm:True_Det:True_tpr_at_fpr_1e-05': 59.50340798442064, 'Norm:True_Det:True_thresh_at_fpr_1e-05': 0.6219891281711789, 'Norm:True_Det:True_tpr_at_fpr_0.0001': 79.5618305744888, 'Norm:True_Det:True_thresh_at_fpr_0.0001': 0.4908320366575011, 'Norm:True_Det:True_tpr_at_fpr_0.001': 88.06231742940604, 'Norm:True_Det:True_thresh_at_fpr_0.001': 0.40755130702294995, 'Norm:True_Det:True_tpr_at_fpr_0.01': 93.4761441090555, 'Norm:True_Det:True_thresh_at_fpr_0.01': 0.32335797778646014, 'Norm:True_Det:True_tpr_at_fpr_0.1': 97.40993184031159, 'Norm:True_Det:True_thresh_at_fpr_0.1': 0.22522928447972057, 'Norm:True_Det:False_tpr_at_fpr_1e-06': 30.730282375851996, 'Norm:True_Det:False_thresh_at_fpr_1e-06': 0.7564476285171493, 'Norm:True_Det:False_tpr_at_fpr_1e-05': 55.978578383641675, 'Norm:True_Det:False_thresh_at_fpr_1e-05': 0.6415597808162861, 'Norm:True_Det:False_tpr_at_fpr_0.0001': 77.5462512171373, 'Norm:True_Det:False_thresh_at_fpr_0.0001': 0.5064675769383368, 'Norm:True_Det:False_tpr_at_fpr_0.001': 87.5365141187926, 'Norm:True_Det:False_thresh_at_fpr_0.001': 0.4139081165447365, 'Norm:True_Det:False_tpr_at_fpr_0.01': 93.33982473222979, 'Norm:True_Det:False_thresh_at_fpr_0.01': 0.32616196114304963, 'Norm:True_Det:False_tpr_at_fpr_0.1': 97.33203505355405, 'Norm:True_Det:False_thresh_at_fpr_0.1': 0.22659173062586124, 'Norm:False_Det:True_tpr_at_fpr_1e-06': 27.234664070107108, 'Norm:False_Det:True_thresh_at_fpr_1e-06': 0.7564279346415024, 'Norm:False_Det:True_tpr_at_fpr_1e-05': 50.67185978578384, 'Norm:False_Det:True_thresh_at_fpr_1e-05': 0.6533848908171436, 'Norm:False_Det:True_tpr_at_fpr_0.0001': 72.56085686465433, 'Norm:False_Det:True_thresh_at_fpr_0.0001': 0.5329814828671666, 'Norm:False_Det:True_tpr_at_fpr_0.001': 84.83933787731256, 'Norm:False_Det:True_thresh_at_fpr_0.001': 0.4344907150804748, 'Norm:False_Det:True_tpr_at_fpr_0.01': 92.44401168451802, 'Norm:False_Det:True_thresh_at_fpr_0.01': 0.34029459919766347, 'Norm:False_Det:True_tpr_at_fpr_0.1': 97.27361246348588, 'Norm:False_Det:True_thresh_at_fpr_0.1': 0.23452588260628077}
Training: 2025-12-01 02:29:57,201-[IJB][IJBC_gt_aligned] {'Norm:True_Det:True_tpr_at_fpr_1e-06': 39.239147108452215, 'Norm:True_Det:True_thresh_at_fpr_1e-06': 0.7308377253951883, 'Norm:True_Det:True_tpr_at_fpr_1e-05': 63.11806514291558, 'Norm:True_Det:True_thresh_at_fpr_1e-05': 0.6190524113288607, 'Norm:True_Det:True_tpr_at_fpr_0.0001': 81.19854783453495, 'Norm:True_Det:True_thresh_at_fpr_0.0001': 0.5023753550058383, 'Norm:True_Det:True_tpr_at_fpr_0.001': 89.98823950503656, 'Norm:True_Det:True_thresh_at_fpr_0.001': 0.4082881804676691, 'Norm:True_Det:True_tpr_at_fpr_0.01': 94.83049547476607, 'Norm:True_Det:True_thresh_at_fpr_0.01': 0.32132718269565064, 'Norm:True_Det:True_tpr_at_fpr_0.1': 97.87288438922126, 'Norm:True_Det:True_thresh_at_fpr_0.1': 0.22342517644907223, 'Norm:True_Det:False_tpr_at_fpr_1e-06': 35.36329702919671, 'Norm:True_Det:False_thresh_at_fpr_1e-06': 0.7451764415698119, 'Norm:True_Det:False_tpr_at_fpr_1e-05': 58.628624022089284, 'Norm:True_Det:False_thresh_at_fpr_1e-05': 0.6430617714548873, 'Norm:True_Det:False_tpr_at_fpr_0.0001': 78.62146545993762, 'Norm:True_Det:False_thresh_at_fpr_0.0001': 0.5220867234941005, 'Norm:True_Det:False_tpr_at_fpr_0.001': 89.37464846346576, 'Norm:True_Det:False_thresh_at_fpr_0.001': 0.41684292562389547, 'Norm:True_Det:False_tpr_at_fpr_0.01': 94.68732423173289, 'Norm:True_Det:False_thresh_at_fpr_0.01': 0.32510337401297573, 'Norm:True_Det:False_tpr_at_fpr_0.1': 97.86265787186174, 'Norm:True_Det:False_thresh_at_fpr_0.1': 0.22522928435073603, 'Norm:False_Det:True_tpr_at_fpr_1e-06': 29.938129569974947, 'Norm:False_Det:True_thresh_at_fpr_1e-06': 0.753021914154079, 'Norm:False_Det:True_tpr_at_fpr_1e-05': 50.47297642787749, 'Norm:False_Det:True_thresh_at_fpr_1e-05': 0.6670490558407669, 'Norm:False_Det:True_tpr_at_fpr_0.0001': 71.5293756711152, 'Norm:False_Det:True_thresh_at_fpr_0.0001': 0.5581919345239117, 'Norm:False_Det:True_tpr_at_fpr_0.001': 86.16352201257862, 'Norm:False_Det:True_thresh_at_fpr_0.001': 0.4479182018630015, 'Norm:False_Det:True_tpr_at_fpr_0.01': 93.59820013294473, 'Norm:False_Det:True_thresh_at_fpr_0.01': 0.3443483160696774, 'Norm:False_Det:True_tpr_at_fpr_0.1': 97.74505292222734, 'Norm:False_Det:True_thresh_at_fpr_0.1': 0.23460968961918335}
Training: 2025-12-01 02:31:35,561-[TinyFace][tinyface_aligned_pad_0.1] {'rank-1': 52.68240571022034, 'rank-5': 59.22746658325195, 'rank-20': 63.89485001564026}
Training: 2025-12-01 02:32:10,691-Speed 32.73 samples/sec   Loss 2.5759 target_logit_mean 0.0011 lma 0.6954  cos_theta_tmp 0.7639  Epoch: 4   Global Step: 60700   Required: 34 hours
Training: 2025-12-01 02:32:28,128-Speed 1101.15 samples/sec   Loss 2.5132 target_logit_mean 0.0001 lma 0.6817  cos_theta_tmp 0.7594  Epoch: 4   Global Step: 60750   Required: 34 hours
Training: 2025-12-01 02:32:45,622-Speed 1097.50 samples/sec   Loss 2.4999 target_logit_mean 0.0008 lma 0.6876  cos_theta_tmp 0.7580  Epoch: 4   Global Step: 60800   Required: 34 hours
Training: 2025-12-01 02:33:03,152-Speed 1095.30 samples/sec   Loss 2.5470 target_logit_mean -0.0003 lma 0.6766  cos_theta_tmp 0.7570  Epoch: 4   Global Step: 60850   Required: 34 hours
Training: 2025-12-01 02:33:20,592-Speed 1101.01 samples/sec   Loss 2.4564 target_logit_mean 0.0014 lma 0.6880  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 60900   Required: 34 hours
Training: 2025-12-01 02:33:38,072-Speed 1098.46 samples/sec   Loss 2.5310 target_logit_mean -0.0013 lma 0.6858  cos_theta_tmp 0.7577  Epoch: 4   Global Step: 60950   Required: 34 hours
Training: 2025-12-01 02:33:55,492-Speed 1102.19 samples/sec   Loss 2.5201 target_logit_mean 0.0036 lma 0.6954  cos_theta_tmp 0.7616  Epoch: 4   Global Step: 61000   Required: 34 hours
Training: 2025-12-01 02:34:12,922-Speed 1101.61 samples/sec   Loss 2.5821 target_logit_mean -0.0006 lma 0.6781  cos_theta_tmp 0.7597  Epoch: 4   Global Step: 61050   Required: 34 hours
Training: 2025-12-01 02:34:30,368-Speed 1100.54 samples/sec   Loss 2.5604 target_logit_mean -0.0007 lma 0.6697  cos_theta_tmp 0.7522  Epoch: 4   Global Step: 61100   Required: 34 hours
Training: 2025-12-01 02:34:47,793-Speed 1101.96 samples/sec   Loss 2.5273 target_logit_mean 0.0010 lma 0.6799  cos_theta_tmp 0.7555  Epoch: 4   Global Step: 61150   Required: 34 hours
Training: 2025-12-01 02:35:05,216-Speed 1102.01 samples/sec   Loss 2.5972 target_logit_mean 0.0017 lma 0.6863  cos_theta_tmp 0.7567  Epoch: 4   Global Step: 61200   Required: 34 hours
Training: 2025-12-01 02:35:22,640-Speed 1101.95 samples/sec   Loss 2.5385 target_logit_mean -0.0017 lma 0.6861  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 61250   Required: 34 hours
Training: 2025-12-01 02:35:40,059-Speed 1102.30 samples/sec   Loss 2.5925 target_logit_mean 0.0006 lma 0.6855  cos_theta_tmp 0.7577  Epoch: 4   Global Step: 61300   Required: 34 hours
Training: 2025-12-01 02:35:57,481-Speed 1102.10 samples/sec   Loss 2.5388 target_logit_mean 0.0044 lma 0.6947  cos_theta_tmp 0.7625  Epoch: 4   Global Step: 61350   Required: 34 hours
Training: 2025-12-01 02:36:14,904-Speed 1102.06 samples/sec   Loss 2.5331 target_logit_mean -0.0006 lma 0.6811  cos_theta_tmp 0.7628  Epoch: 4   Global Step: 61400   Required: 34 hours
Training: 2025-12-01 02:36:32,323-Speed 1102.25 samples/sec   Loss 2.5401 target_logit_mean -0.0020 lma 0.6883  cos_theta_tmp 0.7609  Epoch: 4   Global Step: 61450   Required: 34 hours
Training: 2025-12-01 02:36:49,742-Speed 1102.27 samples/sec   Loss 2.5298 target_logit_mean -0.0015 lma 0.6717  cos_theta_tmp 0.7580  Epoch: 4   Global Step: 61500   Required: 34 hours
Training: 2025-12-01 02:37:07,166-Speed 1101.97 samples/sec   Loss 2.5679 target_logit_mean -0.0002 lma 0.6981  cos_theta_tmp 0.7561  Epoch: 4   Global Step: 61550   Required: 34 hours
Training: 2025-12-01 02:37:24,592-Speed 1101.86 samples/sec   Loss 2.5520 target_logit_mean 0.0010 lma 0.6925  cos_theta_tmp 0.7605  Epoch: 4   Global Step: 61600   Required: 34 hours
Training: 2025-12-01 02:37:42,016-Speed 1101.92 samples/sec   Loss 2.5841 target_logit_mean 0.0002 lma 0.7018  cos_theta_tmp 0.7583  Epoch: 4   Global Step: 61650   Required: 34 hours
Training: 2025-12-01 02:37:59,442-Speed 1101.88 samples/sec   Loss 2.5304 target_logit_mean -0.0004 lma 0.6849  cos_theta_tmp 0.7586  Epoch: 4   Global Step: 61700   Required: 34 hours
Training: 2025-12-01 02:38:16,859-Speed 1102.37 samples/sec   Loss 2.5898 target_logit_mean -0.0021 lma 0.6879  cos_theta_tmp 0.7570  Epoch: 4   Global Step: 61750   Required: 34 hours
Training: 2025-12-01 02:38:34,277-Speed 1102.38 samples/sec   Loss 2.5942 target_logit_mean -0.0022 lma 0.6796  cos_theta_tmp 0.7573  Epoch: 4   Global Step: 61800   Required: 34 hours
Training: 2025-12-01 02:38:51,697-Speed 1102.23 samples/sec   Loss 2.5367 target_logit_mean -0.0025 lma 0.6852  cos_theta_tmp 0.7600  Epoch: 4   Global Step: 61850   Required: 34 hours
Training: 2025-12-01 02:39:09,116-Speed 1102.28 samples/sec   Loss 2.5505 target_logit_mean 0.0002 lma 0.6911  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 61900   Required: 34 hours
Training: 2025-12-01 02:39:26,532-Speed 1102.46 samples/sec   Loss 2.5424 target_logit_mean -0.0014 lma 0.6863  cos_theta_tmp 0.7604  Epoch: 4   Global Step: 61950   Required: 34 hours
Training: 2025-12-01 02:39:43,988-Speed 1099.98 samples/sec   Loss 2.5683 target_logit_mean 0.0004 lma 0.6887  cos_theta_tmp 0.7554  Epoch: 4   Global Step: 62000   Required: 34 hours
Training: 2025-12-01 02:40:01,404-Speed 1102.47 samples/sec   Loss 2.5339 target_logit_mean 0.0002 lma 0.6740  cos_theta_tmp 0.7599  Epoch: 4   Global Step: 62050   Required: 34 hours
Training: 2025-12-01 02:40:18,821-Speed 1102.41 samples/sec   Loss 2.5785 target_logit_mean 0.0015 lma 0.6820  cos_theta_tmp 0.7585  Epoch: 4   Global Step: 62100   Required: 34 hours
Training: 2025-12-01 02:40:36,240-Speed 1102.27 samples/sec   Loss 2.5974 target_logit_mean 0.0008 lma 0.6929  cos_theta_tmp 0.7623  Epoch: 4   Global Step: 62150   Required: 34 hours
Training: 2025-12-01 02:40:53,657-Speed 1102.40 samples/sec   Loss 2.5281 target_logit_mean -0.0003 lma 0.6784  cos_theta_tmp 0.7544  Epoch: 4   Global Step: 62200   Required: 34 hours
Training: 2025-12-01 02:41:11,074-Speed 1102.41 samples/sec   Loss 2.5792 target_logit_mean 0.0011 lma 0.6833  cos_theta_tmp 0.7609  Epoch: 4   Global Step: 62250   Required: 34 hours
Training: 2025-12-01 02:41:28,491-Speed 1102.45 samples/sec   Loss 2.5444 target_logit_mean -0.0015 lma 0.6807  cos_theta_tmp 0.7599  Epoch: 4   Global Step: 62300   Required: 34 hours
Training: 2025-12-01 02:41:45,910-Speed 1102.30 samples/sec   Loss 2.5403 target_logit_mean 0.0011 lma 0.6862  cos_theta_tmp 0.7643  Epoch: 4   Global Step: 62350   Required: 34 hours
Training: 2025-12-01 02:42:03,329-Speed 1102.26 samples/sec   Loss 2.5198 target_logit_mean 0.0006 lma 0.6913  cos_theta_tmp 0.7637  Epoch: 4   Global Step: 62400   Required: 34 hours
Training: 2025-12-01 02:42:20,744-Speed 1102.56 samples/sec   Loss 2.5940 target_logit_mean 0.0011 lma 0.6750  cos_theta_tmp 0.7506  Epoch: 4   Global Step: 62450   Required: 34 hours
Training: 2025-12-01 02:42:38,162-Speed 1102.33 samples/sec   Loss 2.6057 target_logit_mean -0.0020 lma 0.6723  cos_theta_tmp 0.7530  Epoch: 4   Global Step: 62500   Required: 34 hours
Training: 2025-12-01 02:42:55,578-Speed 1102.52 samples/sec   Loss 2.5779 target_logit_mean 0.0016 lma 0.6897  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 62550   Required: 34 hours
Training: 2025-12-01 02:43:12,993-Speed 1102.51 samples/sec   Loss 2.5305 target_logit_mean 0.0008 lma 0.6830  cos_theta_tmp 0.7609  Epoch: 4   Global Step: 62600   Required: 34 hours
Training: 2025-12-01 02:43:30,410-Speed 1102.42 samples/sec   Loss 2.5459 target_logit_mean -0.0014 lma 0.6843  cos_theta_tmp 0.7506  Epoch: 4   Global Step: 62650   Required: 34 hours
Training: 2025-12-01 02:43:47,859-Speed 1100.38 samples/sec   Loss 2.5163 target_logit_mean 0.0005 lma 0.6902  cos_theta_tmp 0.7623  Epoch: 4   Global Step: 62700   Required: 34 hours
Training: 2025-12-01 02:44:05,280-Speed 1102.18 samples/sec   Loss 2.6142 target_logit_mean 0.0005 lma 0.6777  cos_theta_tmp 0.7619  Epoch: 4   Global Step: 62750   Required: 34 hours
Training: 2025-12-01 02:44:22,694-Speed 1102.60 samples/sec   Loss 2.5466 target_logit_mean 0.0027 lma 0.6861  cos_theta_tmp 0.7636  Epoch: 4   Global Step: 62800   Required: 34 hours
Training: 2025-12-01 02:44:40,106-Speed 1102.71 samples/sec   Loss 2.5259 target_logit_mean 0.0016 lma 0.6900  cos_theta_tmp 0.7642  Epoch: 4   Global Step: 62850   Required: 34 hours
Training: 2025-12-01 02:44:57,515-Speed 1102.91 samples/sec   Loss 2.5923 target_logit_mean 0.0003 lma 0.6739  cos_theta_tmp 0.7583  Epoch: 4   Global Step: 62900   Required: 34 hours
Training: 2025-12-01 02:45:14,928-Speed 1102.66 samples/sec   Loss 2.6148 target_logit_mean -0.0034 lma 0.6731  cos_theta_tmp 0.7559  Epoch: 4   Global Step: 62950   Required: 34 hours
Training: 2025-12-01 02:45:32,342-Speed 1102.63 samples/sec   Loss 2.5259 target_logit_mean 0.0003 lma 0.6891  cos_theta_tmp 0.7592  Epoch: 4   Global Step: 63000   Required: 34 hours
Training: 2025-12-01 02:45:49,753-Speed 1102.77 samples/sec   Loss 2.5406 target_logit_mean -0.0008 lma 0.6800  cos_theta_tmp 0.7562  Epoch: 4   Global Step: 63050   Required: 34 hours
Training: 2025-12-01 02:46:07,167-Speed 1102.59 samples/sec   Loss 2.5310 target_logit_mean 0.0015 lma 0.6827  cos_theta_tmp 0.7573  Epoch: 4   Global Step: 63100   Required: 34 hours
Training: 2025-12-01 02:46:24,582-Speed 1102.55 samples/sec   Loss 2.5213 target_logit_mean 0.0000 lma 0.6818  cos_theta_tmp 0.7602  Epoch: 4   Global Step: 63150   Required: 34 hours
Training: 2025-12-01 02:46:41,995-Speed 1102.63 samples/sec   Loss 2.5892 target_logit_mean 0.0002 lma 0.6738  cos_theta_tmp 0.7495  Epoch: 4   Global Step: 63200   Required: 34 hours
Training: 2025-12-01 02:46:59,408-Speed 1102.70 samples/sec   Loss 2.5322 target_logit_mean 0.0001 lma 0.6848  cos_theta_tmp 0.7601  Epoch: 4   Global Step: 63250   Required: 34 hours
Training: 2025-12-01 02:47:16,827-Speed 1102.29 samples/sec   Loss 2.5330 target_logit_mean 0.0019 lma 0.6751  cos_theta_tmp 0.7608  Epoch: 4   Global Step: 63300   Required: 34 hours
Training: 2025-12-01 02:47:34,242-Speed 1102.55 samples/sec   Loss 2.5375 target_logit_mean 0.0001 lma 0.6912  cos_theta_tmp 0.7592  Epoch: 4   Global Step: 63350   Required: 34 hours
Training: 2025-12-01 02:47:51,659-Speed 1102.41 samples/sec   Loss 2.5544 target_logit_mean 0.0029 lma 0.6796  cos_theta_tmp 0.7648  Epoch: 4   Global Step: 63400   Required: 34 hours
Training: 2025-12-01 02:48:09,076-Speed 1102.41 samples/sec   Loss 2.5193 target_logit_mean -0.0006 lma 0.6751  cos_theta_tmp 0.7538  Epoch: 4   Global Step: 63450   Required: 34 hours
Training: 2025-12-01 02:48:26,493-Speed 1102.42 samples/sec   Loss 2.5403 target_logit_mean 0.0011 lma 0.6730  cos_theta_tmp 0.7647  Epoch: 4   Global Step: 63500   Required: 34 hours
Training: 2025-12-01 02:48:43,905-Speed 1102.70 samples/sec   Loss 2.5385 target_logit_mean 0.0005 lma 0.6916  cos_theta_tmp 0.7597  Epoch: 4   Global Step: 63550   Required: 34 hours
Training: 2025-12-01 02:49:01,317-Speed 1102.72 samples/sec   Loss 2.5711 target_logit_mean -0.0007 lma 0.6812  cos_theta_tmp 0.7575  Epoch: 4   Global Step: 63600   Required: 34 hours
Training: 2025-12-01 02:49:18,735-Speed 1102.39 samples/sec   Loss 2.5777 target_logit_mean -0.0006 lma 0.6910  cos_theta_tmp 0.7622  Epoch: 4   Global Step: 63650   Required: 34 hours
Training: 2025-12-01 02:49:36,148-Speed 1102.61 samples/sec   Loss 2.5617 target_logit_mean 0.0001 lma 0.6817  cos_theta_tmp 0.7571  Epoch: 4   Global Step: 63700   Required: 34 hours
Training: 2025-12-01 02:49:53,557-Speed 1102.95 samples/sec   Loss 2.6131 target_logit_mean 0.0016 lma 0.6839  cos_theta_tmp 0.7579  Epoch: 4   Global Step: 63750   Required: 34 hours
Training: 2025-12-01 02:50:10,972-Speed 1102.54 samples/sec   Loss 2.5312 target_logit_mean -0.0032 lma 0.6882  cos_theta_tmp 0.7644  Epoch: 4   Global Step: 63800   Required: 34 hours
Training: 2025-12-01 02:50:28,390-Speed 1102.30 samples/sec   Loss 2.5726 target_logit_mean -0.0006 lma 0.6631  cos_theta_tmp 0.7599  Epoch: 4   Global Step: 63850   Required: 34 hours
Training: 2025-12-01 02:50:45,803-Speed 1102.70 samples/sec   Loss 2.5303 target_logit_mean -0.0016 lma 0.6854  cos_theta_tmp 0.7605  Epoch: 4   Global Step: 63900   Required: 34 hours
Training: 2025-12-01 02:51:03,223-Speed 1102.20 samples/sec   Loss 2.5709 target_logit_mean 0.0002 lma 0.6895  cos_theta_tmp 0.7482  Epoch: 4   Global Step: 63950   Required: 34 hours
Training: 2025-12-01 02:51:20,640-Speed 1102.39 samples/sec   Loss 2.5783 target_logit_mean 0.0009 lma 0.6845  cos_theta_tmp 0.7565  Epoch: 4   Global Step: 64000   Required: 34 hours
Training: 2025-12-01 02:51:38,052-Speed 1102.75 samples/sec   Loss 2.5637 target_logit_mean 0.0014 lma 0.6865  cos_theta_tmp 0.7592  Epoch: 4   Global Step: 64050   Required: 34 hours
Training: 2025-12-01 02:51:55,463-Speed 1102.76 samples/sec   Loss 2.5031 target_logit_mean 0.0014 lma 0.6726  cos_theta_tmp 0.7555  Epoch: 4   Global Step: 64100   Required: 34 hours
Training: 2025-12-01 02:52:12,880-Speed 1102.41 samples/sec   Loss 2.5296 target_logit_mean 0.0011 lma 0.6830  cos_theta_tmp 0.7578  Epoch: 4   Global Step: 64150   Required: 34 hours
Training: 2025-12-01 02:52:30,295-Speed 1102.54 samples/sec   Loss 2.6104 target_logit_mean -0.0013 lma 0.6866  cos_theta_tmp 0.7595  Epoch: 4   Global Step: 64200   Required: 34 hours
Training: 2025-12-01 02:52:47,712-Speed 1102.41 samples/sec   Loss 2.6104 target_logit_mean 0.0015 lma 0.6830  cos_theta_tmp 0.7615  Epoch: 4   Global Step: 64250   Required: 34 hours
Training: 2025-12-01 02:53:05,128-Speed 1102.46 samples/sec   Loss 2.5444 target_logit_mean 0.0005 lma 0.6790  cos_theta_tmp 0.7574  Epoch: 4   Global Step: 64300   Required: 34 hours
Training: 2025-12-01 02:53:22,543-Speed 1102.51 samples/sec   Loss 2.5345 target_logit_mean 0.0003 lma 0.6795  cos_theta_tmp 0.7577  Epoch: 4   Global Step: 64350   Required: 34 hours
Training: 2025-12-01 02:53:39,957-Speed 1102.62 samples/sec   Loss 2.5423 target_logit_mean -0.0006 lma 0.6952  cos_theta_tmp 0.7598  Epoch: 4   Global Step: 64400   Required: 34 hours
Training: 2025-12-01 02:53:57,377-Speed 1102.24 samples/sec   Loss 2.5128 target_logit_mean 0.0006 lma 0.6875  cos_theta_tmp 0.7697  Epoch: 4   Global Step: 64450   Required: 34 hours
Training: 2025-12-01 02:54:14,789-Speed 1102.70 samples/sec   Loss 2.5351 target_logit_mean -0.0010 lma 0.6794  cos_theta_tmp 0.7559  Epoch: 4   Global Step: 64500   Required: 34 hours
Training: 2025-12-01 02:54:32,206-Speed 1102.46 samples/sec   Loss 2.4564 target_logit_mean -0.0000 lma 0.6787  cos_theta_tmp 0.7618  Epoch: 4   Global Step: 64550   Required: 34 hours
Training: 2025-12-01 02:54:49,618-Speed 1102.67 samples/sec   Loss 2.5066 target_logit_mean -0.0014 lma 0.6718  cos_theta_tmp 0.7560  Epoch: 4   Global Step: 64600   Required: 34 hours
Training: 2025-12-01 02:55:07,032-Speed 1102.61 samples/sec   Loss 2.5380 target_logit_mean -0.0031 lma 0.6730  cos_theta_tmp 0.7543  Epoch: 4   Global Step: 64650   Required: 34 hours
Training: 2025-12-01 02:55:24,450-Speed 1102.33 samples/sec   Loss 2.5889 target_logit_mean 0.0022 lma 0.6913  cos_theta_tmp 0.7631  Epoch: 4   Global Step: 64700   Required: 34 hours
Training: 2025-12-01 02:55:41,865-Speed 1102.55 samples/sec   Loss 2.5421 target_logit_mean 0.0014 lma 0.6876  cos_theta_tmp 0.7622  Epoch: 4   Global Step: 64750   Required: 34 hours
Training: 2025-12-01 02:55:59,275-Speed 1102.89 samples/sec   Loss 2.5361 target_logit_mean 0.0002 lma 0.6922  cos_theta_tmp 0.7603  Epoch: 4   Global Step: 64800   Required: 34 hours
Training: 2025-12-01 02:56:16,682-Speed 1103.02 samples/sec   Loss 2.5298 target_logit_mean -0.0014 lma 0.6839  cos_theta_tmp 0.7596  Epoch: 4   Global Step: 64850   Required: 34 hours
Training: 2025-12-01 02:56:34,096-Speed 1102.58 samples/sec   Loss 2.5509 target_logit_mean -0.0009 lma 0.6895  cos_theta_tmp 0.7614  Epoch: 4   Global Step: 64900   Required: 34 hours
Training: 2025-12-01 02:56:51,507-Speed 1102.79 samples/sec   Loss 2.5342 target_logit_mean -0.0008 lma 0.6816  cos_theta_tmp 0.7555  Epoch: 4   Global Step: 64950   Required: 34 hours
Training: 2025-12-01 02:57:08,920-Speed 1102.67 samples/sec   Loss 2.5358 target_logit_mean 0.0003 lma 0.6732  cos_theta_tmp 0.7608  Epoch: 4   Global Step: 65000   Required: 34 hours
Training: 2025-12-01 02:57:26,332-Speed 1102.74 samples/sec   Loss 2.5348 target_logit_mean 0.0004 lma 0.6889  cos_theta_tmp 0.7591  Epoch: 4   Global Step: 65050   Required: 34 hours
Training: 2025-12-01 02:57:43,746-Speed 1102.64 samples/sec   Loss 2.5214 target_logit_mean 0.0007 lma 0.6832  cos_theta_tmp 0.7650  Epoch: 4   Global Step: 65100   Required: 34 hours
Training: 2025-12-01 02:58:01,158-Speed 1102.74 samples/sec   Loss 2.5596 target_logit_mean -0.0009 lma 0.6903  cos_theta_tmp 0.7644  Epoch: 4   Global Step: 65150   Required: 34 hours
Training: 2025-12-01 02:58:18,575-Speed 1102.38 samples/sec   Loss 2.5314 target_logit_mean 0.0016 lma 0.6829  cos_theta_tmp 0.7620  Epoch: 4   Global Step: 65200   Required: 34 hours
Training: 2025-12-01 02:58:35,989-Speed 1102.57 samples/sec   Loss 2.5913 target_logit_mean 0.0029 lma 0.6803  cos_theta_tmp 0.7575  Epoch: 4   Global Step: 65250   Required: 34 hours
Training: 2025-12-01 02:58:53,402-Speed 1102.69 samples/sec   Loss 2.5556 target_logit_mean -0.0012 lma 0.6789  cos_theta_tmp 0.7555  Epoch: 4   Global Step: 65300   Required: 34 hours
Training: 2025-12-01 02:59:10,819-Speed 1102.39 samples/sec   Loss 2.5451 target_logit_mean -0.0023 lma 0.6783  cos_theta_tmp 0.7579  Epoch: 4   Global Step: 65350   Required: 34 hours
Training: 2025-12-01 02:59:28,227-Speed 1103.02 samples/sec   Loss 2.5832 target_logit_mean 0.0034 lma 0.6821  cos_theta_tmp 0.7636  Epoch: 4   Global Step: 65400   Required: 34 hours
Training: 2025-12-01 02:59:45,636-Speed 1102.92 samples/sec   Loss 2.5632 target_logit_mean 0.0017 lma 0.6700  cos_theta_tmp 0.7623  Epoch: 4   Global Step: 65450   Required: 34 hours
Training: 2025-12-01 03:00:03,051-Speed 1102.56 samples/sec   Loss 2.6014 target_logit_mean 0.0004 lma 0.6848  cos_theta_tmp 0.7551  Epoch: 4   Global Step: 65500   Required: 34 hours
Training: 2025-12-01 03:00:20,458-Speed 1103.01 samples/sec   Loss 2.5111 target_logit_mean 0.0018 lma 0.6823  cos_theta_tmp 0.7617  Epoch: 4   Global Step: 65550   Required: 34 hours
Training: 2025-12-01 03:00:37,872-Speed 1102.62 samples/sec   Loss 2.4721 target_logit_mean 0.0001 lma 0.6802  cos_theta_tmp 0.7547  Epoch: 4   Global Step: 65600   Required: 34 hours
Training: 2025-12-01 03:00:55,278-Speed 1103.09 samples/sec   Loss 2.4593 target_logit_mean -0.0006 lma 0.6762  cos_theta_tmp 0.7639  Epoch: 4   Global Step: 65650   Required: 34 hours
Training: 2025-12-01 03:01:12,689-Speed 1102.83 samples/sec   Loss 2.5198 target_logit_mean 0.0007 lma 0.6747  cos_theta_tmp 0.7570  Epoch: 4   Global Step: 65700   Required: 34 hours
Training: 2025-12-01 03:01:30,101-Speed 1102.68 samples/sec   Loss 2.5883 target_logit_mean -0.0022 lma 0.6841  cos_theta_tmp 0.7543  Epoch: 4   Global Step: 65750   Required: 34 hours
Training: 2025-12-01 03:01:47,507-Speed 1103.11 samples/sec   Loss 2.5419 target_logit_mean -0.0010 lma 0.6843  cos_theta_tmp 0.7611  Epoch: 4   Global Step: 65800   Required: 34 hours
Training: 2025-12-01 03:02:04,916-Speed 1102.96 samples/sec   Loss 2.4929 target_logit_mean 0.0011 lma 0.6780  cos_theta_tmp 0.7596  Epoch: 4   Global Step: 65850   Required: 34 hours
Training: 2025-12-01 03:02:22,326-Speed 1102.81 samples/sec   Loss 2.5083 target_logit_mean 0.0005 lma 0.6902  cos_theta_tmp 0.7687  Epoch: 4   Global Step: 65900   Required: 34 hours
Training: 2025-12-01 03:02:39,742-Speed 1102.50 samples/sec   Loss 2.5303 target_logit_mean -0.0009 lma 0.6746  cos_theta_tmp 0.7596  Epoch: 4   Global Step: 65950   Required: 34 hours
Training: 2025-12-01 03:02:57,152-Speed 1102.83 samples/sec   Loss 2.5774 target_logit_mean 0.0010 lma 0.6872  cos_theta_tmp 0.7603  Epoch: 4   Global Step: 66000   Required: 34 hours
Training: 2025-12-01 03:03:14,566-Speed 1102.62 samples/sec   Loss 2.5806 target_logit_mean -0.0018 lma 0.6872  cos_theta_tmp 0.7584  Epoch: 4   Global Step: 66050   Required: 34 hours
Training: 2025-12-01 03:03:31,979-Speed 1102.67 samples/sec   Loss 2.6125 target_logit_mean -0.0006 lma 0.6870  cos_theta_tmp 0.7571  Epoch: 4   Global Step: 66100   Required: 34 hours
Training: 2025-12-01 03:03:49,394-Speed 1102.51 samples/sec   Loss 2.5194 target_logit_mean -0.0039 lma 0.6857  cos_theta_tmp 0.7599  Epoch: 4   Global Step: 66150   Required: 34 hours
Training: 2025-12-01 03:04:06,811-Speed 1102.40 samples/sec   Loss 2.4805 target_logit_mean 0.0010 lma 0.6888  cos_theta_tmp 0.7638  Epoch: 4   Global Step: 66200   Required: 34 hours
Training: 2025-12-01 03:04:24,230-Speed 1102.29 samples/sec   Loss 2.4946 target_logit_mean -0.0016 lma 0.6861  cos_theta_tmp 0.7549  Epoch: 4   Global Step: 66250   Required: 34 hours
Training: 2025-12-01 03:04:41,645-Speed 1102.59 samples/sec   Loss 2.5349 target_logit_mean -0.0024 lma 0.6853  cos_theta_tmp 0.7562  Epoch: 4   Global Step: 66300   Required: 34 hours
Training: 2025-12-01 03:04:59,060-Speed 1102.50 samples/sec   Loss 2.5335 target_logit_mean -0.0006 lma 0.6891  cos_theta_tmp 0.7635  Epoch: 4   Global Step: 66350   Required: 34 hours
Training: 2025-12-01 03:05:16,476-Speed 1102.50 samples/sec   Loss 2.5616 target_logit_mean 0.0013 lma 0.6806  cos_theta_tmp 0.7562  Epoch: 4   Global Step: 66400   Required: 34 hours
Training: 2025-12-01 03:05:33,888-Speed 1102.68 samples/sec   Loss 2.5525 target_logit_mean -0.0010 lma 0.6814  cos_theta_tmp 0.7624  Epoch: 4   Global Step: 66450   Required: 34 hours
Training: 2025-12-01 03:05:51,300-Speed 1102.72 samples/sec   Loss 2.5360 target_logit_mean 0.0014 lma 0.6847  cos_theta_tmp 0.7618  Epoch: 4   Global Step: 66500   Required: 34 hours
Training: 2025-12-01 03:06:08,717-Speed 1102.41 samples/sec   Loss 2.4619 target_logit_mean 0.0016 lma 0.6825  cos_theta_tmp 0.7652  Epoch: 4   Global Step: 66550   Required: 34 hours
Training: 2025-12-01 03:06:26,131-Speed 1102.63 samples/sec   Loss 2.5714 target_logit_mean 0.0012 lma 0.6829  cos_theta_tmp 0.7598  Epoch: 4   Global Step: 66600   Required: 34 hours
Training: 2025-12-01 03:06:43,547-Speed 1102.51 samples/sec   Loss 2.5709 target_logit_mean -0.0008 lma 0.6755  cos_theta_tmp 0.7642  Epoch: 4   Global Step: 66650   Required: 34 hours
Training: 2025-12-01 03:07:00,963-Speed 1102.44 samples/sec   Loss 2.5457 target_logit_mean -0.0006 lma 0.6867  cos_theta_tmp 0.7612  Epoch: 4   Global Step: 66700   Required: 34 hours
Training: 2025-12-01 03:07:18,382-Speed 1102.28 samples/sec   Loss 2.5474 target_logit_mean 0.0001 lma 0.6747  cos_theta_tmp 0.7566  Epoch: 4   Global Step: 66750   Required: 34 hours
Training: 2025-12-01 03:07:35,794-Speed 1102.76 samples/sec   Loss 2.5325 target_logit_mean -0.0002 lma 0.6890  cos_theta_tmp 0.7572  Epoch: 4   Global Step: 66800   Required: 34 hours
Training: 2025-12-01 03:07:53,210-Speed 1102.43 samples/sec   Loss 2.5118 target_logit_mean 0.0010 lma 0.6861  cos_theta_tmp 0.7696  Epoch: 4   Global Step: 66850   Required: 34 hours
Training: 2025-12-01 03:08:10,622-Speed 1102.74 samples/sec   Loss 2.5692 target_logit_mean 0.0006 lma 0.6859  cos_theta_tmp 0.7609  Epoch: 4   Global Step: 66900   Required: 34 hours
Training: 2025-12-01 03:08:28,035-Speed 1102.69 samples/sec   Loss 2.5472 target_logit_mean 0.0015 lma 0.6925  cos_theta_tmp 0.7645  Epoch: 4   Global Step: 66950   Required: 34 hours
Training: 2025-12-01 03:08:45,447-Speed 1102.66 samples/sec   Loss 2.5021 target_logit_mean 0.0013 lma 0.6880  cos_theta_tmp 0.7633  Epoch: 4   Global Step: 67000   Required: 34 hours
Training: 2025-12-01 03:09:02,863-Speed 1102.49 samples/sec   Loss 2.5164 target_logit_mean 0.0000 lma 0.6927  cos_theta_tmp 0.7606  Epoch: 4   Global Step: 67050   Required: 34 hours
Training: 2025-12-01 03:09:20,277-Speed 1102.62 samples/sec   Loss 2.5356 target_logit_mean -0.0005 lma 0.6869  cos_theta_tmp 0.7568  Epoch: 4   Global Step: 67100   Required: 34 hours
Training: 2025-12-01 03:09:37,693-Speed 1102.47 samples/sec   Loss 2.5103 target_logit_mean 0.0006 lma 0.6924  cos_theta_tmp 0.7608  Epoch: 4   Global Step: 67150   Required: 34 hours
Training: 2025-12-01 03:09:55,105-Speed 1102.71 samples/sec   Loss 2.4936 target_logit_mean 0.0009 lma 0.6840  cos_theta_tmp 0.7613  Epoch: 4   Global Step: 67200   Required: 34 hours
Training: 2025-12-01 03:10:12,517-Speed 1102.71 samples/sec   Loss 2.5391 target_logit_mean 0.0008 lma 0.6713  cos_theta_tmp 0.7590  Epoch: 4   Global Step: 67250   Required: 34 hours
Training: 2025-12-01 03:10:29,932-Speed 1102.55 samples/sec   Loss 2.5258 target_logit_mean -0.0010 lma 0.6908  cos_theta_tmp 0.7548  Epoch: 4   Global Step: 67300   Required: 34 hours
Training: 2025-12-01 03:10:47,346-Speed 1102.61 samples/sec   Loss 2.5770 target_logit_mean -0.0031 lma 0.6727  cos_theta_tmp 0.7496  Epoch: 4   Global Step: 67350   Required: 34 hours
Training: 2025-12-01 03:11:04,763-Speed 1102.45 samples/sec   Loss 2.5111 target_logit_mean 0.0024 lma 0.6791  cos_theta_tmp 0.7595  Epoch: 4   Global Step: 67400   Required: 33 hours
Training: 2025-12-01 03:11:22,178-Speed 1102.50 samples/sec   Loss 2.5707 target_logit_mean 0.0013 lma 0.6774  cos_theta_tmp 0.7580  Epoch: 4   Global Step: 67450   Required: 33 hours
Training: 2025-12-01 03:11:39,591-Speed 1102.66 samples/sec   Loss 2.5873 target_logit_mean -0.0017 lma 0.6791  cos_theta_tmp 0.7517  Epoch: 4   Global Step: 67500   Required: 33 hours
Training: 2025-12-01 03:11:57,005-Speed 1102.58 samples/sec   Loss 2.5011 target_logit_mean -0.0015 lma 0.6776  cos_theta_tmp 0.7573  Epoch: 4   Global Step: 67550   Required: 33 hours
Training: 2025-12-01 03:12:14,419-Speed 1102.61 samples/sec   Loss 2.5139 target_logit_mean 0.0020 lma 0.6915  cos_theta_tmp 0.7617  Epoch: 4   Global Step: 67600   Required: 33 hours
Training: 2025-12-01 03:12:31,868-Speed 1100.42 samples/sec   Loss 2.5398 target_logit_mean 0.0010 lma 0.6803  cos_theta_tmp 0.7553  Epoch: 4   Global Step: 67650   Required: 33 hours
Training: 2025-12-01 03:12:49,305-Speed 1101.09 samples/sec   Loss 2.5467 target_logit_mean 0.0006 lma 0.6865  cos_theta_tmp 0.7572  Epoch: 4   Global Step: 67700   Required: 33 hours
Training: 2025-12-01 03:13:07,035-Speed 1082.97 samples/sec   Loss 2.5273 target_logit_mean -0.0014 lma 0.6749  cos_theta_tmp 0.7550  Epoch: 4   Global Step: 67750   Required: 33 hours
Training: 2025-12-01 03:13:24,489-Speed 1100.07 samples/sec   Loss 2.5630 target_logit_mean 0.0030 lma 0.6858  cos_theta_tmp 0.7606  Epoch: 4   Global Step: 67800   Required: 33 hours
Training: 2025-12-01 03:13:41,942-Speed 1100.16 samples/sec   Loss 2.5370 target_logit_mean 0.0014 lma 0.6812  cos_theta_tmp 0.7612  Epoch: 4   Global Step: 67850   Required: 33 hours
Training: 2025-12-01 03:13:59,418-Speed 1098.69 samples/sec   Loss 2.6066 target_logit_mean -0.0005 lma 0.6736  cos_theta_tmp 0.7630  Epoch: 4   Global Step: 67900   Required: 33 hours
Training: 2025-12-01 03:14:16,860-Speed 1100.81 samples/sec   Loss 2.5749 target_logit_mean 0.0002 lma 0.6904  cos_theta_tmp 0.7599  Epoch: 4   Global Step: 67950   Required: 33 hours
Training: 2025-12-01 03:14:34,266-Speed 1103.10 samples/sec   Loss 2.5600 target_logit_mean -0.0003 lma 0.6840  cos_theta_tmp 0.7567  Epoch: 4   Global Step: 68000   Required: 33 hours
Training: 2025-12-01 03:14:51,694-Speed 1101.73 samples/sec   Loss 2.4912 target_logit_mean 0.0006 lma 0.6831  cos_theta_tmp 0.7626  Epoch: 4   Global Step: 68050   Required: 33 hours
Training: 2025-12-01 03:15:09,049-Speed 1106.30 samples/sec   Loss 2.4929 target_logit_mean 0.0023 lma 0.6711  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 68100   Required: 33 hours
Training: 2025-12-01 03:15:26,659-Speed 1090.37 samples/sec   Loss 2.4844 target_logit_mean -0.0023 lma 0.6882  cos_theta_tmp 0.7557  Epoch: 4   Global Step: 68150   Required: 33 hours
Training: 2025-12-01 03:15:44,097-Speed 1101.05 samples/sec   Loss 2.4756 target_logit_mean 0.0008 lma 0.6867  cos_theta_tmp 0.7596  Epoch: 4   Global Step: 68200   Required: 33 hours
Training: 2025-12-01 03:16:01,534-Speed 1101.16 samples/sec   Loss 2.4585 target_logit_mean 0.0011 lma 0.6964  cos_theta_tmp 0.7660  Epoch: 4   Global Step: 68250   Required: 33 hours
Training: 2025-12-01 03:16:18,969-Speed 1101.33 samples/sec   Loss 2.5517 target_logit_mean 0.0014 lma 0.6691  cos_theta_tmp 0.7510  Epoch: 4   Global Step: 68300   Required: 33 hours
Training: 2025-12-01 03:16:36,404-Speed 1101.23 samples/sec   Loss 2.5871 target_logit_mean 0.0012 lma 0.6826  cos_theta_tmp 0.7572  Epoch: 4   Global Step: 68350   Required: 33 hours
Training: 2025-12-01 03:16:53,866-Speed 1099.57 samples/sec   Loss 2.5359 target_logit_mean -0.0024 lma 0.6829  cos_theta_tmp 0.7574  Epoch: 4   Global Step: 68400   Required: 33 hours
Training: 2025-12-01 03:17:11,314-Speed 1100.52 samples/sec   Loss 2.4905 target_logit_mean -0.0023 lma 0.6773  cos_theta_tmp 0.7581  Epoch: 4   Global Step: 68450   Required: 33 hours
Training: 2025-12-01 03:17:28,716-Speed 1103.33 samples/sec   Loss 2.4647 target_logit_mean -0.0015 lma 0.6716  cos_theta_tmp 0.7563  Epoch: 4   Global Step: 68500   Required: 33 hours
Training: 2025-12-01 03:17:46,221-Speed 1096.89 samples/sec   Loss 2.4998 target_logit_mean 0.0032 lma 0.6724  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 68550   Required: 33 hours
Training: 2025-12-01 03:18:03,672-Speed 1100.26 samples/sec   Loss 2.4825 target_logit_mean -0.0016 lma 0.6813  cos_theta_tmp 0.7585  Epoch: 4   Global Step: 68600   Required: 33 hours
Training: 2025-12-01 03:18:21,110-Speed 1101.07 samples/sec   Loss 2.5526 target_logit_mean -0.0010 lma 0.6765  cos_theta_tmp 0.7619  Epoch: 4   Global Step: 68650   Required: 33 hours
Training: 2025-12-01 03:18:38,548-Speed 1101.08 samples/sec   Loss 2.5222 target_logit_mean -0.0004 lma 0.6768  cos_theta_tmp 0.7563  Epoch: 4   Global Step: 68700   Required: 33 hours
Training: 2025-12-01 03:18:56,043-Speed 1097.50 samples/sec   Loss 2.5127 target_logit_mean 0.0018 lma 0.6895  cos_theta_tmp 0.7649  Epoch: 4   Global Step: 68750   Required: 33 hours
Training: 2025-12-01 03:19:13,454-Speed 1102.79 samples/sec   Loss 2.4733 target_logit_mean 0.0020 lma 0.6865  cos_theta_tmp 0.7570  Epoch: 4   Global Step: 68800   Required: 33 hours
Training: 2025-12-01 03:19:30,871-Speed 1102.44 samples/sec   Loss 2.4976 target_logit_mean 0.0010 lma 0.6937  cos_theta_tmp 0.7651  Epoch: 4   Global Step: 68850   Required: 33 hours
Training: 2025-12-01 03:19:48,289-Speed 1102.31 samples/sec   Loss 2.5686 target_logit_mean 0.0007 lma 0.6804  cos_theta_tmp 0.7616  Epoch: 4   Global Step: 68900   Required: 33 hours
Training: 2025-12-01 03:20:05,706-Speed 1102.39 samples/sec   Loss 2.4854 target_logit_mean 0.0015 lma 0.6882  cos_theta_tmp 0.7618  Epoch: 4   Global Step: 68950   Required: 33 hours
Training: 2025-12-01 03:20:23,123-Speed 1102.45 samples/sec   Loss 2.5756 target_logit_mean 0.0015 lma 0.6918  cos_theta_tmp 0.7654  Epoch: 4   Global Step: 69000   Required: 33 hours
Training: 2025-12-01 03:20:40,541-Speed 1102.37 samples/sec   Loss 2.5761 target_logit_mean -0.0020 lma 0.6817  cos_theta_tmp 0.7575  Epoch: 4   Global Step: 69050   Required: 33 hours
Training: 2025-12-01 03:20:57,958-Speed 1102.36 samples/sec   Loss 2.5402 target_logit_mean 0.0001 lma 0.6871  cos_theta_tmp 0.7598  Epoch: 4   Global Step: 69100   Required: 33 hours
Training: 2025-12-01 03:21:15,372-Speed 1102.60 samples/sec   Loss 2.5206 target_logit_mean 0.0003 lma 0.6801  cos_theta_tmp 0.7546  Epoch: 4   Global Step: 69150   Required: 33 hours
Training: 2025-12-01 03:21:32,788-Speed 1102.48 samples/sec   Loss 2.5517 target_logit_mean 0.0000 lma 0.6786  cos_theta_tmp 0.7642  Epoch: 4   Global Step: 69200   Required: 33 hours
Training: 2025-12-01 03:21:50,203-Speed 1102.54 samples/sec   Loss 2.5277 target_logit_mean 0.0020 lma 0.6815  cos_theta_tmp 0.7538  Epoch: 4   Global Step: 69250   Required: 33 hours
Training: 2025-12-01 03:22:07,621-Speed 1102.35 samples/sec   Loss 2.5447 target_logit_mean -0.0004 lma 0.6803  cos_theta_tmp 0.7625  Epoch: 4   Global Step: 69300   Required: 33 hours
Training: 2025-12-01 03:22:25,035-Speed 1102.59 samples/sec   Loss 2.4900 target_logit_mean 0.0015 lma 0.6891  cos_theta_tmp 0.7635  Epoch: 4   Global Step: 69350   Required: 33 hours
Training: 2025-12-01 03:22:42,447-Speed 1102.71 samples/sec   Loss 2.5105 target_logit_mean -0.0035 lma 0.6763  cos_theta_tmp 0.7561  Epoch: 4   Global Step: 69400   Required: 33 hours
Training: 2025-12-01 03:22:59,864-Speed 1102.42 samples/sec   Loss 2.5638 target_logit_mean 0.0000 lma 0.6724  cos_theta_tmp 0.7615  Epoch: 4   Global Step: 69450   Required: 33 hours
Training: 2025-12-01 03:23:17,280-Speed 1102.45 samples/sec   Loss 2.5055 target_logit_mean 0.0010 lma 0.6862  cos_theta_tmp 0.7673  Epoch: 4   Global Step: 69500   Required: 33 hours
Training: 2025-12-01 03:23:34,696-Speed 1102.54 samples/sec   Loss 2.4448 target_logit_mean -0.0010 lma 0.6793  cos_theta_tmp 0.7547  Epoch: 4   Global Step: 69550   Required: 33 hours
Training: 2025-12-01 03:23:52,111-Speed 1102.55 samples/sec   Loss 2.4937 target_logit_mean 0.0001 lma 0.6926  cos_theta_tmp 0.7553  Epoch: 4   Global Step: 69600   Required: 33 hours
Training: 2025-12-01 03:24:09,530-Speed 1102.29 samples/sec   Loss 2.5288 target_logit_mean 0.0027 lma 0.6832  cos_theta_tmp 0.7584  Epoch: 4   Global Step: 69650   Required: 33 hours
Training: 2025-12-01 03:24:26,944-Speed 1102.64 samples/sec   Loss 2.5667 target_logit_mean 0.0012 lma 0.6896  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 69700   Required: 33 hours
Training: 2025-12-01 03:24:44,374-Speed 1102.47 samples/sec   Loss 2.5050 target_logit_mean -0.0003 lma 0.6893  cos_theta_tmp 0.7635  Epoch: 4   Global Step: 69750   Required: 33 hours
Training: 2025-12-01 03:25:01,790-Speed 1102.46 samples/sec   Loss 2.5458 target_logit_mean -0.0001 lma 0.6765  cos_theta_tmp 0.7539  Epoch: 4   Global Step: 69800   Required: 33 hours
Training: 2025-12-01 03:25:19,204-Speed 1102.65 samples/sec   Loss 2.5185 target_logit_mean -0.0006 lma 0.6859  cos_theta_tmp 0.7604  Epoch: 4   Global Step: 69850   Required: 33 hours
Training: 2025-12-01 03:25:36,618-Speed 1102.57 samples/sec   Loss 2.5366 target_logit_mean -0.0021 lma 0.6745  cos_theta_tmp 0.7515  Epoch: 4   Global Step: 69900   Required: 33 hours
Training: 2025-12-01 03:25:54,031-Speed 1102.63 samples/sec   Loss 2.5753 target_logit_mean 0.0037 lma 0.6907  cos_theta_tmp 0.7602  Epoch: 4   Global Step: 69950   Required: 33 hours
Training: 2025-12-01 03:26:11,449-Speed 1102.36 samples/sec   Loss 2.5379 target_logit_mean 0.0010 lma 0.6812  cos_theta_tmp 0.7619  Epoch: 4   Global Step: 70000   Required: 33 hours
Training: 2025-12-01 03:26:28,868-Speed 1102.26 samples/sec   Loss 2.5507 target_logit_mean 0.0012 lma 0.6755  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 70050   Required: 33 hours
Training: 2025-12-01 03:26:46,284-Speed 1102.51 samples/sec   Loss 2.4795 target_logit_mean -0.0013 lma 0.6947  cos_theta_tmp 0.7625  Epoch: 4   Global Step: 70100   Required: 33 hours
Training: 2025-12-01 03:27:03,699-Speed 1102.53 samples/sec   Loss 2.5120 target_logit_mean -0.0020 lma 0.6777  cos_theta_tmp 0.7549  Epoch: 4   Global Step: 70150   Required: 33 hours
Training: 2025-12-01 03:27:21,118-Speed 1102.29 samples/sec   Loss 2.5102 target_logit_mean -0.0012 lma 0.6849  cos_theta_tmp 0.7625  Epoch: 4   Global Step: 70200   Required: 33 hours
Training: 2025-12-01 03:27:38,531-Speed 1102.63 samples/sec   Loss 2.5434 target_logit_mean 0.0009 lma 0.6905  cos_theta_tmp 0.7541  Epoch: 4   Global Step: 70250   Required: 33 hours
Training: 2025-12-01 03:27:55,948-Speed 1102.41 samples/sec   Loss 2.4729 target_logit_mean 0.0012 lma 0.6813  cos_theta_tmp 0.7592  Epoch: 4   Global Step: 70300   Required: 33 hours
Training: 2025-12-01 03:28:13,361-Speed 1102.66 samples/sec   Loss 2.5673 target_logit_mean 0.0017 lma 0.6767  cos_theta_tmp 0.7600  Epoch: 4   Global Step: 70350   Required: 33 hours
Training: 2025-12-01 03:28:30,776-Speed 1102.52 samples/sec   Loss 2.5338 target_logit_mean -0.0013 lma 0.6795  cos_theta_tmp 0.7595  Epoch: 4   Global Step: 70400   Required: 33 hours
Training: 2025-12-01 03:28:48,189-Speed 1102.65 samples/sec   Loss 2.4714 target_logit_mean 0.0015 lma 0.6795  cos_theta_tmp 0.7601  Epoch: 4   Global Step: 70450   Required: 33 hours
Training: 2025-12-01 03:29:05,604-Speed 1102.53 samples/sec   Loss 2.4928 target_logit_mean -0.0009 lma 0.6877  cos_theta_tmp 0.7612  Epoch: 4   Global Step: 70500   Required: 33 hours
Training: 2025-12-01 03:29:23,019-Speed 1102.58 samples/sec   Loss 2.4999 target_logit_mean 0.0010 lma 0.6893  cos_theta_tmp 0.7619  Epoch: 4   Global Step: 70550   Required: 33 hours
Training: 2025-12-01 03:29:40,434-Speed 1102.55 samples/sec   Loss 2.4888 target_logit_mean -0.0009 lma 0.6776  cos_theta_tmp 0.7611  Epoch: 4   Global Step: 70600   Required: 33 hours
Training: 2025-12-01 03:29:57,850-Speed 1102.45 samples/sec   Loss 2.4966 target_logit_mean 0.0029 lma 0.6798  cos_theta_tmp 0.7613  Epoch: 4   Global Step: 70650   Required: 33 hours
Training: 2025-12-01 03:30:15,263-Speed 1102.62 samples/sec   Loss 2.4696 target_logit_mean 0.0027 lma 0.6909  cos_theta_tmp 0.7650  Epoch: 4   Global Step: 70700   Required: 33 hours
Training: 2025-12-01 03:30:32,678-Speed 1102.58 samples/sec   Loss 2.4507 target_logit_mean 0.0021 lma 0.6851  cos_theta_tmp 0.7610  Epoch: 4   Global Step: 70750   Required: 33 hours
Training: 2025-12-01 03:30:50,097-Speed 1102.28 samples/sec   Loss 2.4958 target_logit_mean -0.0017 lma 0.6838  cos_theta_tmp 0.7632  Epoch: 4   Global Step: 70800   Required: 33 hours
Training: 2025-12-01 03:31:07,516-Speed 1102.27 samples/sec   Loss 2.5676 target_logit_mean 0.0004 lma 0.6728  cos_theta_tmp 0.7586  Epoch: 4   Global Step: 70850   Required: 33 hours
Training: 2025-12-01 03:31:24,931-Speed 1102.53 samples/sec   Loss 2.5231 target_logit_mean -0.0014 lma 0.6781  cos_theta_tmp 0.7546  Epoch: 4   Global Step: 70900   Required: 33 hours
Training: 2025-12-01 03:31:42,344-Speed 1102.68 samples/sec   Loss 2.5526 target_logit_mean 0.0003 lma 0.6869  cos_theta_tmp 0.7551  Epoch: 4   Global Step: 70950   Required: 33 hours
Training: 2025-12-01 03:31:59,760-Speed 1102.49 samples/sec   Loss 2.5549 target_logit_mean 0.0022 lma 0.6813  cos_theta_tmp 0.7520  Epoch: 4   Global Step: 71000   Required: 33 hours
Training: 2025-12-01 03:32:17,180-Speed 1102.18 samples/sec   Loss 2.5299 target_logit_mean -0.0002 lma 0.6833  cos_theta_tmp 0.7590  Epoch: 4   Global Step: 71050   Required: 33 hours
Training: 2025-12-01 03:32:34,600-Speed 1102.21 samples/sec   Loss 2.5619 target_logit_mean 0.0013 lma 0.6798  cos_theta_tmp 0.7595  Epoch: 4   Global Step: 71100   Required: 33 hours
Training: 2025-12-01 03:32:52,020-Speed 1102.24 samples/sec   Loss 2.5281 target_logit_mean -0.0017 lma 0.6808  cos_theta_tmp 0.7626  Epoch: 4   Global Step: 71150   Required: 33 hours
Training: 2025-12-01 03:33:09,439-Speed 1102.27 samples/sec   Loss 2.5207 target_logit_mean 0.0003 lma 0.6759  cos_theta_tmp 0.7541  Epoch: 4   Global Step: 71200   Required: 33 hours
Training: 2025-12-01 03:33:26,858-Speed 1102.29 samples/sec   Loss 2.5260 target_logit_mean 0.0009 lma 0.6830  cos_theta_tmp 0.7637  Epoch: 4   Global Step: 71250   Required: 33 hours
Training: 2025-12-01 03:33:44,272-Speed 1102.61 samples/sec   Loss 2.5233 target_logit_mean -0.0005 lma 0.6690  cos_theta_tmp 0.7525  Epoch: 4   Global Step: 71300   Required: 33 hours
Training: 2025-12-01 03:34:01,686-Speed 1102.57 samples/sec   Loss 2.4619 target_logit_mean -0.0004 lma 0.6966  cos_theta_tmp 0.7607  Epoch: 4   Global Step: 71350   Required: 33 hours
Training: 2025-12-01 03:34:19,098-Speed 1102.77 samples/sec   Loss 2.4980 target_logit_mean -0.0001 lma 0.6735  cos_theta_tmp 0.7629  Epoch: 4   Global Step: 71400   Required: 33 hours
Training: 2025-12-01 03:34:36,517-Speed 1102.29 samples/sec   Loss 2.4403 target_logit_mean -0.0019 lma 0.6816  cos_theta_tmp 0.7606  Epoch: 4   Global Step: 71450   Required: 33 hours
Training: 2025-12-01 03:34:53,926-Speed 1102.85 samples/sec   Loss 2.5750 target_logit_mean -0.0003 lma 0.6818  cos_theta_tmp 0.7572  Epoch: 4   Global Step: 71500   Required: 33 hours
Training: 2025-12-01 03:35:11,336-Speed 1102.85 samples/sec   Loss 2.5750 target_logit_mean -0.0002 lma 0.6816  cos_theta_tmp 0.7580  Epoch: 4   Global Step: 71550   Required: 33 hours
Training: 2025-12-01 03:35:28,750-Speed 1102.62 samples/sec   Loss 2.5630 target_logit_mean 0.0011 lma 0.6875  cos_theta_tmp 0.7635  Epoch: 4   Global Step: 71600   Required: 33 hours
Training: 2025-12-01 03:35:46,165-Speed 1102.55 samples/sec   Loss 2.4982 target_logit_mean 0.0011 lma 0.6804  cos_theta_tmp 0.7649  Epoch: 4   Global Step: 71650   Required: 33 hours
Training: 2025-12-01 03:36:03,579-Speed 1102.57 samples/sec   Loss 2.4883 target_logit_mean -0.0004 lma 0.6791  cos_theta_tmp 0.7590  Epoch: 4   Global Step: 71700   Required: 33 hours
Training: 2025-12-01 03:36:20,992-Speed 1102.65 samples/sec   Loss 2.5567 target_logit_mean 0.0030 lma 0.6861  cos_theta_tmp 0.7640  Epoch: 4   Global Step: 71750   Required: 33 hours
Training: 2025-12-01 03:36:38,409-Speed 1102.42 samples/sec   Loss 2.5438 target_logit_mean -0.0002 lma 0.6819  cos_theta_tmp 0.7586  Epoch: 4   Global Step: 71800   Required: 33 hours
Training: 2025-12-01 03:36:55,826-Speed 1102.40 samples/sec   Loss 2.5275 target_logit_mean -0.0020 lma 0.6993  cos_theta_tmp 0.7541  Epoch: 4   Global Step: 71850   Required: 33 hours
Training: 2025-12-01 03:37:13,243-Speed 1102.41 samples/sec   Loss 2.4966 target_logit_mean 0.0016 lma 0.6787  cos_theta_tmp 0.7621  Epoch: 4   Global Step: 71900   Required: 33 hours
Training: 2025-12-01 03:37:30,664-Speed 1102.17 samples/sec   Loss 2.5242 target_logit_mean -0.0022 lma 0.6840  cos_theta_tmp 0.7617  Epoch: 4   Global Step: 71950   Required: 33 hours
Training: 2025-12-01 03:37:48,083-Speed 1102.26 samples/sec   Loss 2.5552 target_logit_mean 0.0025 lma 0.6731  cos_theta_tmp 0.7578  Epoch: 4   Global Step: 72000   Required: 33 hours
Training: 2025-12-01 03:38:05,501-Speed 1102.36 samples/sec   Loss 2.4531 target_logit_mean 0.0011 lma 0.6935  cos_theta_tmp 0.7688  Epoch: 4   Global Step: 72050   Required: 33 hours
Training: 2025-12-01 03:38:22,915-Speed 1102.66 samples/sec   Loss 2.5226 target_logit_mean 0.0004 lma 0.6843  cos_theta_tmp 0.7516  Epoch: 4   Global Step: 72100   Required: 33 hours
Training: 2025-12-01 03:38:40,328-Speed 1102.65 samples/sec   Loss 2.5074 target_logit_mean -0.0008 lma 0.6805  cos_theta_tmp 0.7616  Epoch: 4   Global Step: 72150   Required: 33 hours
Training: 2025-12-01 03:38:57,747-Speed 1102.29 samples/sec   Loss 2.5493 target_logit_mean -0.0010 lma 0.6828  cos_theta_tmp 0.7615  Epoch: 4   Global Step: 72200   Required: 33 hours
Training: 2025-12-01 03:39:15,163-Speed 1102.47 samples/sec   Loss 2.5261 target_logit_mean 0.0007 lma 0.6890  cos_theta_tmp 0.7579  Epoch: 4   Global Step: 72250   Required: 33 hours
Training: 2025-12-01 03:39:32,581-Speed 1102.37 samples/sec   Loss 2.5302 target_logit_mean 0.0016 lma 0.6730  cos_theta_tmp 0.7612  Epoch: 4   Global Step: 72300   Required: 33 hours
Training: 2025-12-01 03:39:49,999-Speed 1102.30 samples/sec   Loss 2.5526 target_logit_mean 0.0015 lma 0.6785  cos_theta_tmp 0.7617  Epoch: 4   Global Step: 72350   Required: 33 hours
Training: 2025-12-01 03:40:07,418-Speed 1102.33 samples/sec   Loss 2.5300 target_logit_mean 0.0005 lma 0.6838  cos_theta_tmp 0.7611  Epoch: 4   Global Step: 72400   Required: 33 hours
Training: 2025-12-01 03:40:24,835-Speed 1102.39 samples/sec   Loss 2.5153 target_logit_mean 0.0008 lma 0.6897  cos_theta_tmp 0.7599  Epoch: 4   Global Step: 72450   Required: 33 hours
Training: 2025-12-01 03:40:42,252-Speed 1102.42 samples/sec   Loss 2.5078 target_logit_mean -0.0002 lma 0.6821  cos_theta_tmp 0.7601  Epoch: 4   Global Step: 72500   Required: 33 hours
Training: 2025-12-01 03:40:59,668-Speed 1102.43 samples/sec   Loss 2.4946 target_logit_mean 0.0002 lma 0.6763  cos_theta_tmp 0.7526  Epoch: 4   Global Step: 72550   Required: 33 hours
Training: 2025-12-01 03:41:17,087-Speed 1102.32 samples/sec   Loss 2.5246 target_logit_mean -0.0007 lma 0.6753  cos_theta_tmp 0.7552  Epoch: 4   Global Step: 72600   Required: 33 hours
Training: 2025-12-01 03:41:34,496-Speed 1102.89 samples/sec   Loss 2.4312 target_logit_mean 0.0011 lma 0.6949  cos_theta_tmp 0.7572  Epoch: 4   Global Step: 72650   Required: 33 hours
Training: 2025-12-01 03:41:51,912-Speed 1102.52 samples/sec   Loss 2.5059 target_logit_mean -0.0024 lma 0.6759  cos_theta_tmp 0.7612  Epoch: 4   Global Step: 72700   Required: 33 hours
Training: 2025-12-01 03:42:09,327-Speed 1102.50 samples/sec   Loss 2.5010 target_logit_mean -0.0022 lma 0.6775  cos_theta_tmp 0.7602  Epoch: 4   Global Step: 72750   Required: 33 hours
Training: 2025-12-01 03:42:26,742-Speed 1102.57 samples/sec   Loss 2.5242 target_logit_mean -0.0004 lma 0.6804  cos_theta_tmp 0.7583  Epoch: 4   Global Step: 72800   Required: 33 hours
Training: 2025-12-01 03:42:44,161-Speed 1102.27 samples/sec   Loss 2.5547 target_logit_mean 0.0012 lma 0.6812  cos_theta_tmp 0.7584  Epoch: 4   Global Step: 72850   Required: 33 hours
Training: 2025-12-01 03:43:01,577-Speed 1102.44 samples/sec   Loss 2.5480 target_logit_mean 0.0019 lma 0.6917  cos_theta_tmp 0.7585  Epoch: 4   Global Step: 72900   Required: 33 hours
Training: 2025-12-01 03:43:18,993-Speed 1102.47 samples/sec   Loss 2.4893 target_logit_mean -0.0032 lma 0.6711  cos_theta_tmp 0.7585  Epoch: 4   Global Step: 72950   Required: 33 hours
Training: 2025-12-01 03:43:36,410-Speed 1102.45 samples/sec   Loss 2.4535 target_logit_mean 0.0013 lma 0.6846  cos_theta_tmp 0.7666  Epoch: 4   Global Step: 73000   Required: 33 hours
Training: 2025-12-01 03:43:53,824-Speed 1102.59 samples/sec   Loss 2.5215 target_logit_mean 0.0013 lma 0.6859  cos_theta_tmp 0.7585  Epoch: 4   Global Step: 73050   Required: 33 hours
Training: 2025-12-01 03:44:11,242-Speed 1102.34 samples/sec   Loss 2.4820 target_logit_mean 0.0010 lma 0.6874  cos_theta_tmp 0.7670  Epoch: 4   Global Step: 73100   Required: 33 hours
Training: 2025-12-01 03:44:28,657-Speed 1102.50 samples/sec   Loss 2.5564 target_logit_mean -0.0018 lma 0.6778  cos_theta_tmp 0.7575  Epoch: 4   Global Step: 73150   Required: 33 hours
Training: 2025-12-01 03:44:46,153-Speed 1097.45 samples/sec   Loss 2.5575 target_logit_mean 0.0014 lma 0.6745  cos_theta_tmp 0.7588  Epoch: 4   Global Step: 73200   Required: 33 hours
Training: 2025-12-01 03:45:03,724-Speed 1092.73 samples/sec   Loss 2.4949 target_logit_mean 0.0013 lma 0.6812  cos_theta_tmp 0.7647  Epoch: 4   Global Step: 73250   Required: 33 hours
Training: 2025-12-01 03:45:21,205-Speed 1098.42 samples/sec   Loss 2.4770 target_logit_mean 0.0013 lma 0.6836  cos_theta_tmp 0.7622  Epoch: 4   Global Step: 73300   Required: 33 hours
Training: 2025-12-01 03:45:38,622-Speed 1102.40 samples/sec   Loss 2.4716 target_logit_mean -0.0004 lma 0.6827  cos_theta_tmp 0.7617  Epoch: 4   Global Step: 73350   Required: 33 hours
Training: 2025-12-01 03:45:56,032-Speed 1102.87 samples/sec   Loss 2.5246 target_logit_mean -0.0006 lma 0.6741  cos_theta_tmp 0.7580  Epoch: 4   Global Step: 73400   Required: 33 hours
Training: 2025-12-01 03:46:13,446-Speed 1102.55 samples/sec   Loss 2.4570 target_logit_mean 0.0004 lma 0.6834  cos_theta_tmp 0.7625  Epoch: 4   Global Step: 73450   Required: 33 hours
Training: 2025-12-01 03:46:30,860-Speed 1102.63 samples/sec   Loss 2.5416 target_logit_mean -0.0012 lma 0.6849  cos_theta_tmp 0.7575  Epoch: 4   Global Step: 73500   Required: 33 hours
Training: 2025-12-01 03:46:48,279-Speed 1102.31 samples/sec   Loss 2.5332 target_logit_mean -0.0003 lma 0.6847  cos_theta_tmp 0.7610  Epoch: 4   Global Step: 73550   Required: 33 hours
Training: 2025-12-01 03:47:05,694-Speed 1102.47 samples/sec   Loss 2.5265 target_logit_mean -0.0005 lma 0.6750  cos_theta_tmp 0.7574  Epoch: 4   Global Step: 73600   Required: 33 hours
Training: 2025-12-01 03:47:23,112-Speed 1102.35 samples/sec   Loss 2.5024 target_logit_mean 0.0011 lma 0.6777  cos_theta_tmp 0.7570  Epoch: 4   Global Step: 73650   Required: 33 hours
Training: 2025-12-01 03:47:40,528-Speed 1102.46 samples/sec   Loss 2.5374 target_logit_mean -0.0016 lma 0.6695  cos_theta_tmp 0.7572  Epoch: 4   Global Step: 73700   Required: 33 hours
Training: 2025-12-01 03:47:57,946-Speed 1102.40 samples/sec   Loss 2.4981 target_logit_mean -0.0001 lma 0.6706  cos_theta_tmp 0.7602  Epoch: 4   Global Step: 73750   Required: 33 hours
Training: 2025-12-01 03:48:15,361-Speed 1102.50 samples/sec   Loss 2.4408 target_logit_mean -0.0024 lma 0.6772  cos_theta_tmp 0.7578  Epoch: 4   Global Step: 73800   Required: 33 hours
Training: 2025-12-01 03:48:32,775-Speed 1102.65 samples/sec   Loss 2.5641 target_logit_mean 0.0002 lma 0.6806  cos_theta_tmp 0.7571  Epoch: 4   Global Step: 73850   Required: 33 hours
Training: 2025-12-01 03:48:50,196-Speed 1102.12 samples/sec   Loss 2.5283 target_logit_mean 0.0000 lma 0.6840  cos_theta_tmp 0.7622  Epoch: 4   Global Step: 73900   Required: 33 hours
Training: 2025-12-01 03:49:07,615-Speed 1102.31 samples/sec   Loss 2.5376 target_logit_mean -0.0002 lma 0.6980  cos_theta_tmp 0.7626  Epoch: 4   Global Step: 73950   Required: 33 hours
Training: 2025-12-01 03:49:25,030-Speed 1102.50 samples/sec   Loss 2.5234 target_logit_mean 0.0024 lma 0.6949  cos_theta_tmp 0.7602  Epoch: 4   Global Step: 74000   Required: 33 hours
Training: 2025-12-01 03:49:42,450-Speed 1102.24 samples/sec   Loss 2.4790 target_logit_mean 0.0007 lma 0.6798  cos_theta_tmp 0.7553  Epoch: 4   Global Step: 74050   Required: 33 hours
Training: 2025-12-01 03:49:59,871-Speed 1102.19 samples/sec   Loss 2.4896 target_logit_mean -0.0021 lma 0.6906  cos_theta_tmp 0.7589  Epoch: 4   Global Step: 74100   Required: 33 hours
Training: 2025-12-01 03:50:17,293-Speed 1102.12 samples/sec   Loss 2.5071 target_logit_mean 0.0025 lma 0.6918  cos_theta_tmp 0.7651  Epoch: 4   Global Step: 74150   Required: 33 hours
Training: 2025-12-01 03:50:34,712-Speed 1102.23 samples/sec   Loss 2.4614 target_logit_mean 0.0002 lma 0.6867  cos_theta_tmp 0.7558  Epoch: 4   Global Step: 74200   Required: 33 hours
Training: 2025-12-01 03:50:52,132-Speed 1102.22 samples/sec   Loss 2.5138 target_logit_mean -0.0010 lma 0.6759  cos_theta_tmp 0.7594  Epoch: 4   Global Step: 74250   Required: 33 hours
Training: 2025-12-01 03:51:09,554-Speed 1102.08 samples/sec   Loss 2.5148 target_logit_mean 0.0001 lma 0.6697  cos_theta_tmp 0.7600  Epoch: 4   Global Step: 74300   Required: 33 hours
Training: 2025-12-01 03:51:26,970-Speed 1102.48 samples/sec   Loss 2.4812 target_logit_mean -0.0018 lma 0.6702  cos_theta_tmp 0.7572  Epoch: 4   Global Step: 74350   Required: 33 hours
Training: 2025-12-01 03:51:44,387-Speed 1102.42 samples/sec   Loss 2.4572 target_logit_mean -0.0016 lma 0.6887  cos_theta_tmp 0.7574  Epoch: 4   Global Step: 74400   Required: 33 hours
Training: 2025-12-01 03:52:01,804-Speed 1102.42 samples/sec   Loss 2.4965 target_logit_mean 0.0016 lma 0.6747  cos_theta_tmp 0.7644  Epoch: 4   Global Step: 74450   Required: 33 hours
Training: 2025-12-01 03:52:19,217-Speed 1102.70 samples/sec   Loss 2.4841 target_logit_mean 0.0008 lma 0.6795  cos_theta_tmp 0.7669  Epoch: 4   Global Step: 74500   Required: 33 hours
Training: 2025-12-01 03:52:36,628-Speed 1102.81 samples/sec   Loss 2.4619 target_logit_mean -0.0005 lma 0.6703  cos_theta_tmp 0.7581  Epoch: 4   Global Step: 74550   Required: 33 hours
Training: 2025-12-01 03:52:54,050-Speed 1102.09 samples/sec   Loss 2.4886 target_logit_mean 0.0009 lma 0.6749  cos_theta_tmp 0.7610  Epoch: 4   Global Step: 74600   Required: 33 hours
Training: 2025-12-01 03:53:11,467-Speed 1102.36 samples/sec   Loss 2.4682 target_logit_mean 0.0005 lma 0.6789  cos_theta_tmp 0.7576  Epoch: 4   Global Step: 74650   Required: 33 hours
Training: 2025-12-01 03:53:28,884-Speed 1102.41 samples/sec   Loss 2.5072 target_logit_mean -0.0007 lma 0.6813  cos_theta_tmp 0.7601  Epoch: 4   Global Step: 74700   Required: 33 hours
Training: 2025-12-01 03:53:46,304-Speed 1102.25 samples/sec   Loss 2.4992 target_logit_mean -0.0006 lma 0.6819  cos_theta_tmp 0.7634  Epoch: 4   Global Step: 74750   Required: 33 hours
Training: 2025-12-01 03:54:03,720-Speed 1102.51 samples/sec   Loss 2.4999 target_logit_mean 0.0002 lma 0.6763  cos_theta_tmp 0.7578  Epoch: 4   Global Step: 74800   Required: 33 hours
Training: 2025-12-01 03:54:21,134-Speed 1102.59 samples/sec   Loss 2.4871 target_logit_mean 0.0000 lma 0.6811  cos_theta_tmp 0.7588  Epoch: 4   Global Step: 74850   Required: 33 hours
Training: 2025-12-01 03:54:38,547-Speed 1102.68 samples/sec   Loss 2.4788 target_logit_mean 0.0024 lma 0.6775  cos_theta_tmp 0.7586  Epoch: 4   Global Step: 74900   Required: 33 hours
Training: 2025-12-01 03:54:55,994-Speed 1100.46 samples/sec   Loss 2.5340 target_logit_mean 0.0001 lma 0.6818  cos_theta_tmp 0.7610  Epoch: 4   Global Step: 74950   Required: 33 hours
Training: 2025-12-01 03:55:13,410-Speed 1102.50 samples/sec   Loss 2.5018 target_logit_mean 0.0008 lma 0.6920  cos_theta_tmp 0.7680  Epoch: 4   Global Step: 75000   Required: 33 hours
Training: 2025-12-01 03:55:30,826-Speed 1102.49 samples/sec   Loss 2.5840 target_logit_mean -0.0001 lma 0.6871  cos_theta_tmp 0.7575  Epoch: 4   Global Step: 75050   Required: 33 hours
Training: 2025-12-01 03:55:48,241-Speed 1102.52 samples/sec   Loss 2.4683 target_logit_mean 0.0002 lma 0.6887  cos_theta_tmp 0.7636  Epoch: 4   Global Step: 75100   Required: 33 hours
Training: 2025-12-01 03:56:05,654-Speed 1102.63 samples/sec   Loss 2.4615 target_logit_mean 0.0003 lma 0.6752  cos_theta_tmp 0.7635  Epoch: 4   Global Step: 75150   Required: 33 hours
Training: 2025-12-01 03:56:23,070-Speed 1102.46 samples/sec   Loss 2.4872 target_logit_mean -0.0003 lma 0.6850  cos_theta_tmp 0.7601  Epoch: 4   Global Step: 75200   Required: 33 hours
Training: 2025-12-01 03:56:40,485-Speed 1102.54 samples/sec   Loss 2.4910 target_logit_mean -0.0008 lma 0.7001  cos_theta_tmp 0.7662  Epoch: 4   Global Step: 75250   Required: 33 hours
Training: 2025-12-01 03:56:57,897-Speed 1102.77 samples/sec   Loss 2.5365 target_logit_mean 0.0014 lma 0.6744  cos_theta_tmp 0.7541  Epoch: 4   Global Step: 75300   Required: 32 hours
Training: 2025-12-01 03:57:15,309-Speed 1102.68 samples/sec   Loss 2.5165 target_logit_mean 0.0020 lma 0.6808  cos_theta_tmp 0.7608  Epoch: 4   Global Step: 75350   Required: 32 hours
Training: 2025-12-01 03:57:32,722-Speed 1102.65 samples/sec   Loss 2.4334 target_logit_mean -0.0002 lma 0.6863  cos_theta_tmp 0.7556  Epoch: 4   Global Step: 75400   Required: 32 hours
Training: 2025-12-01 03:57:50,138-Speed 1102.49 samples/sec   Loss 2.4985 target_logit_mean 0.0015 lma 0.6994  cos_theta_tmp 0.7637  Epoch: 4   Global Step: 75450   Required: 32 hours
Training: 2025-12-01 03:58:07,550-Speed 1102.74 samples/sec   Loss 2.5422 target_logit_mean 0.0011 lma 0.6846  cos_theta_tmp 0.7596  Epoch: 4   Global Step: 75500   Required: 32 hours
Training: 2025-12-01 03:58:24,965-Speed 1102.52 samples/sec   Loss 2.5311 target_logit_mean 0.0011 lma 0.6804  cos_theta_tmp 0.7632  Epoch: 4   Global Step: 75550   Required: 32 hours
Training: 2025-12-01 03:58:42,375-Speed 1102.84 samples/sec   Loss 2.5205 target_logit_mean -0.0005 lma 0.6812  cos_theta_tmp 0.7601  Epoch: 4   Global Step: 75600   Required: 32 hours
Training: 2025-12-01 03:58:59,790-Speed 1102.51 samples/sec   Loss 2.4888 target_logit_mean -0.0015 lma 0.6820  cos_theta_tmp 0.7595  Epoch: 4   Global Step: 75650   Required: 32 hours
Training: 2025-12-01 03:59:17,209-Speed 1102.29 samples/sec   Loss 2.5134 target_logit_mean 0.0015 lma 0.6899  cos_theta_tmp 0.7628  Epoch: 4   Global Step: 75700   Required: 32 hours
Training: 2025-12-01 03:59:34,626-Speed 1102.44 samples/sec   Loss 2.5092 target_logit_mean 0.0018 lma 0.6909  cos_theta_tmp 0.7673  Epoch: 4   Global Step: 75750   Required: 32 hours
Training: 2025-12-01 03:59:52,077-Speed 1100.25 samples/sec   Loss 2.4890 target_logit_mean 0.0015 lma 0.6890  cos_theta_tmp 0.7636  Epoch: 4   Global Step: 75800   Required: 32 hours
Training: 2025-12-01 04:00:09,933-[lfw][75815]XNorm: 24.104931
Training: 2025-12-01 04:00:09,933-[lfw][75815]Accuracy-Flip: 0.99117+-0.00454
Training: 2025-12-01 04:00:09,933-[lfw][75815]Accuracy-Highest: 0.99117
Training: 2025-12-01 04:00:24,212-[cfp_fp][75815]XNorm: 19.604474
Training: 2025-12-01 04:00:24,212-[cfp_fp][75815]Accuracy-Flip: 0.88014+-0.01708
Training: 2025-12-01 04:00:24,212-[cfp_fp][75815]Accuracy-Highest: 0.88429
Training: 2025-12-01 04:00:38,525-[cfp_ff][75815]XNorm: 23.402476
Training: 2025-12-01 04:00:38,525-[cfp_ff][75815]Accuracy-Flip: 0.99043+-0.00367
Training: 2025-12-01 04:00:38,525-[cfp_ff][75815]Accuracy-Highest: 0.99043
Training: 2025-12-01 04:00:50,853-[agedb_30][75815]XNorm: 22.994264
Training: 2025-12-01 04:00:50,853-[agedb_30][75815]Accuracy-Flip: 0.92917+-0.01728
Training: 2025-12-01 04:00:50,853-[agedb_30][75815]Accuracy-Highest: 0.92917
Training: 2025-12-01 04:01:03,433-[calfw][75815]XNorm: 24.080907
Training: 2025-12-01 04:01:03,433-[calfw][75815]Accuracy-Flip: 0.93817+-0.00886
Training: 2025-12-01 04:01:03,433-[calfw][75815]Accuracy-Highest: 0.93883
Training: 2025-12-01 04:01:15,977-[cplfw][75815]XNorm: 19.837388
Training: 2025-12-01 04:01:15,977-[cplfw][75815]Accuracy-Flip: 0.84967+-0.02202
Training: 2025-12-01 04:01:15,977-[cplfw][75815]Accuracy-Highest: 0.85333
Training: 2025-12-01 04:01:26,551-[vgg2_fp][75815]XNorm: 20.288333
Training: 2025-12-01 04:01:26,551-[vgg2_fp][75815]Accuracy-Flip: 0.88840+-0.01196
Training: 2025-12-01 04:01:26,551-[vgg2_fp][75815]Accuracy-Highest: 0.88840
Training: 2025-12-01 04:01:53,415-Speed 158.24 samples/sec   Loss 2.5412 target_logit_mean 0.0004 lma 0.6817  cos_theta_tmp 0.7578  Epoch: 5   Global Step: 75850   Required: 33 hours
Training: 2025-12-01 04:02:10,783-Speed 1105.56 samples/sec   Loss 2.4933 target_logit_mean 0.0028 lma 0.6874  cos_theta_tmp 0.7573  Epoch: 5   Global Step: 75900   Required: 33 hours
Training: 2025-12-01 04:02:28,179-Speed 1103.74 samples/sec   Loss 2.4592 target_logit_mean 0.0021 lma 0.6878  cos_theta_tmp 0.7619  Epoch: 5   Global Step: 75950   Required: 33 hours
Training: 2025-12-01 04:02:45,598-Speed 1102.30 samples/sec   Loss 2.4540 target_logit_mean -0.0006 lma 0.6842  cos_theta_tmp 0.7579  Epoch: 5   Global Step: 76000   Required: 33 hours
Training: 2025-12-01 04:03:03,017-Speed 1102.23 samples/sec   Loss 2.4416 target_logit_mean -0.0010 lma 0.6966  cos_theta_tmp 0.7647  Epoch: 5   Global Step: 76050   Required: 33 hours
Training: 2025-12-01 04:03:20,439-Speed 1102.15 samples/sec   Loss 2.5322 target_logit_mean 0.0010 lma 0.6919  cos_theta_tmp 0.7593  Epoch: 5   Global Step: 76100   Required: 33 hours
Training: 2025-12-01 04:03:37,854-Speed 1102.50 samples/sec   Loss 2.5316 target_logit_mean -0.0013 lma 0.6922  cos_theta_tmp 0.7589  Epoch: 5   Global Step: 76150   Required: 33 hours
Training: 2025-12-01 04:03:55,276-Speed 1102.09 samples/sec   Loss 2.4644 target_logit_mean 0.0012 lma 0.6893  cos_theta_tmp 0.7585  Epoch: 5   Global Step: 76200   Required: 33 hours
Training: 2025-12-01 04:04:12,695-Speed 1102.26 samples/sec   Loss 2.4957 target_logit_mean 0.0002 lma 0.6833  cos_theta_tmp 0.7643  Epoch: 5   Global Step: 76250   Required: 33 hours
Training: 2025-12-01 04:04:30,114-Speed 1102.29 samples/sec   Loss 2.4559 target_logit_mean -0.0013 lma 0.6874  cos_theta_tmp 0.7629  Epoch: 5   Global Step: 76300   Required: 32 hours
Training: 2025-12-01 04:04:47,539-Speed 1101.92 samples/sec   Loss 2.5033 target_logit_mean 0.0009 lma 0.6777  cos_theta_tmp 0.7598  Epoch: 5   Global Step: 76350   Required: 32 hours
Training: 2025-12-01 04:05:04,958-Speed 1102.25 samples/sec   Loss 2.5054 target_logit_mean 0.0000 lma 0.6808  cos_theta_tmp 0.7615  Epoch: 5   Global Step: 76400   Required: 32 hours
Training: 2025-12-01 04:05:22,379-Speed 1102.18 samples/sec   Loss 2.5195 target_logit_mean -0.0023 lma 0.6754  cos_theta_tmp 0.7536  Epoch: 5   Global Step: 76450   Required: 32 hours
Training: 2025-12-01 04:05:39,793-Speed 1102.58 samples/sec   Loss 2.5596 target_logit_mean -0.0029 lma 0.6923  cos_theta_tmp 0.7602  Epoch: 5   Global Step: 76500   Required: 32 hours
Training: 2025-12-01 04:05:57,210-Speed 1102.42 samples/sec   Loss 2.5187 target_logit_mean 0.0002 lma 0.6966  cos_theta_tmp 0.7659  Epoch: 5   Global Step: 76550   Required: 32 hours
Training: 2025-12-01 04:06:14,628-Speed 1102.34 samples/sec   Loss 2.4897 target_logit_mean 0.0012 lma 0.6812  cos_theta_tmp 0.7665  Epoch: 5   Global Step: 76600   Required: 32 hours
Training: 2025-12-01 04:06:32,045-Speed 1102.43 samples/sec   Loss 2.5064 target_logit_mean 0.0018 lma 0.6934  cos_theta_tmp 0.7664  Epoch: 5   Global Step: 76650   Required: 32 hours
Training: 2025-12-01 04:06:49,464-Speed 1102.27 samples/sec   Loss 2.4694 target_logit_mean 0.0042 lma 0.6787  cos_theta_tmp 0.7611  Epoch: 5   Global Step: 76700   Required: 32 hours
Training: 2025-12-01 04:07:06,879-Speed 1102.56 samples/sec   Loss 2.4988 target_logit_mean -0.0028 lma 0.6924  cos_theta_tmp 0.7637  Epoch: 5   Global Step: 76750   Required: 32 hours
Training: 2025-12-01 04:07:24,298-Speed 1102.26 samples/sec   Loss 2.5586 target_logit_mean -0.0008 lma 0.6928  cos_theta_tmp 0.7655  Epoch: 5   Global Step: 76800   Required: 32 hours
Training: 2025-12-01 04:07:41,716-Speed 1102.37 samples/sec   Loss 2.5063 target_logit_mean 0.0003 lma 0.6800  cos_theta_tmp 0.7614  Epoch: 5   Global Step: 76850   Required: 32 hours
Training: 2025-12-01 04:07:59,134-Speed 1102.31 samples/sec   Loss 2.5090 target_logit_mean -0.0009 lma 0.6907  cos_theta_tmp 0.7582  Epoch: 5   Global Step: 76900   Required: 32 hours
Training: 2025-12-01 04:08:16,556-Speed 1102.10 samples/sec   Loss 2.4998 target_logit_mean -0.0006 lma 0.6901  cos_theta_tmp 0.7664  Epoch: 5   Global Step: 76950   Required: 32 hours
Training: 2025-12-01 04:08:33,974-Speed 1102.36 samples/sec   Loss 2.4679 target_logit_mean -0.0019 lma 0.6937  cos_theta_tmp 0.7611  Epoch: 5   Global Step: 77000   Required: 32 hours
Training: 2025-12-01 04:08:51,392-Speed 1102.33 samples/sec   Loss 2.5140 target_logit_mean 0.0006 lma 0.6946  cos_theta_tmp 0.7590  Epoch: 5   Global Step: 77050   Required: 32 hours
Training: 2025-12-01 04:09:08,810-Speed 1102.38 samples/sec   Loss 2.5137 target_logit_mean 0.0011 lma 0.6849  cos_theta_tmp 0.7596  Epoch: 5   Global Step: 77100   Required: 32 hours
Training: 2025-12-01 04:09:26,225-Speed 1102.56 samples/sec   Loss 2.5356 target_logit_mean 0.0002 lma 0.6820  cos_theta_tmp 0.7638  Epoch: 5   Global Step: 77150   Required: 32 hours
Training: 2025-12-01 04:09:43,639-Speed 1102.59 samples/sec   Loss 2.4904 target_logit_mean -0.0020 lma 0.6797  cos_theta_tmp 0.7616  Epoch: 5   Global Step: 77200   Required: 32 hours
Training: 2025-12-01 04:10:01,059-Speed 1102.21 samples/sec   Loss 2.4489 target_logit_mean -0.0026 lma 0.6868  cos_theta_tmp 0.7635  Epoch: 5   Global Step: 77250   Required: 32 hours
Training: 2025-12-01 04:10:18,474-Speed 1102.52 samples/sec   Loss 2.4876 target_logit_mean -0.0006 lma 0.6816  cos_theta_tmp 0.7615  Epoch: 5   Global Step: 77300   Required: 32 hours
Training: 2025-12-01 04:10:35,894-Speed 1102.24 samples/sec   Loss 2.4808 target_logit_mean 0.0013 lma 0.6802  cos_theta_tmp 0.7599  Epoch: 5   Global Step: 77350   Required: 32 hours
Training: 2025-12-01 04:10:53,317-Speed 1102.03 samples/sec   Loss 2.4890 target_logit_mean -0.0018 lma 0.6867  cos_theta_tmp 0.7595  Epoch: 5   Global Step: 77400   Required: 32 hours
Training: 2025-12-01 04:11:10,733-Speed 1102.46 samples/sec   Loss 2.4981 target_logit_mean 0.0009 lma 0.6742  cos_theta_tmp 0.7616  Epoch: 5   Global Step: 77450   Required: 32 hours
Training: 2025-12-01 04:11:28,154-Speed 1102.16 samples/sec   Loss 2.4893 target_logit_mean -0.0029 lma 0.6676  cos_theta_tmp 0.7589  Epoch: 5   Global Step: 77500   Required: 32 hours
Training: 2025-12-01 04:11:45,581-Speed 1101.79 samples/sec   Loss 2.5345 target_logit_mean -0.0028 lma 0.6823  cos_theta_tmp 0.7598  Epoch: 5   Global Step: 77550   Required: 32 hours
Training: 2025-12-01 04:12:03,003-Speed 1102.05 samples/sec   Loss 2.4491 target_logit_mean 0.0010 lma 0.6857  cos_theta_tmp 0.7586  Epoch: 5   Global Step: 77600   Required: 32 hours
Training: 2025-12-01 04:12:20,420-Speed 1102.45 samples/sec   Loss 2.4977 target_logit_mean -0.0016 lma 0.6857  cos_theta_tmp 0.7606  Epoch: 5   Global Step: 77650   Required: 32 hours
Training: 2025-12-01 04:12:37,839-Speed 1102.27 samples/sec   Loss 2.4533 target_logit_mean -0.0006 lma 0.6932  cos_theta_tmp 0.7652  Epoch: 5   Global Step: 77700   Required: 32 hours
Training: 2025-12-01 04:12:55,473-Speed 1088.83 samples/sec   Loss 2.4826 target_logit_mean 0.0004 lma 0.6793  cos_theta_tmp 0.7602  Epoch: 5   Global Step: 77750   Required: 32 hours
Training: 2025-12-01 04:13:13,007-Speed 1095.05 samples/sec   Loss 2.4919 target_logit_mean 0.0005 lma 0.6983  cos_theta_tmp 0.7614  Epoch: 5   Global Step: 77800   Required: 32 hours
Training: 2025-12-01 04:13:30,585-Speed 1092.34 samples/sec   Loss 2.4934 target_logit_mean -0.0003 lma 0.6723  cos_theta_tmp 0.7535  Epoch: 5   Global Step: 77850   Required: 32 hours
Training: 2025-12-01 04:13:47,999-Speed 1102.59 samples/sec   Loss 2.5683 target_logit_mean -0.0008 lma 0.6835  cos_theta_tmp 0.7583  Epoch: 5   Global Step: 77900   Required: 32 hours
Training: 2025-12-01 04:14:05,420-Speed 1102.18 samples/sec   Loss 2.4733 target_logit_mean 0.0009 lma 0.6749  cos_theta_tmp 0.7595  Epoch: 5   Global Step: 77950   Required: 32 hours
Training: 2025-12-01 04:14:22,838-Speed 1102.33 samples/sec   Loss 2.4697 target_logit_mean 0.0003 lma 0.6849  cos_theta_tmp 0.7625  Epoch: 5   Global Step: 78000   Required: 32 hours
Training: 2025-12-01 04:14:40,256-Speed 1102.30 samples/sec   Loss 2.4516 target_logit_mean -0.0011 lma 0.6768  cos_theta_tmp 0.7590  Epoch: 5   Global Step: 78050   Required: 32 hours
Training: 2025-12-01 04:14:57,672-Speed 1102.54 samples/sec   Loss 2.4874 target_logit_mean 0.0006 lma 0.6872  cos_theta_tmp 0.7568  Epoch: 5   Global Step: 78100   Required: 32 hours
Training: 2025-12-01 04:15:15,085-Speed 1102.62 samples/sec   Loss 2.4557 target_logit_mean 0.0019 lma 0.6826  cos_theta_tmp 0.7603  Epoch: 5   Global Step: 78150   Required: 32 hours
Training: 2025-12-01 04:15:32,510-Speed 1101.91 samples/sec   Loss 2.4844 target_logit_mean -0.0024 lma 0.6843  cos_theta_tmp 0.7584  Epoch: 5   Global Step: 78200   Required: 32 hours
Training: 2025-12-01 04:15:49,929-Speed 1102.26 samples/sec   Loss 2.4780 target_logit_mean -0.0002 lma 0.6858  cos_theta_tmp 0.7623  Epoch: 5   Global Step: 78250   Required: 32 hours
Training: 2025-12-01 04:16:07,347-Speed 1102.37 samples/sec   Loss 2.5257 target_logit_mean 0.0020 lma 0.6816  cos_theta_tmp 0.7609  Epoch: 5   Global Step: 78300   Required: 32 hours
Training: 2025-12-01 04:16:24,767-Speed 1102.20 samples/sec   Loss 2.5498 target_logit_mean 0.0012 lma 0.6811  cos_theta_tmp 0.7535  Epoch: 5   Global Step: 78350   Required: 32 hours
Training: 2025-12-01 04:16:42,189-Speed 1102.08 samples/sec   Loss 2.5119 target_logit_mean 0.0015 lma 0.6891  cos_theta_tmp 0.7646  Epoch: 5   Global Step: 78400   Required: 32 hours
Training: 2025-12-01 04:16:59,613-Speed 1101.96 samples/sec   Loss 2.5011 target_logit_mean 0.0026 lma 0.6891  cos_theta_tmp 0.7620  Epoch: 5   Global Step: 78450   Required: 32 hours
Training: 2025-12-01 04:17:17,031-Speed 1102.35 samples/sec   Loss 2.4594 target_logit_mean 0.0021 lma 0.6892  cos_theta_tmp 0.7629  Epoch: 5   Global Step: 78500   Required: 32 hours
Training: 2025-12-01 04:17:34,449-Speed 1102.33 samples/sec   Loss 2.4719 target_logit_mean -0.0011 lma 0.6733  cos_theta_tmp 0.7610  Epoch: 5   Global Step: 78550   Required: 32 hours
Training: 2025-12-01 04:17:51,865-Speed 1102.53 samples/sec   Loss 2.4723 target_logit_mean 0.0001 lma 0.6812  cos_theta_tmp 0.7640  Epoch: 5   Global Step: 78600   Required: 32 hours
Training: 2025-12-01 04:18:09,287-Speed 1102.09 samples/sec   Loss 2.4649 target_logit_mean 0.0002 lma 0.6815  cos_theta_tmp 0.7599  Epoch: 5   Global Step: 78650   Required: 32 hours
Training: 2025-12-01 04:18:26,709-Speed 1102.08 samples/sec   Loss 2.4680 target_logit_mean 0.0004 lma 0.6872  cos_theta_tmp 0.7595  Epoch: 5   Global Step: 78700   Required: 32 hours
Training: 2025-12-01 04:18:44,127-Speed 1102.32 samples/sec   Loss 2.4433 target_logit_mean -0.0013 lma 0.6775  cos_theta_tmp 0.7591  Epoch: 5   Global Step: 78750   Required: 32 hours
Training: 2025-12-01 04:19:01,551-Speed 1101.95 samples/sec   Loss 2.5436 target_logit_mean 0.0006 lma 0.6918  cos_theta_tmp 0.7680  Epoch: 5   Global Step: 78800   Required: 32 hours
Training: 2025-12-01 04:19:18,972-Speed 1102.16 samples/sec   Loss 2.4989 target_logit_mean 0.0024 lma 0.6944  cos_theta_tmp 0.7659  Epoch: 5   Global Step: 78850   Required: 32 hours
Training: 2025-12-01 04:19:36,394-Speed 1102.09 samples/sec   Loss 2.5052 target_logit_mean 0.0020 lma 0.6908  cos_theta_tmp 0.7627  Epoch: 5   Global Step: 78900   Required: 32 hours
Training: 2025-12-01 04:19:53,856-Speed 1099.60 samples/sec   Loss 2.5250 target_logit_mean -0.0003 lma 0.6855  cos_theta_tmp 0.7572  Epoch: 5   Global Step: 78950   Required: 32 hours
Training: 2025-12-01 04:20:11,275-Speed 1102.30 samples/sec   Loss 2.5259 target_logit_mean 0.0008 lma 0.6862  cos_theta_tmp 0.7579  Epoch: 5   Global Step: 79000   Required: 32 hours
Training: 2025-12-01 04:20:28,695-Speed 1102.21 samples/sec   Loss 2.4535 target_logit_mean 0.0002 lma 0.6781  cos_theta_tmp 0.7598  Epoch: 5   Global Step: 79050   Required: 32 hours
Training: 2025-12-01 04:20:46,108-Speed 1102.63 samples/sec   Loss 2.4914 target_logit_mean 0.0003 lma 0.6830  cos_theta_tmp 0.7670  Epoch: 5   Global Step: 79100   Required: 32 hours
Training: 2025-12-01 04:21:03,527-Speed 1102.35 samples/sec   Loss 2.4490 target_logit_mean -0.0000 lma 0.6807  cos_theta_tmp 0.7556  Epoch: 5   Global Step: 79150   Required: 32 hours
Training: 2025-12-01 04:21:20,947-Speed 1102.23 samples/sec   Loss 2.4874 target_logit_mean -0.0020 lma 0.6954  cos_theta_tmp 0.7583  Epoch: 5   Global Step: 79200   Required: 32 hours
Training: 2025-12-01 04:21:38,371-Speed 1101.92 samples/sec   Loss 2.4910 target_logit_mean -0.0005 lma 0.6888  cos_theta_tmp 0.7633  Epoch: 5   Global Step: 79250   Required: 32 hours
Training: 2025-12-01 04:21:55,792-Speed 1102.15 samples/sec   Loss 2.5162 target_logit_mean 0.0003 lma 0.6822  cos_theta_tmp 0.7584  Epoch: 5   Global Step: 79300   Required: 32 hours
Training: 2025-12-01 04:22:13,214-Speed 1102.12 samples/sec   Loss 2.4343 target_logit_mean -0.0010 lma 0.6779  cos_theta_tmp 0.7629  Epoch: 5   Global Step: 79350   Required: 32 hours
Training: 2025-12-01 04:22:30,633-Speed 1102.27 samples/sec   Loss 2.4437 target_logit_mean 0.0011 lma 0.6766  cos_theta_tmp 0.7654  Epoch: 5   Global Step: 79400   Required: 32 hours
Training: 2025-12-01 04:22:48,051-Speed 1102.37 samples/sec   Loss 2.4914 target_logit_mean 0.0005 lma 0.6958  cos_theta_tmp 0.7633  Epoch: 5   Global Step: 79450   Required: 32 hours
Training: 2025-12-01 04:23:05,476-Speed 1101.92 samples/sec   Loss 2.4985 target_logit_mean 0.0037 lma 0.6899  cos_theta_tmp 0.7628  Epoch: 5   Global Step: 79500   Required: 32 hours
Training: 2025-12-01 04:23:22,894-Speed 1102.30 samples/sec   Loss 2.4603 target_logit_mean 0.0002 lma 0.6821  cos_theta_tmp 0.7650  Epoch: 5   Global Step: 79550   Required: 32 hours
Training: 2025-12-01 04:23:40,313-Speed 1102.29 samples/sec   Loss 2.4937 target_logit_mean -0.0003 lma 0.6880  cos_theta_tmp 0.7590  Epoch: 5   Global Step: 79600   Required: 32 hours
Training: 2025-12-01 04:23:57,731-Speed 1102.38 samples/sec   Loss 2.5170 target_logit_mean 0.0015 lma 0.6860  cos_theta_tmp 0.7636  Epoch: 5   Global Step: 79650   Required: 32 hours
Training: 2025-12-01 04:24:15,149-Speed 1102.34 samples/sec   Loss 2.4583 target_logit_mean 0.0038 lma 0.6866  cos_theta_tmp 0.7617  Epoch: 5   Global Step: 79700   Required: 32 hours
Training: 2025-12-01 04:24:32,573-Speed 1101.97 samples/sec   Loss 2.5018 target_logit_mean 0.0006 lma 0.6752  cos_theta_tmp 0.7609  Epoch: 5   Global Step: 79750   Required: 32 hours
Training: 2025-12-01 04:24:49,991-Speed 1102.34 samples/sec   Loss 2.4654 target_logit_mean 0.0002 lma 0.6762  cos_theta_tmp 0.7633  Epoch: 5   Global Step: 79800   Required: 32 hours
Training: 2025-12-01 04:25:07,410-Speed 1102.28 samples/sec   Loss 2.4975 target_logit_mean -0.0036 lma 0.6851  cos_theta_tmp 0.7636  Epoch: 5   Global Step: 79850   Required: 32 hours
Training: 2025-12-01 04:25:24,833-Speed 1102.04 samples/sec   Loss 2.4628 target_logit_mean -0.0009 lma 0.6774  cos_theta_tmp 0.7612  Epoch: 5   Global Step: 79900   Required: 32 hours
Training: 2025-12-01 04:25:42,248-Speed 1102.49 samples/sec   Loss 2.4883 target_logit_mean -0.0004 lma 0.6859  cos_theta_tmp 0.7660  Epoch: 5   Global Step: 79950   Required: 32 hours
Training: 2025-12-01 04:25:59,668-Speed 1102.24 samples/sec   Loss 2.4797 target_logit_mean -0.0007 lma 0.6828  cos_theta_tmp 0.7593  Epoch: 5   Global Step: 80000   Required: 32 hours
Training: 2025-12-01 04:26:17,089-Speed 1102.18 samples/sec   Loss 2.4657 target_logit_mean 0.0005 lma 0.6791  cos_theta_tmp 0.7634  Epoch: 5   Global Step: 80050   Required: 32 hours
Training: 2025-12-01 04:26:34,513-Speed 1101.97 samples/sec   Loss 2.5488 target_logit_mean 0.0009 lma 0.6793  cos_theta_tmp 0.7623  Epoch: 5   Global Step: 80100   Required: 32 hours
Training: 2025-12-01 04:26:51,933-Speed 1102.21 samples/sec   Loss 2.4837 target_logit_mean 0.0028 lma 0.6837  cos_theta_tmp 0.7621  Epoch: 5   Global Step: 80150   Required: 32 hours
Training: 2025-12-01 04:27:09,358-Speed 1101.89 samples/sec   Loss 2.5513 target_logit_mean -0.0012 lma 0.6695  cos_theta_tmp 0.7568  Epoch: 5   Global Step: 80200   Required: 32 hours
Training: 2025-12-01 04:27:26,784-Speed 1101.84 samples/sec   Loss 2.5107 target_logit_mean -0.0006 lma 0.6690  cos_theta_tmp 0.7635  Epoch: 5   Global Step: 80250   Required: 32 hours
Training: 2025-12-01 04:27:44,200-Speed 1102.48 samples/sec   Loss 2.5174 target_logit_mean -0.0034 lma 0.6698  cos_theta_tmp 0.7579  Epoch: 5   Global Step: 80300   Required: 32 hours
Training: 2025-12-01 04:28:01,619-Speed 1102.30 samples/sec   Loss 2.4441 target_logit_mean -0.0011 lma 0.6921  cos_theta_tmp 0.7643  Epoch: 5   Global Step: 80350   Required: 32 hours
Training: 2025-12-01 04:28:19,036-Speed 1102.35 samples/sec   Loss 2.4503 target_logit_mean -0.0014 lma 0.6823  cos_theta_tmp 0.7621  Epoch: 5   Global Step: 80400   Required: 32 hours
Training: 2025-12-01 04:28:36,457-Speed 1102.16 samples/sec   Loss 2.5164 target_logit_mean 0.0004 lma 0.6755  cos_theta_tmp 0.7627  Epoch: 5   Global Step: 80450   Required: 32 hours
Training: 2025-12-01 04:28:53,881-Speed 1102.00 samples/sec   Loss 2.5179 target_logit_mean -0.0000 lma 0.6798  cos_theta_tmp 0.7575  Epoch: 5   Global Step: 80500   Required: 32 hours
Training: 2025-12-01 04:29:11,302-Speed 1102.12 samples/sec   Loss 2.5207 target_logit_mean -0.0023 lma 0.6739  cos_theta_tmp 0.7540  Epoch: 5   Global Step: 80550   Required: 32 hours
Training: 2025-12-01 04:29:28,723-Speed 1102.18 samples/sec   Loss 2.4911 target_logit_mean 0.0031 lma 0.6861  cos_theta_tmp 0.7608  Epoch: 5   Global Step: 80600   Required: 32 hours
Training: 2025-12-01 04:29:46,146-Speed 1102.08 samples/sec   Loss 2.4486 target_logit_mean 0.0003 lma 0.6743  cos_theta_tmp 0.7581  Epoch: 5   Global Step: 80650   Required: 32 hours
Training: 2025-12-01 04:30:03,567-Speed 1102.15 samples/sec   Loss 2.5116 target_logit_mean 0.0002 lma 0.6832  cos_theta_tmp 0.7582  Epoch: 5   Global Step: 80700   Required: 32 hours
Training: 2025-12-01 04:30:20,986-Speed 1102.28 samples/sec   Loss 2.4453 target_logit_mean 0.0007 lma 0.6871  cos_theta_tmp 0.7596  Epoch: 5   Global Step: 80750   Required: 32 hours
Training: 2025-12-01 04:30:38,403-Speed 1102.38 samples/sec   Loss 2.4506 target_logit_mean 0.0018 lma 0.6870  cos_theta_tmp 0.7672  Epoch: 5   Global Step: 80800   Required: 32 hours
Training: 2025-12-01 04:30:55,822-Speed 1102.30 samples/sec   Loss 2.4736 target_logit_mean -0.0002 lma 0.6748  cos_theta_tmp 0.7576  Epoch: 5   Global Step: 80850   Required: 32 hours
Training: 2025-12-01 04:31:13,241-Speed 1102.29 samples/sec   Loss 2.4824 target_logit_mean 0.0011 lma 0.6778  cos_theta_tmp 0.7652  Epoch: 5   Global Step: 80900   Required: 32 hours
Training: 2025-12-01 04:31:30,661-Speed 1102.19 samples/sec   Loss 2.4797 target_logit_mean -0.0010 lma 0.6878  cos_theta_tmp 0.7628  Epoch: 5   Global Step: 80950   Required: 32 hours
Training: 2025-12-01 04:31:48,084-Speed 1102.06 samples/sec   Loss 2.4438 target_logit_mean 0.0011 lma 0.6838  cos_theta_tmp 0.7578  Epoch: 5   Global Step: 81000   Required: 32 hours
Training: 2025-12-01 04:32:05,505-Speed 1102.13 samples/sec   Loss 2.4639 target_logit_mean 0.0015 lma 0.6827  cos_theta_tmp 0.7605  Epoch: 5   Global Step: 81050   Required: 32 hours
Training: 2025-12-01 04:32:22,925-Speed 1102.24 samples/sec   Loss 2.5072 target_logit_mean -0.0000 lma 0.6933  cos_theta_tmp 0.7681  Epoch: 5   Global Step: 81100   Required: 32 hours
Training: 2025-12-01 04:32:40,344-Speed 1102.26 samples/sec   Loss 2.5136 target_logit_mean -0.0029 lma 0.6813  cos_theta_tmp 0.7572  Epoch: 5   Global Step: 81150   Required: 32 hours
Training: 2025-12-01 04:32:57,763-Speed 1102.28 samples/sec   Loss 2.4208 target_logit_mean -0.0013 lma 0.6777  cos_theta_tmp 0.7553  Epoch: 5   Global Step: 81200   Required: 32 hours
Training: 2025-12-01 04:33:15,185-Speed 1102.12 samples/sec   Loss 2.4233 target_logit_mean -0.0011 lma 0.6904  cos_theta_tmp 0.7625  Epoch: 5   Global Step: 81250   Required: 32 hours
Training: 2025-12-01 04:33:32,609-Speed 1101.95 samples/sec   Loss 2.4437 target_logit_mean 0.0020 lma 0.6816  cos_theta_tmp 0.7581  Epoch: 5   Global Step: 81300   Required: 32 hours
Training: 2025-12-01 04:33:50,044-Speed 1101.25 samples/sec   Loss 2.4634 target_logit_mean 0.0011 lma 0.6880  cos_theta_tmp 0.7626  Epoch: 5   Global Step: 81350   Required: 32 hours
Training: 2025-12-01 04:34:07,483-Speed 1101.02 samples/sec   Loss 2.4907 target_logit_mean -0.0016 lma 0.6855  cos_theta_tmp 0.7562  Epoch: 5   Global Step: 81400   Required: 32 hours
Training: 2025-12-01 04:34:24,819-Speed 1107.58 samples/sec   Loss 2.5195 target_logit_mean 0.0018 lma 0.6881  cos_theta_tmp 0.7671  Epoch: 5   Global Step: 81450   Required: 32 hours
Training: 2025-12-01 04:34:42,176-Speed 1106.19 samples/sec   Loss 2.4299 target_logit_mean -0.0007 lma 0.6908  cos_theta_tmp 0.7655  Epoch: 5   Global Step: 81500   Required: 32 hours
Training: 2025-12-01 04:34:59,723-Speed 1094.29 samples/sec   Loss 2.4456 target_logit_mean -0.0004 lma 0.6865  cos_theta_tmp 0.7637  Epoch: 5   Global Step: 81550   Required: 32 hours
Training: 2025-12-01 04:35:17,295-Speed 1092.71 samples/sec   Loss 2.4236 target_logit_mean 0.0001 lma 0.6882  cos_theta_tmp 0.7675  Epoch: 5   Global Step: 81600   Required: 32 hours
Training: 2025-12-01 04:35:34,748-Speed 1100.07 samples/sec   Loss 2.5105 target_logit_mean 0.0005 lma 0.6794  cos_theta_tmp 0.7645  Epoch: 5   Global Step: 81650   Required: 32 hours
Training: 2025-12-01 04:35:52,205-Speed 1099.92 samples/sec   Loss 2.4159 target_logit_mean 0.0016 lma 0.6911  cos_theta_tmp 0.7687  Epoch: 5   Global Step: 81700   Required: 32 hours
Training: 2025-12-01 04:36:09,647-Speed 1100.87 samples/sec   Loss 2.4350 target_logit_mean 0.0007 lma 0.6806  cos_theta_tmp 0.7628  Epoch: 5   Global Step: 81750   Required: 32 hours
Training: 2025-12-01 04:36:26,935-Speed 1110.62 samples/sec   Loss 2.4449 target_logit_mean -0.0000 lma 0.6779  cos_theta_tmp 0.7613  Epoch: 5   Global Step: 81800   Required: 32 hours
Training: 2025-12-01 04:36:44,377-Speed 1100.83 samples/sec   Loss 2.4480 target_logit_mean 0.0011 lma 0.6930  cos_theta_tmp 0.7636  Epoch: 5   Global Step: 81850   Required: 32 hours
Training: 2025-12-01 04:37:01,969-Speed 1091.45 samples/sec   Loss 2.4815 target_logit_mean 0.0027 lma 0.6891  cos_theta_tmp 0.7586  Epoch: 5   Global Step: 81900   Required: 32 hours
Training: 2025-12-01 04:37:19,456-Speed 1097.97 samples/sec   Loss 2.4568 target_logit_mean 0.0005 lma 0.6949  cos_theta_tmp 0.7660  Epoch: 5   Global Step: 81950   Required: 32 hours
Training: 2025-12-01 04:37:36,910-Speed 1100.10 samples/sec   Loss 2.4333 target_logit_mean -0.0029 lma 0.6768  cos_theta_tmp 0.7571  Epoch: 5   Global Step: 82000   Required: 32 hours
Training: 2025-12-01 04:37:54,360-Speed 1100.29 samples/sec   Loss 2.4830 target_logit_mean 0.0004 lma 0.6872  cos_theta_tmp 0.7603  Epoch: 5   Global Step: 82050   Required: 32 hours
Training: 2025-12-01 04:38:11,814-Speed 1100.10 samples/sec   Loss 2.5006 target_logit_mean 0.0023 lma 0.6815  cos_theta_tmp 0.7623  Epoch: 5   Global Step: 82100   Required: 32 hours
Training: 2025-12-01 04:38:29,249-Speed 1101.31 samples/sec   Loss 2.4151 target_logit_mean 0.0008 lma 0.6623  cos_theta_tmp 0.7618  Epoch: 5   Global Step: 82150   Required: 32 hours
Training: 2025-12-01 04:38:46,693-Speed 1100.70 samples/sec   Loss 2.4755 target_logit_mean -0.0004 lma 0.6892  cos_theta_tmp 0.7643  Epoch: 5   Global Step: 82200   Required: 32 hours
Training: 2025-12-01 04:39:04,085-Speed 1103.97 samples/sec   Loss 2.4238 target_logit_mean -0.0004 lma 0.6647  cos_theta_tmp 0.7600  Epoch: 5   Global Step: 82250   Required: 32 hours
Training: 2025-12-01 04:39:21,641-Speed 1093.65 samples/sec   Loss 2.5553 target_logit_mean 0.0010 lma 0.6811  cos_theta_tmp 0.7604  Epoch: 5   Global Step: 82300   Required: 32 hours
Training: 2025-12-01 04:39:39,096-Speed 1100.01 samples/sec   Loss 2.4679 target_logit_mean 0.0014 lma 0.6913  cos_theta_tmp 0.7648  Epoch: 5   Global Step: 82350   Required: 32 hours
Training: 2025-12-01 04:39:56,584-Speed 1097.99 samples/sec   Loss 2.4777 target_logit_mean 0.0008 lma 0.6832  cos_theta_tmp 0.7581  Epoch: 5   Global Step: 82400   Required: 32 hours
Training: 2025-12-01 04:40:14,023-Speed 1101.00 samples/sec   Loss 2.4606 target_logit_mean 0.0002 lma 0.6845  cos_theta_tmp 0.7600  Epoch: 5   Global Step: 82450   Required: 32 hours
Training: 2025-12-01 04:40:31,457-Speed 1101.34 samples/sec   Loss 2.4749 target_logit_mean -0.0004 lma 0.6804  cos_theta_tmp 0.7602  Epoch: 5   Global Step: 82500   Required: 32 hours
Training: 2025-12-01 04:40:48,899-Speed 1100.82 samples/sec   Loss 2.4843 target_logit_mean 0.0005 lma 0.6793  cos_theta_tmp 0.7565  Epoch: 5   Global Step: 82550   Required: 32 hours
Training: 2025-12-01 04:41:06,341-Speed 1100.81 samples/sec   Loss 2.5067 target_logit_mean 0.0013 lma 0.6822  cos_theta_tmp 0.7611  Epoch: 5   Global Step: 82600   Required: 32 hours
Training: 2025-12-01 04:41:23,775-Speed 1101.35 samples/sec   Loss 2.4653 target_logit_mean 0.0001 lma 0.6874  cos_theta_tmp 0.7591  Epoch: 5   Global Step: 82650   Required: 32 hours
Training: 2025-12-01 04:41:41,216-Speed 1100.93 samples/sec   Loss 2.4673 target_logit_mean -0.0029 lma 0.6804  cos_theta_tmp 0.7552  Epoch: 5   Global Step: 82700   Required: 32 hours
Training: 2025-12-01 04:41:58,653-Speed 1101.10 samples/sec   Loss 2.4751 target_logit_mean 0.0039 lma 0.6730  cos_theta_tmp 0.7606  Epoch: 5   Global Step: 82750   Required: 32 hours
Training: 2025-12-01 04:42:16,095-Speed 1100.82 samples/sec   Loss 2.4574 target_logit_mean -0.0018 lma 0.6683  cos_theta_tmp 0.7611  Epoch: 5   Global Step: 82800   Required: 32 hours
Training: 2025-12-01 04:42:33,535-Speed 1100.97 samples/sec   Loss 2.4558 target_logit_mean 0.0006 lma 0.6826  cos_theta_tmp 0.7639  Epoch: 5   Global Step: 82850   Required: 32 hours
Training: 2025-12-01 04:42:50,975-Speed 1100.99 samples/sec   Loss 2.4369 target_logit_mean -0.0002 lma 0.6839  cos_theta_tmp 0.7660  Epoch: 5   Global Step: 82900   Required: 32 hours
Training: 2025-12-01 04:43:08,415-Speed 1100.93 samples/sec   Loss 2.4724 target_logit_mean 0.0016 lma 0.6650  cos_theta_tmp 0.7634  Epoch: 5   Global Step: 82950   Required: 32 hours
Training: 2025-12-01 04:43:25,854-Speed 1101.04 samples/sec   Loss 2.5198 target_logit_mean 0.0004 lma 0.6817  cos_theta_tmp 0.7640  Epoch: 5   Global Step: 83000   Required: 32 hours
Training: 2025-12-01 04:43:43,238-Speed 1104.50 samples/sec   Loss 2.4275 target_logit_mean 0.0026 lma 0.6937  cos_theta_tmp 0.7595  Epoch: 5   Global Step: 83050   Required: 32 hours
Training: 2025-12-01 04:44:00,711-Speed 1098.91 samples/sec   Loss 2.4199 target_logit_mean 0.0010 lma 0.6900  cos_theta_tmp 0.7626  Epoch: 5   Global Step: 83100   Required: 32 hours
Training: 2025-12-01 04:44:18,175-Speed 1099.45 samples/sec   Loss 2.4814 target_logit_mean -0.0004 lma 0.6795  cos_theta_tmp 0.7554  Epoch: 5   Global Step: 83150   Required: 32 hours
Training: 2025-12-01 04:44:35,623-Speed 1100.44 samples/sec   Loss 2.4654 target_logit_mean -0.0003 lma 0.6797  cos_theta_tmp 0.7619  Epoch: 5   Global Step: 83200   Required: 32 hours
Training: 2025-12-01 04:44:53,045-Speed 1102.10 samples/sec   Loss 2.5452 target_logit_mean -0.0003 lma 0.6761  cos_theta_tmp 0.7548  Epoch: 5   Global Step: 83250   Required: 32 hours
Training: 2025-12-01 04:45:10,408-Speed 1105.82 samples/sec   Loss 2.5398 target_logit_mean 0.0005 lma 0.6645  cos_theta_tmp 0.7622  Epoch: 5   Global Step: 83300   Required: 32 hours
Training: 2025-12-01 04:45:27,850-Speed 1100.83 samples/sec   Loss 2.5391 target_logit_mean 0.0008 lma 0.6781  cos_theta_tmp 0.7653  Epoch: 5   Global Step: 83350   Required: 32 hours
Training: 2025-12-01 04:45:45,395-Speed 1094.35 samples/sec   Loss 2.4689 target_logit_mean -0.0040 lma 0.6763  cos_theta_tmp 0.7519  Epoch: 5   Global Step: 83400   Required: 32 hours
Training: 2025-12-01 04:46:02,932-Speed 1094.88 samples/sec   Loss 2.4887 target_logit_mean 0.0016 lma 0.6829  cos_theta_tmp 0.7629  Epoch: 5   Global Step: 83450   Required: 32 hours
Training: 2025-12-01 04:46:20,525-Speed 1091.36 samples/sec   Loss 2.5174 target_logit_mean -0.0023 lma 0.6816  cos_theta_tmp 0.7558  Epoch: 5   Global Step: 83500   Required: 32 hours
Training: 2025-12-01 04:46:37,979-Speed 1100.13 samples/sec   Loss 2.4996 target_logit_mean -0.0011 lma 0.6695  cos_theta_tmp 0.7623  Epoch: 5   Global Step: 83550   Required: 32 hours
Training: 2025-12-01 04:46:55,423-Speed 1100.66 samples/sec   Loss 2.4841 target_logit_mean -0.0025 lma 0.6835  cos_theta_tmp 0.7613  Epoch: 5   Global Step: 83600   Required: 32 hours
Training: 2025-12-01 04:47:12,887-Speed 1099.50 samples/sec   Loss 2.4155 target_logit_mean -0.0003 lma 0.7006  cos_theta_tmp 0.7675  Epoch: 5   Global Step: 83650   Required: 32 hours
Training: 2025-12-01 04:47:30,348-Speed 1099.63 samples/sec   Loss 2.4767 target_logit_mean -0.0032 lma 0.6763  cos_theta_tmp 0.7581  Epoch: 5   Global Step: 83700   Required: 32 hours
Training: 2025-12-01 04:47:47,799-Speed 1100.27 samples/sec   Loss 2.4250 target_logit_mean 0.0002 lma 0.6834  cos_theta_tmp 0.7612  Epoch: 5   Global Step: 83750   Required: 32 hours
Training: 2025-12-01 04:48:05,222-Speed 1102.00 samples/sec   Loss 2.4363 target_logit_mean -0.0023 lma 0.6850  cos_theta_tmp 0.7575  Epoch: 5   Global Step: 83800   Required: 32 hours
Training: 2025-12-01 04:48:22,649-Speed 1101.80 samples/sec   Loss 2.4069 target_logit_mean 0.0009 lma 0.6739  cos_theta_tmp 0.7610  Epoch: 5   Global Step: 83850   Required: 32 hours
Training: 2025-12-01 04:48:40,078-Speed 1101.64 samples/sec   Loss 2.4332 target_logit_mean -0.0004 lma 0.6777  cos_theta_tmp 0.7604  Epoch: 5   Global Step: 83900   Required: 32 hours
Training: 2025-12-01 04:48:57,494-Speed 1102.48 samples/sec   Loss 2.4983 target_logit_mean 0.0020 lma 0.6830  cos_theta_tmp 0.7615  Epoch: 5   Global Step: 83950   Required: 32 hours
Training: 2025-12-01 04:49:14,923-Speed 1101.65 samples/sec   Loss 2.4143 target_logit_mean 0.0002 lma 0.6596  cos_theta_tmp 0.7632  Epoch: 5   Global Step: 84000   Required: 32 hours
Training: 2025-12-01 04:49:32,365-Speed 1100.80 samples/sec   Loss 2.4265 target_logit_mean -0.0014 lma 0.6744  cos_theta_tmp 0.7566  Epoch: 5   Global Step: 84050   Required: 32 hours
Training: 2025-12-01 04:49:49,796-Speed 1101.54 samples/sec   Loss 2.4812 target_logit_mean -0.0019 lma 0.6782  cos_theta_tmp 0.7601  Epoch: 5   Global Step: 84100   Required: 32 hours
Training: 2025-12-01 04:50:07,333-Speed 1094.89 samples/sec   Loss 2.5015 target_logit_mean -0.0024 lma 0.6795  cos_theta_tmp 0.7565  Epoch: 5   Global Step: 84150   Required: 32 hours
Training: 2025-12-01 04:50:24,820-Speed 1098.00 samples/sec   Loss 2.4684 target_logit_mean -0.0019 lma 0.6882  cos_theta_tmp 0.7620  Epoch: 5   Global Step: 84200   Required: 32 hours
Training: 2025-12-01 04:50:42,290-Speed 1099.03 samples/sec   Loss 2.4754 target_logit_mean 0.0007 lma 0.6898  cos_theta_tmp 0.7630  Epoch: 5   Global Step: 84250   Required: 32 hours
Training: 2025-12-01 04:50:59,710-Speed 1102.25 samples/sec   Loss 2.4732 target_logit_mean -0.0014 lma 0.6941  cos_theta_tmp 0.7572  Epoch: 5   Global Step: 84300   Required: 32 hours
Training: 2025-12-01 04:51:17,138-Speed 1101.73 samples/sec   Loss 2.5122 target_logit_mean 0.0011 lma 0.6844  cos_theta_tmp 0.7665  Epoch: 5   Global Step: 84350   Required: 32 hours
Training: 2025-12-01 04:51:34,554-Speed 1102.48 samples/sec   Loss 2.4763 target_logit_mean -0.0006 lma 0.6700  cos_theta_tmp 0.7603  Epoch: 5   Global Step: 84400   Required: 32 hours
Training: 2025-12-01 04:51:51,977-Speed 1102.01 samples/sec   Loss 2.4235 target_logit_mean 0.0016 lma 0.6820  cos_theta_tmp 0.7588  Epoch: 5   Global Step: 84450   Required: 32 hours
Training: 2025-12-01 04:52:09,411-Speed 1101.37 samples/sec   Loss 2.4822 target_logit_mean 0.0014 lma 0.6827  cos_theta_tmp 0.7646  Epoch: 5   Global Step: 84500   Required: 31 hours
Training: 2025-12-01 04:52:26,824-Speed 1102.67 samples/sec   Loss 2.4495 target_logit_mean 0.0015 lma 0.6772  cos_theta_tmp 0.7596  Epoch: 5   Global Step: 84550   Required: 31 hours
Training: 2025-12-01 04:52:44,258-Speed 1101.35 samples/sec   Loss 2.5008 target_logit_mean 0.0001 lma 0.6830  cos_theta_tmp 0.7619  Epoch: 5   Global Step: 84600   Required: 31 hours
Training: 2025-12-01 04:53:01,677-Speed 1102.26 samples/sec   Loss 2.5061 target_logit_mean -0.0038 lma 0.6912  cos_theta_tmp 0.7568  Epoch: 5   Global Step: 84650   Required: 31 hours
Training: 2025-12-01 04:53:19,127-Speed 1100.29 samples/sec   Loss 2.5018 target_logit_mean 0.0003 lma 0.6789  cos_theta_tmp 0.7585  Epoch: 5   Global Step: 84700   Required: 31 hours
Training: 2025-12-01 04:53:36,487-Speed 1106.08 samples/sec   Loss 2.4755 target_logit_mean 0.0003 lma 0.6933  cos_theta_tmp 0.7665  Epoch: 5   Global Step: 84750   Required: 31 hours
Training: 2025-12-01 04:53:53,831-Speed 1107.00 samples/sec   Loss 2.4640 target_logit_mean -0.0012 lma 0.6847  cos_theta_tmp 0.7591  Epoch: 5   Global Step: 84800   Required: 31 hours
Training: 2025-12-01 04:54:11,487-Speed 1087.55 samples/sec   Loss 2.4393 target_logit_mean 0.0027 lma 0.6820  cos_theta_tmp 0.7668  Epoch: 5   Global Step: 84850   Required: 31 hours
Training: 2025-12-01 04:54:28,950-Speed 1099.48 samples/sec   Loss 2.4577 target_logit_mean 0.0002 lma 0.6791  cos_theta_tmp 0.7575  Epoch: 5   Global Step: 84900   Required: 31 hours
Training: 2025-12-01 04:54:46,440-Speed 1097.79 samples/sec   Loss 2.4297 target_logit_mean 0.0024 lma 0.6774  cos_theta_tmp 0.7618  Epoch: 5   Global Step: 84950   Required: 31 hours
Training: 2025-12-01 04:55:03,925-Speed 1098.14 samples/sec   Loss 2.4362 target_logit_mean 0.0016 lma 0.6770  cos_theta_tmp 0.7610  Epoch: 5   Global Step: 85000   Required: 31 hours
Training: 2025-12-01 04:55:21,476-Speed 1094.01 samples/sec   Loss 2.4728 target_logit_mean 0.0031 lma 0.6904  cos_theta_tmp 0.7610  Epoch: 5   Global Step: 85050   Required: 31 hours
Training: 2025-12-01 04:55:38,972-Speed 1097.46 samples/sec   Loss 2.5076 target_logit_mean 0.0003 lma 0.6830  cos_theta_tmp 0.7581  Epoch: 5   Global Step: 85100   Required: 31 hours
Training: 2025-12-01 04:55:56,459-Speed 1098.00 samples/sec   Loss 2.5086 target_logit_mean 0.0033 lma 0.6861  cos_theta_tmp 0.7738  Epoch: 5   Global Step: 85150   Required: 31 hours
Training: 2025-12-01 04:56:13,964-Speed 1096.84 samples/sec   Loss 2.5206 target_logit_mean -0.0001 lma 0.6737  cos_theta_tmp 0.7599  Epoch: 5   Global Step: 85200   Required: 31 hours
Training: 2025-12-01 04:56:31,458-Speed 1097.57 samples/sec   Loss 2.4725 target_logit_mean 0.0003 lma 0.6814  cos_theta_tmp 0.7585  Epoch: 5   Global Step: 85250   Required: 31 hours
Training: 2025-12-01 04:56:49,003-Speed 1094.38 samples/sec   Loss 2.4211 target_logit_mean 0.0016 lma 0.6816  cos_theta_tmp 0.7677  Epoch: 5   Global Step: 85300   Required: 31 hours
Training: 2025-12-01 04:57:06,493-Speed 1097.81 samples/sec   Loss 2.4608 target_logit_mean -0.0002 lma 0.6823  cos_theta_tmp 0.7636  Epoch: 5   Global Step: 85350   Required: 31 hours
Training: 2025-12-01 04:57:24,025-Speed 1095.20 samples/sec   Loss 2.4673 target_logit_mean 0.0016 lma 0.6868  cos_theta_tmp 0.7646  Epoch: 5   Global Step: 85400   Required: 31 hours
Training: 2025-12-01 04:57:41,512-Speed 1098.00 samples/sec   Loss 2.4679 target_logit_mean 0.0016 lma 0.6897  cos_theta_tmp 0.7578  Epoch: 5   Global Step: 85450   Required: 31 hours
Training: 2025-12-01 04:57:58,952-Speed 1100.95 samples/sec   Loss 2.4565 target_logit_mean -0.0011 lma 0.6889  cos_theta_tmp 0.7635  Epoch: 5   Global Step: 85500   Required: 31 hours
Training: 2025-12-01 04:58:16,404-Speed 1100.18 samples/sec   Loss 2.4293 target_logit_mean 0.0017 lma 0.6937  cos_theta_tmp 0.7657  Epoch: 5   Global Step: 85550   Required: 31 hours
Training: 2025-12-01 04:58:33,841-Speed 1101.16 samples/sec   Loss 2.4521 target_logit_mean 0.0017 lma 0.6754  cos_theta_tmp 0.7649  Epoch: 5   Global Step: 85600   Required: 31 hours
Training: 2025-12-01 04:58:51,307-Speed 1099.35 samples/sec   Loss 2.4715 target_logit_mean -0.0009 lma 0.6856  cos_theta_tmp 0.7617  Epoch: 5   Global Step: 85650   Required: 31 hours
Training: 2025-12-01 04:59:08,771-Speed 1099.42 samples/sec   Loss 2.5062 target_logit_mean 0.0015 lma 0.6797  cos_theta_tmp 0.7646  Epoch: 5   Global Step: 85700   Required: 31 hours
Training: 2025-12-01 04:59:26,261-Speed 1097.83 samples/sec   Loss 2.4343 target_logit_mean -0.0025 lma 0.6769  cos_theta_tmp 0.7601  Epoch: 5   Global Step: 85750   Required: 31 hours
Training: 2025-12-01 04:59:43,678-Speed 1102.39 samples/sec   Loss 2.5323 target_logit_mean 0.0024 lma 0.6914  cos_theta_tmp 0.7632  Epoch: 5   Global Step: 85800   Required: 31 hours
Training: 2025-12-01 05:00:01,199-Speed 1095.90 samples/sec   Loss 2.5198 target_logit_mean -0.0008 lma 0.6836  cos_theta_tmp 0.7593  Epoch: 5   Global Step: 85850   Required: 31 hours
Training: 2025-12-01 05:00:18,690-Speed 1097.75 samples/sec   Loss 2.5208 target_logit_mean 0.0016 lma 0.6839  cos_theta_tmp 0.7631  Epoch: 5   Global Step: 85900   Required: 31 hours
Training: 2025-12-01 05:00:36,125-Speed 1101.28 samples/sec   Loss 2.5016 target_logit_mean 0.0014 lma 0.6819  cos_theta_tmp 0.7610  Epoch: 5   Global Step: 85950   Required: 31 hours
Training: 2025-12-01 05:00:53,577-Speed 1100.16 samples/sec   Loss 2.4784 target_logit_mean -0.0010 lma 0.6601  cos_theta_tmp 0.7534  Epoch: 5   Global Step: 86000   Required: 31 hours
Training: 2025-12-01 05:01:11,030-Speed 1100.17 samples/sec   Loss 2.5333 target_logit_mean 0.0007 lma 0.6812  cos_theta_tmp 0.7621  Epoch: 5   Global Step: 86050   Required: 31 hours
Training: 2025-12-01 05:01:28,704-Speed 1086.36 samples/sec   Loss 2.4820 target_logit_mean 0.0009 lma 0.6796  cos_theta_tmp 0.7602  Epoch: 5   Global Step: 86100   Required: 31 hours
Training: 2025-12-01 05:01:46,412-Speed 1084.28 samples/sec   Loss 2.4556 target_logit_mean 0.0024 lma 0.6896  cos_theta_tmp 0.7674  Epoch: 5   Global Step: 86150   Required: 31 hours
Training: 2025-12-01 05:02:03,903-Speed 1097.76 samples/sec   Loss 2.4593 target_logit_mean 0.0006 lma 0.6821  cos_theta_tmp 0.7629  Epoch: 5   Global Step: 86200   Required: 31 hours
Training: 2025-12-01 05:02:21,403-Speed 1097.17 samples/sec   Loss 2.4543 target_logit_mean 0.0009 lma 0.6933  cos_theta_tmp 0.7570  Epoch: 5   Global Step: 86250   Required: 31 hours
Training: 2025-12-01 05:02:38,857-Speed 1100.06 samples/sec   Loss 2.4356 target_logit_mean 0.0010 lma 0.6818  cos_theta_tmp 0.7590  Epoch: 5   Global Step: 86300   Required: 31 hours
Training: 2025-12-01 05:02:56,263-Speed 1103.10 samples/sec   Loss 2.4560 target_logit_mean 0.0010 lma 0.6834  cos_theta_tmp 0.7634  Epoch: 5   Global Step: 86350   Required: 31 hours
Training: 2025-12-01 05:03:13,662-Speed 1103.53 samples/sec   Loss 2.4731 target_logit_mean -0.0014 lma 0.6850  cos_theta_tmp 0.7548  Epoch: 5   Global Step: 86400   Required: 31 hours
Training: 2025-12-01 05:03:31,261-Speed 1091.01 samples/sec   Loss 2.4630 target_logit_mean 0.0025 lma 0.6800  cos_theta_tmp 0.7608  Epoch: 5   Global Step: 86450   Required: 31 hours
Training: 2025-12-01 05:03:48,766-Speed 1096.90 samples/sec   Loss 2.4554 target_logit_mean 0.0011 lma 0.6897  cos_theta_tmp 0.7590  Epoch: 5   Global Step: 86500   Required: 31 hours
Training: 2025-12-01 05:04:06,233-Speed 1099.27 samples/sec   Loss 2.4798 target_logit_mean 0.0009 lma 0.6768  cos_theta_tmp 0.7596  Epoch: 5   Global Step: 86550   Required: 31 hours
Training: 2025-12-01 05:04:23,605-Speed 1105.23 samples/sec   Loss 2.3909 target_logit_mean -0.0027 lma 0.6800  cos_theta_tmp 0.7583  Epoch: 5   Global Step: 86600   Required: 31 hours
Training: 2025-12-01 05:04:41,013-Speed 1103.01 samples/sec   Loss 2.4927 target_logit_mean 0.0009 lma 0.6843  cos_theta_tmp 0.7582  Epoch: 5   Global Step: 86650   Required: 31 hours
Training: 2025-12-01 05:04:58,534-Speed 1095.82 samples/sec   Loss 2.4828 target_logit_mean 0.0008 lma 0.6868  cos_theta_tmp 0.7663  Epoch: 5   Global Step: 86700   Required: 31 hours
Training: 2025-12-01 05:05:16,009-Speed 1098.76 samples/sec   Loss 2.5428 target_logit_mean -0.0013 lma 0.6857  cos_theta_tmp 0.7665  Epoch: 5   Global Step: 86750   Required: 31 hours
Training: 2025-12-01 05:05:33,430-Speed 1102.15 samples/sec   Loss 2.4204 target_logit_mean 0.0002 lma 0.6864  cos_theta_tmp 0.7644  Epoch: 5   Global Step: 86800   Required: 31 hours
Training: 2025-12-01 05:05:50,866-Speed 1101.22 samples/sec   Loss 2.4467 target_logit_mean 0.0016 lma 0.6871  cos_theta_tmp 0.7673  Epoch: 5   Global Step: 86850   Required: 31 hours
Training: 2025-12-01 05:06:08,463-Speed 1091.17 samples/sec   Loss 2.5000 target_logit_mean 0.0002 lma 0.6820  cos_theta_tmp 0.7625  Epoch: 5   Global Step: 86900   Required: 31 hours
Training: 2025-12-01 05:06:25,952-Speed 1097.86 samples/sec   Loss 2.4708 target_logit_mean 0.0004 lma 0.6918  cos_theta_tmp 0.7597  Epoch: 5   Global Step: 86950   Required: 31 hours
Training: 2025-12-01 05:06:43,596-Speed 1088.22 samples/sec   Loss 2.5511 target_logit_mean 0.0011 lma 0.6879  cos_theta_tmp 0.7574  Epoch: 5   Global Step: 87000   Required: 31 hours
Training: 2025-12-01 05:07:01,204-Speed 1090.43 samples/sec   Loss 2.4641 target_logit_mean 0.0027 lma 0.6782  cos_theta_tmp 0.7649  Epoch: 5   Global Step: 87050   Required: 31 hours
Training: 2025-12-01 05:07:18,725-Speed 1095.87 samples/sec   Loss 2.5114 target_logit_mean -0.0001 lma 0.6984  cos_theta_tmp 0.7658  Epoch: 5   Global Step: 87100   Required: 31 hours
Training: 2025-12-01 05:07:36,312-Speed 1091.77 samples/sec   Loss 2.4620 target_logit_mean -0.0014 lma 0.6842  cos_theta_tmp 0.7622  Epoch: 5   Global Step: 87150   Required: 31 hours
Training: 2025-12-01 05:07:53,811-Speed 1097.24 samples/sec   Loss 2.4894 target_logit_mean 0.0014 lma 0.6845  cos_theta_tmp 0.7621  Epoch: 5   Global Step: 87200   Required: 31 hours
Training: 2025-12-01 05:08:11,240-Speed 1101.66 samples/sec   Loss 2.4912 target_logit_mean 0.0001 lma 0.6831  cos_theta_tmp 0.7631  Epoch: 5   Global Step: 87250   Required: 31 hours
Training: 2025-12-01 05:08:28,655-Speed 1102.57 samples/sec   Loss 2.5112 target_logit_mean -0.0001 lma 0.6881  cos_theta_tmp 0.7564  Epoch: 5   Global Step: 87300   Required: 31 hours
Training: 2025-12-01 05:08:46,084-Speed 1101.65 samples/sec   Loss 2.4272 target_logit_mean 0.0007 lma 0.6694  cos_theta_tmp 0.7642  Epoch: 5   Global Step: 87350   Required: 31 hours
Training: 2025-12-01 05:09:03,494-Speed 1102.88 samples/sec   Loss 2.4384 target_logit_mean -0.0016 lma 0.6802  cos_theta_tmp 0.7636  Epoch: 5   Global Step: 87400   Required: 31 hours
Training: 2025-12-01 05:09:20,921-Speed 1101.76 samples/sec   Loss 2.4532 target_logit_mean 0.0001 lma 0.6773  cos_theta_tmp 0.7623  Epoch: 5   Global Step: 87450   Required: 31 hours
Training: 2025-12-01 05:09:38,337-Speed 1102.44 samples/sec   Loss 2.4427 target_logit_mean 0.0014 lma 0.6859  cos_theta_tmp 0.7525  Epoch: 5   Global Step: 87500   Required: 31 hours
Training: 2025-12-01 05:09:55,767-Speed 1101.62 samples/sec   Loss 2.4522 target_logit_mean 0.0012 lma 0.6949  cos_theta_tmp 0.7663  Epoch: 5   Global Step: 87550   Required: 31 hours
Training: 2025-12-01 05:10:13,196-Speed 1101.60 samples/sec   Loss 2.3583 target_logit_mean 0.0001 lma 0.6835  cos_theta_tmp 0.7612  Epoch: 5   Global Step: 87600   Required: 31 hours
Training: 2025-12-01 05:10:30,610-Speed 1102.59 samples/sec   Loss 2.4648 target_logit_mean -0.0014 lma 0.6680  cos_theta_tmp 0.7544  Epoch: 5   Global Step: 87650   Required: 31 hours
Training: 2025-12-01 05:10:48,041-Speed 1101.58 samples/sec   Loss 2.4440 target_logit_mean -0.0017 lma 0.6845  cos_theta_tmp 0.7587  Epoch: 5   Global Step: 87700   Required: 31 hours
Training: 2025-12-01 05:11:05,453-Speed 1102.69 samples/sec   Loss 2.4629 target_logit_mean 0.0012 lma 0.6745  cos_theta_tmp 0.7564  Epoch: 5   Global Step: 87750   Required: 31 hours
Training: 2025-12-01 05:11:22,880-Speed 1101.75 samples/sec   Loss 2.4598 target_logit_mean -0.0000 lma 0.6828  cos_theta_tmp 0.7570  Epoch: 5   Global Step: 87800   Required: 31 hours
Training: 2025-12-01 05:11:40,310-Speed 1101.62 samples/sec   Loss 2.4930 target_logit_mean -0.0018 lma 0.6831  cos_theta_tmp 0.7638  Epoch: 5   Global Step: 87850   Required: 31 hours
Training: 2025-12-01 05:11:57,725-Speed 1102.54 samples/sec   Loss 2.4499 target_logit_mean -0.0005 lma 0.6940  cos_theta_tmp 0.7670  Epoch: 5   Global Step: 87900   Required: 31 hours
Training: 2025-12-01 05:12:15,152-Speed 1101.77 samples/sec   Loss 2.5081 target_logit_mean -0.0011 lma 0.6848  cos_theta_tmp 0.7590  Epoch: 5   Global Step: 87950   Required: 31 hours
Training: 2025-12-01 05:12:32,563-Speed 1102.80 samples/sec   Loss 2.4287 target_logit_mean 0.0025 lma 0.6982  cos_theta_tmp 0.7666  Epoch: 5   Global Step: 88000   Required: 31 hours
Training: 2025-12-01 05:12:49,988-Speed 1101.90 samples/sec   Loss 2.3856 target_logit_mean 0.0010 lma 0.6720  cos_theta_tmp 0.7551  Epoch: 5   Global Step: 88050   Required: 31 hours
Training: 2025-12-01 05:13:07,408-Speed 1102.19 samples/sec   Loss 2.4598 target_logit_mean -0.0023 lma 0.6764  cos_theta_tmp 0.7589  Epoch: 5   Global Step: 88100   Required: 31 hours
Training: 2025-12-01 05:13:24,841-Speed 1101.37 samples/sec   Loss 2.4876 target_logit_mean -0.0032 lma 0.6730  cos_theta_tmp 0.7542  Epoch: 5   Global Step: 88150   Required: 31 hours
Training: 2025-12-01 05:13:42,268-Speed 1101.79 samples/sec   Loss 2.4699 target_logit_mean 0.0000 lma 0.6766  cos_theta_tmp 0.7616  Epoch: 5   Global Step: 88200   Required: 31 hours
Training: 2025-12-01 05:13:59,682-Speed 1102.61 samples/sec   Loss 2.4679 target_logit_mean -0.0008 lma 0.6816  cos_theta_tmp 0.7627  Epoch: 5   Global Step: 88250   Required: 31 hours
Training: 2025-12-01 05:14:17,110-Speed 1101.70 samples/sec   Loss 2.4099 target_logit_mean -0.0018 lma 0.6820  cos_theta_tmp 0.7618  Epoch: 5   Global Step: 88300   Required: 31 hours
Training: 2025-12-01 05:14:34,525-Speed 1102.56 samples/sec   Loss 2.4333 target_logit_mean -0.0006 lma 0.6868  cos_theta_tmp 0.7611  Epoch: 5   Global Step: 88350   Required: 31 hours
Training: 2025-12-01 05:14:51,965-Speed 1100.95 samples/sec   Loss 2.4560 target_logit_mean -0.0002 lma 0.6923  cos_theta_tmp 0.7609  Epoch: 5   Global Step: 88400   Required: 31 hours
Training: 2025-12-01 05:15:09,374-Speed 1102.89 samples/sec   Loss 2.4555 target_logit_mean -0.0012 lma 0.6729  cos_theta_tmp 0.7587  Epoch: 5   Global Step: 88450   Required: 31 hours
Training: 2025-12-01 05:15:26,797-Speed 1102.08 samples/sec   Loss 2.4214 target_logit_mean -0.0028 lma 0.6882  cos_theta_tmp 0.7643  Epoch: 5   Global Step: 88500   Required: 31 hours
Training: 2025-12-01 05:15:44,228-Speed 1101.49 samples/sec   Loss 2.4386 target_logit_mean -0.0020 lma 0.6836  cos_theta_tmp 0.7560  Epoch: 5   Global Step: 88550   Required: 31 hours
Training: 2025-12-01 05:16:01,646-Speed 1102.39 samples/sec   Loss 2.4360 target_logit_mean 0.0002 lma 0.6816  cos_theta_tmp 0.7662  Epoch: 5   Global Step: 88600   Required: 31 hours
Training: 2025-12-01 05:16:19,073-Speed 1101.77 samples/sec   Loss 2.3643 target_logit_mean 0.0006 lma 0.6867  cos_theta_tmp 0.7720  Epoch: 5   Global Step: 88650   Required: 31 hours
Training: 2025-12-01 05:16:36,491-Speed 1102.34 samples/sec   Loss 2.4685 target_logit_mean -0.0016 lma 0.6843  cos_theta_tmp 0.7614  Epoch: 5   Global Step: 88700   Required: 31 hours
Training: 2025-12-01 05:16:53,920-Speed 1101.63 samples/sec   Loss 2.4469 target_logit_mean 0.0011 lma 0.6939  cos_theta_tmp 0.7639  Epoch: 5   Global Step: 88750   Required: 31 hours
Training: 2025-12-01 05:17:11,353-Speed 1101.41 samples/sec   Loss 2.4821 target_logit_mean 0.0025 lma 0.6850  cos_theta_tmp 0.7665  Epoch: 5   Global Step: 88800   Required: 31 hours
Training: 2025-12-01 05:17:28,763-Speed 1102.85 samples/sec   Loss 2.4444 target_logit_mean 0.0023 lma 0.6798  cos_theta_tmp 0.7620  Epoch: 5   Global Step: 88850   Required: 31 hours
Training: 2025-12-01 05:17:46,194-Speed 1101.54 samples/sec   Loss 2.4124 target_logit_mean 0.0004 lma 0.6875  cos_theta_tmp 0.7634  Epoch: 5   Global Step: 88900   Required: 31 hours
Training: 2025-12-01 05:18:03,608-Speed 1102.59 samples/sec   Loss 2.4481 target_logit_mean 0.0007 lma 0.6829  cos_theta_tmp 0.7614  Epoch: 5   Global Step: 88950   Required: 31 hours
Training: 2025-12-01 05:18:21,032-Speed 1101.94 samples/sec   Loss 2.4269 target_logit_mean -0.0001 lma 0.6743  cos_theta_tmp 0.7637  Epoch: 5   Global Step: 89000   Required: 31 hours
Training: 2025-12-01 05:18:38,446-Speed 1102.60 samples/sec   Loss 2.4524 target_logit_mean 0.0004 lma 0.6792  cos_theta_tmp 0.7632  Epoch: 5   Global Step: 89050   Required: 31 hours
Training: 2025-12-01 05:18:55,874-Speed 1101.75 samples/sec   Loss 2.5024 target_logit_mean 0.0042 lma 0.6900  cos_theta_tmp 0.7643  Epoch: 5   Global Step: 89100   Required: 31 hours
Training: 2025-12-01 05:19:13,302-Speed 1101.70 samples/sec   Loss 2.4643 target_logit_mean -0.0031 lma 0.6671  cos_theta_tmp 0.7507  Epoch: 5   Global Step: 89150   Required: 31 hours
Training: 2025-12-01 05:19:30,722-Speed 1102.22 samples/sec   Loss 2.4190 target_logit_mean -0.0009 lma 0.6800  cos_theta_tmp 0.7615  Epoch: 5   Global Step: 89200   Required: 31 hours
Training: 2025-12-01 05:19:48,148-Speed 1101.81 samples/sec   Loss 2.4729 target_logit_mean -0.0022 lma 0.6821  cos_theta_tmp 0.7580  Epoch: 5   Global Step: 89250   Required: 31 hours
Training: 2025-12-01 05:20:05,565-Speed 1102.44 samples/sec   Loss 2.4246 target_logit_mean 0.0012 lma 0.6894  cos_theta_tmp 0.7623  Epoch: 5   Global Step: 89300   Required: 31 hours
Training: 2025-12-01 05:20:22,993-Speed 1101.67 samples/sec   Loss 2.5126 target_logit_mean 0.0021 lma 0.6806  cos_theta_tmp 0.7573  Epoch: 5   Global Step: 89350   Required: 31 hours
Training: 2025-12-01 05:20:40,415-Speed 1102.10 samples/sec   Loss 2.5114 target_logit_mean -0.0028 lma 0.6872  cos_theta_tmp 0.7641  Epoch: 5   Global Step: 89400   Required: 31 hours
Training: 2025-12-01 05:20:57,829-Speed 1102.62 samples/sec   Loss 2.4858 target_logit_mean 0.0010 lma 0.6859  cos_theta_tmp 0.7652  Epoch: 5   Global Step: 89450   Required: 31 hours
Training: 2025-12-01 05:21:15,256-Speed 1101.72 samples/sec   Loss 2.4615 target_logit_mean 0.0014 lma 0.6833  cos_theta_tmp 0.7577  Epoch: 5   Global Step: 89500   Required: 31 hours
Training: 2025-12-01 05:21:32,677-Speed 1102.15 samples/sec   Loss 2.4462 target_logit_mean -0.0001 lma 0.6850  cos_theta_tmp 0.7658  Epoch: 5   Global Step: 89550   Required: 31 hours
Training: 2025-12-01 05:21:50,106-Speed 1101.67 samples/sec   Loss 2.4291 target_logit_mean 0.0019 lma 0.6879  cos_theta_tmp 0.7647  Epoch: 5   Global Step: 89600   Required: 31 hours
Training: 2025-12-01 05:22:07,520-Speed 1102.64 samples/sec   Loss 2.4390 target_logit_mean -0.0002 lma 0.6866  cos_theta_tmp 0.7576  Epoch: 5   Global Step: 89650   Required: 31 hours
Training: 2025-12-01 05:22:24,949-Speed 1101.64 samples/sec   Loss 2.4913 target_logit_mean 0.0031 lma 0.6851  cos_theta_tmp 0.7594  Epoch: 5   Global Step: 89700   Required: 31 hours
Training: 2025-12-01 05:22:42,382-Speed 1101.39 samples/sec   Loss 2.4888 target_logit_mean -0.0014 lma 0.6779  cos_theta_tmp 0.7583  Epoch: 5   Global Step: 89750   Required: 31 hours
Training: 2025-12-01 05:22:59,800-Speed 1102.32 samples/sec   Loss 2.4782 target_logit_mean 0.0007 lma 0.6662  cos_theta_tmp 0.7540  Epoch: 5   Global Step: 89800   Required: 31 hours
Training: 2025-12-01 05:23:17,226-Speed 1101.85 samples/sec   Loss 2.4687 target_logit_mean 0.0039 lma 0.6826  cos_theta_tmp 0.7651  Epoch: 5   Global Step: 89850   Required: 31 hours
Training: 2025-12-01 05:23:34,642-Speed 1102.48 samples/sec   Loss 2.4921 target_logit_mean -0.0000 lma 0.6900  cos_theta_tmp 0.7609  Epoch: 5   Global Step: 89900   Required: 31 hours
Training: 2025-12-01 05:23:52,068-Speed 1101.90 samples/sec   Loss 2.4565 target_logit_mean -0.0013 lma 0.6848  cos_theta_tmp 0.7593  Epoch: 5   Global Step: 89950   Required: 31 hours
Training: 2025-12-01 05:24:09,480-Speed 1102.67 samples/sec   Loss 2.4042 target_logit_mean -0.0009 lma 0.6850  cos_theta_tmp 0.7606  Epoch: 5   Global Step: 90000   Required: 31 hours
Training: 2025-12-01 05:24:26,908-Speed 1101.73 samples/sec   Loss 2.4214 target_logit_mean -0.0008 lma 0.6860  cos_theta_tmp 0.7630  Epoch: 5   Global Step: 90050   Required: 31 hours
Training: 2025-12-01 05:24:44,336-Speed 1101.74 samples/sec   Loss 2.4687 target_logit_mean -0.0012 lma 0.6892  cos_theta_tmp 0.7605  Epoch: 5   Global Step: 90100   Required: 31 hours
Training: 2025-12-01 05:25:01,754-Speed 1102.35 samples/sec   Loss 2.4414 target_logit_mean 0.0004 lma 0.6784  cos_theta_tmp 0.7594  Epoch: 5   Global Step: 90150   Required: 31 hours
Training: 2025-12-01 05:25:19,179-Speed 1101.91 samples/sec   Loss 2.4477 target_logit_mean 0.0001 lma 0.6783  cos_theta_tmp 0.7611  Epoch: 5   Global Step: 90200   Required: 31 hours
Training: 2025-12-01 05:25:36,593-Speed 1102.59 samples/sec   Loss 2.4797 target_logit_mean 0.0000 lma 0.6862  cos_theta_tmp 0.7617  Epoch: 5   Global Step: 90250   Required: 31 hours
Training: 2025-12-01 05:25:54,019-Speed 1101.86 samples/sec   Loss 2.4684 target_logit_mean 0.0014 lma 0.6885  cos_theta_tmp 0.7642  Epoch: 5   Global Step: 90300   Required: 31 hours
Training: 2025-12-01 05:26:11,446-Speed 1101.75 samples/sec   Loss 2.4359 target_logit_mean -0.0009 lma 0.6900  cos_theta_tmp 0.7565  Epoch: 5   Global Step: 90350   Required: 31 hours
Training: 2025-12-01 05:26:28,866-Speed 1102.28 samples/sec   Loss 2.4655 target_logit_mean 0.0001 lma 0.6853  cos_theta_tmp 0.7608  Epoch: 5   Global Step: 90400   Required: 31 hours
Training: 2025-12-01 05:26:46,292-Speed 1101.80 samples/sec   Loss 2.4585 target_logit_mean 0.0010 lma 0.6879  cos_theta_tmp 0.7629  Epoch: 5   Global Step: 90450   Required: 31 hours
Training: 2025-12-01 05:27:03,705-Speed 1102.67 samples/sec   Loss 2.5202 target_logit_mean 0.0004 lma 0.6740  cos_theta_tmp 0.7519  Epoch: 5   Global Step: 90500   Required: 31 hours
Training: 2025-12-01 05:27:21,133-Speed 1101.73 samples/sec   Loss 2.5056 target_logit_mean 0.0027 lma 0.6829  cos_theta_tmp 0.7694  Epoch: 5   Global Step: 90550   Required: 31 hours
Training: 2025-12-01 05:27:38,547-Speed 1102.62 samples/sec   Loss 2.4892 target_logit_mean -0.0003 lma 0.6891  cos_theta_tmp 0.7602  Epoch: 5   Global Step: 90600   Required: 31 hours
Training: 2025-12-01 05:27:55,979-Speed 1101.46 samples/sec   Loss 2.4801 target_logit_mean 0.0017 lma 0.6778  cos_theta_tmp 0.7593  Epoch: 5   Global Step: 90650   Required: 31 hours
Training: 2025-12-01 05:28:13,407-Speed 1101.71 samples/sec   Loss 2.5031 target_logit_mean 0.0001 lma 0.6896  cos_theta_tmp 0.7592  Epoch: 5   Global Step: 90700   Required: 31 hours
Training: 2025-12-01 05:28:30,824-Speed 1102.38 samples/sec   Loss 2.4572 target_logit_mean -0.0024 lma 0.6739  cos_theta_tmp 0.7561  Epoch: 5   Global Step: 90750   Required: 31 hours
Training: 2025-12-01 05:28:48,256-Speed 1101.50 samples/sec   Loss 2.3937 target_logit_mean -0.0006 lma 0.6724  cos_theta_tmp 0.7585  Epoch: 5   Global Step: 90800   Required: 31 hours
Training: 2025-12-01 05:29:05,674-Speed 1102.36 samples/sec   Loss 2.4397 target_logit_mean 0.0014 lma 0.6781  cos_theta_tmp 0.7597  Epoch: 5   Global Step: 90850   Required: 31 hours
Training: 2025-12-01 05:29:23,099-Speed 1101.89 samples/sec   Loss 2.5005 target_logit_mean 0.0008 lma 0.6786  cos_theta_tmp 0.7639  Epoch: 5   Global Step: 90900   Required: 31 hours
Training: 2025-12-01 05:29:40,553-Speed 1100.09 samples/sec   Loss 2.4265 target_logit_mean -0.0019 lma 0.6778  cos_theta_tmp 0.7614  Epoch: 5   Global Step: 90950   Required: 31 hours
Training: 2025-12-01 05:30:02,113-[lfw][90978]XNorm: 23.646998
Training: 2025-12-01 05:30:02,113-[lfw][90978]Accuracy-Flip: 0.99217+-0.00350
Training: 2025-12-01 05:30:02,113-[lfw][90978]Accuracy-Highest: 0.99217
Training: 2025-12-01 05:30:15,680-[cfp_fp][90978]XNorm: 19.371541
Training: 2025-12-01 05:30:15,681-[cfp_fp][90978]Accuracy-Flip: 0.88300+-0.01704
Training: 2025-12-01 05:30:15,681-[cfp_fp][90978]Accuracy-Highest: 0.88429
Training: 2025-12-01 05:30:29,087-[cfp_ff][90978]XNorm: 22.985997
Training: 2025-12-01 05:30:29,087-[cfp_ff][90978]Accuracy-Flip: 0.98986+-0.00259
Training: 2025-12-01 05:30:29,087-[cfp_ff][90978]Accuracy-Highest: 0.99043
Training: 2025-12-01 05:30:40,693-[agedb_30][90978]XNorm: 22.485974
Training: 2025-12-01 05:30:40,693-[agedb_30][90978]Accuracy-Flip: 0.93133+-0.00942
Training: 2025-12-01 05:30:40,693-[agedb_30][90978]Accuracy-Highest: 0.93133
Training: 2025-12-01 05:30:53,334-[calfw][90978]XNorm: 23.480095
Training: 2025-12-01 05:30:53,334-[calfw][90978]Accuracy-Flip: 0.93700+-0.00936
Training: 2025-12-01 05:30:53,334-[calfw][90978]Accuracy-Highest: 0.93883
Training: 2025-12-01 05:31:05,855-[cplfw][90978]XNorm: 19.558126
Training: 2025-12-01 05:31:05,855-[cplfw][90978]Accuracy-Flip: 0.85033+-0.02156
Training: 2025-12-01 05:31:05,855-[cplfw][90978]Accuracy-Highest: 0.85333
Training: 2025-12-01 05:31:16,467-[vgg2_fp][90978]XNorm: 20.064879
Training: 2025-12-01 05:31:16,467-[vgg2_fp][90978]Accuracy-Flip: 0.88200+-0.01374
Training: 2025-12-01 05:31:16,467-[vgg2_fp][90978]Accuracy-Highest: 0.88840
Training: 2025-12-01 05:31:38,602-Speed 162.64 samples/sec   Loss 2.4561 target_logit_mean 0.0000 lma 0.6883  cos_theta_tmp 0.7589  Epoch: 6   Global Step: 91000   Required: 31 hours
Training: 2025-12-01 05:31:55,972-Speed 1105.43 samples/sec   Loss 2.4254 target_logit_mean 0.0002 lma 0.7032  cos_theta_tmp 0.7608  Epoch: 6   Global Step: 91050   Required: 31 hours
Training: 2025-12-01 05:32:13,371-Speed 1103.54 samples/sec   Loss 2.3518 target_logit_mean -0.0009 lma 0.6929  cos_theta_tmp 0.7689  Epoch: 6   Global Step: 91100   Required: 31 hours
Training: 2025-12-01 05:32:30,779-Speed 1102.99 samples/sec   Loss 2.3981 target_logit_mean 0.0002 lma 0.6858  cos_theta_tmp 0.7609  Epoch: 6   Global Step: 91150   Required: 31 hours
Training: 2025-12-01 05:32:48,209-Speed 1101.58 samples/sec   Loss 2.3838 target_logit_mean 0.0021 lma 0.6974  cos_theta_tmp 0.7653  Epoch: 6   Global Step: 91200   Required: 31 hours
Training: 2025-12-01 05:33:05,628-Speed 1102.29 samples/sec   Loss 2.4391 target_logit_mean -0.0005 lma 0.6918  cos_theta_tmp 0.7622  Epoch: 6   Global Step: 91250   Required: 31 hours
Training: 2025-12-01 05:33:23,051-Speed 1102.01 samples/sec   Loss 2.4199 target_logit_mean -0.0024 lma 0.6850  cos_theta_tmp 0.7661  Epoch: 6   Global Step: 91300   Required: 31 hours
Training: 2025-12-01 05:33:40,468-Speed 1102.38 samples/sec   Loss 2.3759 target_logit_mean -0.0042 lma 0.6821  cos_theta_tmp 0.7593  Epoch: 6   Global Step: 91350   Required: 31 hours
Training: 2025-12-01 05:33:57,896-Speed 1101.76 samples/sec   Loss 2.4284 target_logit_mean -0.0013 lma 0.6917  cos_theta_tmp 0.7548  Epoch: 6   Global Step: 91400   Required: 31 hours
Training: 2025-12-01 05:34:15,326-Speed 1101.57 samples/sec   Loss 2.4621 target_logit_mean -0.0023 lma 0.6786  cos_theta_tmp 0.7580  Epoch: 6   Global Step: 91450   Required: 31 hours
Training: 2025-12-01 05:34:32,742-Speed 1102.49 samples/sec   Loss 2.4574 target_logit_mean 0.0006 lma 0.6805  cos_theta_tmp 0.7611  Epoch: 6   Global Step: 91500   Required: 31 hours
Training: 2025-12-01 05:34:50,167-Speed 1101.88 samples/sec   Loss 2.4910 target_logit_mean 0.0013 lma 0.6853  cos_theta_tmp 0.7575  Epoch: 6   Global Step: 91550   Required: 31 hours
Training: 2025-12-01 05:35:07,584-Speed 1102.45 samples/sec   Loss 2.3771 target_logit_mean 0.0012 lma 0.6849  cos_theta_tmp 0.7622  Epoch: 6   Global Step: 91600   Required: 31 hours
Training: 2025-12-01 05:35:25,014-Speed 1101.60 samples/sec   Loss 2.4335 target_logit_mean 0.0009 lma 0.6858  cos_theta_tmp 0.7605  Epoch: 6   Global Step: 91650   Required: 31 hours
Training: 2025-12-01 05:35:42,443-Speed 1101.66 samples/sec   Loss 2.4469 target_logit_mean 0.0023 lma 0.6887  cos_theta_tmp 0.7689  Epoch: 6   Global Step: 91700   Required: 31 hours
Training: 2025-12-01 05:35:59,858-Speed 1102.54 samples/sec   Loss 2.4810 target_logit_mean -0.0024 lma 0.6890  cos_theta_tmp 0.7648  Epoch: 6   Global Step: 91750   Required: 31 hours
Training: 2025-12-01 05:36:17,283-Speed 1101.90 samples/sec   Loss 2.3741 target_logit_mean 0.0000 lma 0.6828  cos_theta_tmp 0.7623  Epoch: 6   Global Step: 91800   Required: 31 hours
Training: 2025-12-01 05:36:34,698-Speed 1102.55 samples/sec   Loss 2.4545 target_logit_mean 0.0016 lma 0.6839  cos_theta_tmp 0.7650  Epoch: 6   Global Step: 91850   Required: 31 hours
Training: 2025-12-01 05:36:52,129-Speed 1101.52 samples/sec   Loss 2.4427 target_logit_mean 0.0002 lma 0.6802  cos_theta_tmp 0.7601  Epoch: 6   Global Step: 91900   Required: 31 hours
Training: 2025-12-01 05:37:09,544-Speed 1102.51 samples/sec   Loss 2.4529 target_logit_mean 0.0021 lma 0.6972  cos_theta_tmp 0.7661  Epoch: 6   Global Step: 91950   Required: 31 hours
Training: 2025-12-01 05:37:26,969-Speed 1101.92 samples/sec   Loss 2.4228 target_logit_mean 0.0017 lma 0.6857  cos_theta_tmp 0.7653  Epoch: 6   Global Step: 92000   Required: 31 hours
Training: 2025-12-01 05:37:44,395-Speed 1101.81 samples/sec   Loss 2.4223 target_logit_mean -0.0003 lma 0.6840  cos_theta_tmp 0.7642  Epoch: 6   Global Step: 92050   Required: 31 hours
Training: 2025-12-01 05:38:01,809-Speed 1102.65 samples/sec   Loss 2.4677 target_logit_mean -0.0004 lma 0.6807  cos_theta_tmp 0.7664  Epoch: 6   Global Step: 92100   Required: 31 hours
Training: 2025-12-01 05:38:19,236-Speed 1101.77 samples/sec   Loss 2.4148 target_logit_mean -0.0004 lma 0.6818  cos_theta_tmp 0.7556  Epoch: 6   Global Step: 92150   Required: 31 hours
Training: 2025-12-01 05:38:36,648-Speed 1102.74 samples/sec   Loss 2.5093 target_logit_mean 0.0003 lma 0.6754  cos_theta_tmp 0.7636  Epoch: 6   Global Step: 92200   Required: 31 hours
Training: 2025-12-01 05:38:54,077-Speed 1101.65 samples/sec   Loss 2.4259 target_logit_mean 0.0021 lma 0.6780  cos_theta_tmp 0.7569  Epoch: 6   Global Step: 92250   Required: 31 hours
Training: 2025-12-01 05:39:11,485-Speed 1102.95 samples/sec   Loss 2.4694 target_logit_mean 0.0031 lma 0.6875  cos_theta_tmp 0.7623  Epoch: 6   Global Step: 92300   Required: 31 hours
Training: 2025-12-01 05:39:28,912-Speed 1101.79 samples/sec   Loss 2.4744 target_logit_mean 0.0010 lma 0.6803  cos_theta_tmp 0.7653  Epoch: 6   Global Step: 92350   Required: 31 hours
Training: 2025-12-01 05:39:46,339-Speed 1101.78 samples/sec   Loss 2.4424 target_logit_mean 0.0020 lma 0.6856  cos_theta_tmp 0.7639  Epoch: 6   Global Step: 92400   Required: 31 hours
Training: 2025-12-01 05:40:03,754-Speed 1102.49 samples/sec   Loss 2.4261 target_logit_mean -0.0012 lma 0.6878  cos_theta_tmp 0.7637  Epoch: 6   Global Step: 92450   Required: 31 hours
Training: 2025-12-01 05:40:21,182-Speed 1101.76 samples/sec   Loss 2.4579 target_logit_mean 0.0000 lma 0.6817  cos_theta_tmp 0.7622  Epoch: 6   Global Step: 92500   Required: 31 hours
Training: 2025-12-01 05:40:38,595-Speed 1102.66 samples/sec   Loss 2.4833 target_logit_mean 0.0022 lma 0.6935  cos_theta_tmp 0.7602  Epoch: 6   Global Step: 92550   Required: 31 hours
Training: 2025-12-01 05:40:56,026-Speed 1101.50 samples/sec   Loss 2.4589 target_logit_mean 0.0000 lma 0.6838  cos_theta_tmp 0.7538  Epoch: 6   Global Step: 92600   Required: 31 hours
Training: 2025-12-01 05:41:13,447-Speed 1102.17 samples/sec   Loss 2.4662 target_logit_mean -0.0000 lma 0.6983  cos_theta_tmp 0.7612  Epoch: 6   Global Step: 92650   Required: 31 hours
Training: 2025-12-01 05:41:30,862-Speed 1102.53 samples/sec   Loss 2.4763 target_logit_mean 0.0004 lma 0.6945  cos_theta_tmp 0.7650  Epoch: 6   Global Step: 92700   Required: 31 hours
Training: 2025-12-01 05:41:48,287-Speed 1101.91 samples/sec   Loss 2.4868 target_logit_mean -0.0005 lma 0.6739  cos_theta_tmp 0.7545  Epoch: 6   Global Step: 92750   Required: 31 hours
Training: 2025-12-01 05:42:05,704-Speed 1102.43 samples/sec   Loss 2.4875 target_logit_mean -0.0016 lma 0.7007  cos_theta_tmp 0.7703  Epoch: 6   Global Step: 92800   Required: 31 hours
Training: 2025-12-01 05:42:23,130-Speed 1101.84 samples/sec   Loss 2.4596 target_logit_mean 0.0004 lma 0.6823  cos_theta_tmp 0.7589  Epoch: 6   Global Step: 92850   Required: 31 hours
Training: 2025-12-01 05:42:40,544-Speed 1102.62 samples/sec   Loss 2.4303 target_logit_mean -0.0003 lma 0.6864  cos_theta_tmp 0.7622  Epoch: 6   Global Step: 92900   Required: 31 hours
Training: 2025-12-01 05:42:57,969-Speed 1101.87 samples/sec   Loss 2.4628 target_logit_mean 0.0007 lma 0.6846  cos_theta_tmp 0.7636  Epoch: 6   Global Step: 92950   Required: 31 hours
Training: 2025-12-01 05:43:15,394-Speed 1101.90 samples/sec   Loss 2.4206 target_logit_mean -0.0017 lma 0.6760  cos_theta_tmp 0.7606  Epoch: 6   Global Step: 93000   Required: 31 hours
Training: 2025-12-01 05:43:32,807-Speed 1102.64 samples/sec   Loss 2.4598 target_logit_mean 0.0002 lma 0.6884  cos_theta_tmp 0.7598  Epoch: 6   Global Step: 93050   Required: 31 hours
Training: 2025-12-01 05:43:50,236-Speed 1101.70 samples/sec   Loss 2.4498 target_logit_mean -0.0010 lma 0.6849  cos_theta_tmp 0.7578  Epoch: 6   Global Step: 93100   Required: 31 hours
Training: 2025-12-01 05:44:07,655-Speed 1102.24 samples/sec   Loss 2.3810 target_logit_mean -0.0011 lma 0.6869  cos_theta_tmp 0.7588  Epoch: 6   Global Step: 93150   Required: 31 hours
Training: 2025-12-01 05:44:25,084-Speed 1101.64 samples/sec   Loss 2.4292 target_logit_mean 0.0011 lma 0.6954  cos_theta_tmp 0.7674  Epoch: 6   Global Step: 93200   Required: 31 hours
Training: 2025-12-01 05:44:42,512-Speed 1101.74 samples/sec   Loss 2.4484 target_logit_mean 0.0002 lma 0.6898  cos_theta_tmp 0.7621  Epoch: 6   Global Step: 93250   Required: 31 hours
Training: 2025-12-01 05:44:59,927-Speed 1102.56 samples/sec   Loss 2.5087 target_logit_mean -0.0003 lma 0.6815  cos_theta_tmp 0.7580  Epoch: 6   Global Step: 93300   Required: 31 hours
Training: 2025-12-01 05:45:17,353-Speed 1101.85 samples/sec   Loss 2.4360 target_logit_mean -0.0003 lma 0.6759  cos_theta_tmp 0.7598  Epoch: 6   Global Step: 93350   Required: 31 hours
Training: 2025-12-01 05:45:34,765-Speed 1102.71 samples/sec   Loss 2.4742 target_logit_mean 0.0013 lma 0.6951  cos_theta_tmp 0.7673  Epoch: 6   Global Step: 93400   Required: 31 hours
Training: 2025-12-01 05:45:52,189-Speed 1102.01 samples/sec   Loss 2.4091 target_logit_mean 0.0013 lma 0.6842  cos_theta_tmp 0.7672  Epoch: 6   Global Step: 93450   Required: 31 hours
Training: 2025-12-01 05:46:09,602-Speed 1102.64 samples/sec   Loss 2.4540 target_logit_mean 0.0015 lma 0.6778  cos_theta_tmp 0.7689  Epoch: 6   Global Step: 93500   Required: 31 hours
Training: 2025-12-01 05:46:27,033-Speed 1101.52 samples/sec   Loss 2.4532 target_logit_mean 0.0013 lma 0.6860  cos_theta_tmp 0.7535  Epoch: 6   Global Step: 93550   Required: 31 hours
Training: 2025-12-01 05:46:44,457-Speed 1101.95 samples/sec   Loss 2.4751 target_logit_mean 0.0037 lma 0.6854  cos_theta_tmp 0.7635  Epoch: 6   Global Step: 93600   Required: 31 hours
Training: 2025-12-01 05:47:01,867-Speed 1102.85 samples/sec   Loss 2.4436 target_logit_mean -0.0012 lma 0.6885  cos_theta_tmp 0.7677  Epoch: 6   Global Step: 93650   Required: 31 hours
Training: 2025-12-01 05:47:19,290-Speed 1102.07 samples/sec   Loss 2.4918 target_logit_mean 0.0007 lma 0.6756  cos_theta_tmp 0.7670  Epoch: 6   Global Step: 93700   Required: 31 hours
Training: 2025-12-01 05:47:36,703-Speed 1102.67 samples/sec   Loss 2.4543 target_logit_mean -0.0014 lma 0.6828  cos_theta_tmp 0.7698  Epoch: 6   Global Step: 93750   Required: 31 hours
Training: 2025-12-01 05:47:54,128-Speed 1101.90 samples/sec   Loss 2.4036 target_logit_mean 0.0017 lma 0.6790  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 93800   Required: 30 hours
Training: 2025-12-01 05:48:11,545-Speed 1102.40 samples/sec   Loss 2.4595 target_logit_mean 0.0001 lma 0.6949  cos_theta_tmp 0.7640  Epoch: 6   Global Step: 93850   Required: 30 hours
Training: 2025-12-01 05:48:28,974-Speed 1101.68 samples/sec   Loss 2.4960 target_logit_mean -0.0000 lma 0.6795  cos_theta_tmp 0.7607  Epoch: 6   Global Step: 93900   Required: 30 hours
Training: 2025-12-01 05:48:46,397-Speed 1102.01 samples/sec   Loss 2.4318 target_logit_mean -0.0012 lma 0.6805  cos_theta_tmp 0.7629  Epoch: 6   Global Step: 93950   Required: 30 hours
Training: 2025-12-01 05:49:03,810-Speed 1102.69 samples/sec   Loss 2.4551 target_logit_mean -0.0001 lma 0.6868  cos_theta_tmp 0.7588  Epoch: 6   Global Step: 94000   Required: 30 hours
Training: 2025-12-01 05:49:21,237-Speed 1101.77 samples/sec   Loss 2.4583 target_logit_mean -0.0016 lma 0.6651  cos_theta_tmp 0.7547  Epoch: 6   Global Step: 94050   Required: 30 hours
Training: 2025-12-01 05:49:38,648-Speed 1102.80 samples/sec   Loss 2.4315 target_logit_mean 0.0004 lma 0.6901  cos_theta_tmp 0.7670  Epoch: 6   Global Step: 94100   Required: 30 hours
Training: 2025-12-01 05:49:56,075-Speed 1101.72 samples/sec   Loss 2.4893 target_logit_mean 0.0011 lma 0.6785  cos_theta_tmp 0.7627  Epoch: 6   Global Step: 94150   Required: 30 hours
Training: 2025-12-01 05:50:13,503-Speed 1101.75 samples/sec   Loss 2.3921 target_logit_mean -0.0021 lma 0.6738  cos_theta_tmp 0.7623  Epoch: 6   Global Step: 94200   Required: 30 hours
Training: 2025-12-01 05:50:30,917-Speed 1102.57 samples/sec   Loss 2.4233 target_logit_mean 0.0022 lma 0.6799  cos_theta_tmp 0.7639  Epoch: 6   Global Step: 94250   Required: 30 hours
Training: 2025-12-01 05:50:48,341-Speed 1101.98 samples/sec   Loss 2.4713 target_logit_mean 0.0017 lma 0.6902  cos_theta_tmp 0.7605  Epoch: 6   Global Step: 94300   Required: 30 hours
Training: 2025-12-01 05:51:05,750-Speed 1102.91 samples/sec   Loss 2.3774 target_logit_mean 0.0011 lma 0.6911  cos_theta_tmp 0.7613  Epoch: 6   Global Step: 94350   Required: 30 hours
Training: 2025-12-01 05:51:23,171-Speed 1102.20 samples/sec   Loss 2.4246 target_logit_mean -0.0008 lma 0.6933  cos_theta_tmp 0.7688  Epoch: 6   Global Step: 94400   Required: 30 hours
Training: 2025-12-01 05:51:40,579-Speed 1102.98 samples/sec   Loss 2.4624 target_logit_mean 0.0015 lma 0.6835  cos_theta_tmp 0.7650  Epoch: 6   Global Step: 94450   Required: 30 hours
Training: 2025-12-01 05:51:58,004-Speed 1101.86 samples/sec   Loss 2.4771 target_logit_mean 0.0003 lma 0.6726  cos_theta_tmp 0.7647  Epoch: 6   Global Step: 94500   Required: 30 hours
Training: 2025-12-01 05:52:15,430-Speed 1101.90 samples/sec   Loss 2.4380 target_logit_mean 0.0020 lma 0.6973  cos_theta_tmp 0.7667  Epoch: 6   Global Step: 94550   Required: 30 hours
Training: 2025-12-01 05:52:32,845-Speed 1102.54 samples/sec   Loss 2.4565 target_logit_mean -0.0031 lma 0.6864  cos_theta_tmp 0.7551  Epoch: 6   Global Step: 94600   Required: 30 hours
Training: 2025-12-01 05:52:50,273-Speed 1101.72 samples/sec   Loss 2.4244 target_logit_mean 0.0018 lma 0.6844  cos_theta_tmp 0.7613  Epoch: 6   Global Step: 94650   Required: 30 hours
Training: 2025-12-01 05:53:07,682-Speed 1102.90 samples/sec   Loss 2.3614 target_logit_mean 0.0015 lma 0.6849  cos_theta_tmp 0.7662  Epoch: 6   Global Step: 94700   Required: 30 hours
Training: 2025-12-01 05:53:25,105-Speed 1102.03 samples/sec   Loss 2.4056 target_logit_mean 0.0006 lma 0.6923  cos_theta_tmp 0.7628  Epoch: 6   Global Step: 94750   Required: 30 hours
Training: 2025-12-01 05:53:42,516-Speed 1102.75 samples/sec   Loss 2.3945 target_logit_mean -0.0011 lma 0.6919  cos_theta_tmp 0.7628  Epoch: 6   Global Step: 94800   Required: 30 hours
Training: 2025-12-01 05:53:59,944-Speed 1101.77 samples/sec   Loss 2.4214 target_logit_mean -0.0014 lma 0.6983  cos_theta_tmp 0.7655  Epoch: 6   Global Step: 94850   Required: 30 hours
Training: 2025-12-01 05:54:17,368-Speed 1101.93 samples/sec   Loss 2.4620 target_logit_mean -0.0019 lma 0.6737  cos_theta_tmp 0.7609  Epoch: 6   Global Step: 94900   Required: 30 hours
Training: 2025-12-01 05:54:34,780-Speed 1102.72 samples/sec   Loss 2.4981 target_logit_mean 0.0014 lma 0.6879  cos_theta_tmp 0.7616  Epoch: 6   Global Step: 94950   Required: 30 hours
Training: 2025-12-01 05:54:52,215-Speed 1101.31 samples/sec   Loss 2.5380 target_logit_mean -0.0024 lma 0.6748  cos_theta_tmp 0.7612  Epoch: 6   Global Step: 95000   Required: 30 hours
Training: 2025-12-01 05:55:09,629-Speed 1102.59 samples/sec   Loss 2.4750 target_logit_mean 0.0008 lma 0.6801  cos_theta_tmp 0.7656  Epoch: 6   Global Step: 95050   Required: 30 hours
Training: 2025-12-01 05:55:27,055-Speed 1101.88 samples/sec   Loss 2.4319 target_logit_mean -0.0002 lma 0.6856  cos_theta_tmp 0.7590  Epoch: 6   Global Step: 95100   Required: 30 hours
Training: 2025-12-01 05:55:44,477-Speed 1102.09 samples/sec   Loss 2.4560 target_logit_mean 0.0024 lma 0.6808  cos_theta_tmp 0.7634  Epoch: 6   Global Step: 95150   Required: 30 hours
Training: 2025-12-01 05:56:01,893-Speed 1102.48 samples/sec   Loss 2.4249 target_logit_mean -0.0002 lma 0.6886  cos_theta_tmp 0.7630  Epoch: 6   Global Step: 95200   Required: 30 hours
Training: 2025-12-01 05:56:19,316-Speed 1101.98 samples/sec   Loss 2.3506 target_logit_mean -0.0006 lma 0.6743  cos_theta_tmp 0.7639  Epoch: 6   Global Step: 95250   Required: 30 hours
Training: 2025-12-01 05:56:36,734-Speed 1102.40 samples/sec   Loss 2.4289 target_logit_mean -0.0019 lma 0.6866  cos_theta_tmp 0.7652  Epoch: 6   Global Step: 95300   Required: 30 hours
Training: 2025-12-01 05:56:54,162-Speed 1101.69 samples/sec   Loss 2.4295 target_logit_mean -0.0002 lma 0.6781  cos_theta_tmp 0.7628  Epoch: 6   Global Step: 95350   Required: 30 hours
Training: 2025-12-01 05:57:11,580-Speed 1102.36 samples/sec   Loss 2.4536 target_logit_mean -0.0022 lma 0.6865  cos_theta_tmp 0.7565  Epoch: 6   Global Step: 95400   Required: 30 hours
Training: 2025-12-01 05:57:29,010-Speed 1101.60 samples/sec   Loss 2.4616 target_logit_mean -0.0014 lma 0.6869  cos_theta_tmp 0.7609  Epoch: 6   Global Step: 95450   Required: 30 hours
Training: 2025-12-01 05:57:46,442-Speed 1101.45 samples/sec   Loss 2.4602 target_logit_mean 0.0038 lma 0.6855  cos_theta_tmp 0.7664  Epoch: 6   Global Step: 95500   Required: 30 hours
Training: 2025-12-01 05:58:03,852-Speed 1102.82 samples/sec   Loss 2.4760 target_logit_mean 0.0002 lma 0.6816  cos_theta_tmp 0.7618  Epoch: 6   Global Step: 95550   Required: 30 hours
Training: 2025-12-01 05:58:21,281-Speed 1101.66 samples/sec   Loss 2.4688 target_logit_mean 0.0028 lma 0.6971  cos_theta_tmp 0.7649  Epoch: 6   Global Step: 95600   Required: 30 hours
Training: 2025-12-01 05:58:38,698-Speed 1102.36 samples/sec   Loss 2.4511 target_logit_mean 0.0007 lma 0.6956  cos_theta_tmp 0.7606  Epoch: 6   Global Step: 95650   Required: 30 hours
Training: 2025-12-01 05:58:56,125-Speed 1101.80 samples/sec   Loss 2.4677 target_logit_mean -0.0020 lma 0.6793  cos_theta_tmp 0.7619  Epoch: 6   Global Step: 95700   Required: 30 hours
Training: 2025-12-01 05:59:13,539-Speed 1102.61 samples/sec   Loss 2.3982 target_logit_mean -0.0015 lma 0.6811  cos_theta_tmp 0.7567  Epoch: 6   Global Step: 95750   Required: 30 hours
Training: 2025-12-01 05:59:30,967-Speed 1101.70 samples/sec   Loss 2.4198 target_logit_mean -0.0000 lma 0.6805  cos_theta_tmp 0.7604  Epoch: 6   Global Step: 95800   Required: 30 hours
Training: 2025-12-01 05:59:48,399-Speed 1101.48 samples/sec   Loss 2.4206 target_logit_mean 0.0027 lma 0.6863  cos_theta_tmp 0.7699  Epoch: 6   Global Step: 95850   Required: 30 hours
Training: 2025-12-01 06:00:05,815-Speed 1102.44 samples/sec   Loss 2.4653 target_logit_mean 0.0004 lma 0.6862  cos_theta_tmp 0.7598  Epoch: 6   Global Step: 95900   Required: 30 hours
Training: 2025-12-01 06:00:23,244-Speed 1101.70 samples/sec   Loss 2.4351 target_logit_mean 0.0002 lma 0.6873  cos_theta_tmp 0.7591  Epoch: 6   Global Step: 95950   Required: 30 hours
Training: 2025-12-01 06:00:40,662-Speed 1102.34 samples/sec   Loss 2.4388 target_logit_mean -0.0004 lma 0.6804  cos_theta_tmp 0.7652  Epoch: 6   Global Step: 96000   Required: 30 hours
Training: 2025-12-01 06:00:58,091-Speed 1101.62 samples/sec   Loss 2.4425 target_logit_mean 0.0007 lma 0.6950  cos_theta_tmp 0.7631  Epoch: 6   Global Step: 96050   Required: 30 hours
Training: 2025-12-01 06:01:15,521-Speed 1101.61 samples/sec   Loss 2.4852 target_logit_mean 0.0021 lma 0.6884  cos_theta_tmp 0.7609  Epoch: 6   Global Step: 96100   Required: 30 hours
Training: 2025-12-01 06:01:32,930-Speed 1102.91 samples/sec   Loss 2.4181 target_logit_mean -0.0028 lma 0.6849  cos_theta_tmp 0.7598  Epoch: 6   Global Step: 96150   Required: 30 hours
Training: 2025-12-01 06:01:50,357-Speed 1101.77 samples/sec   Loss 2.5049 target_logit_mean -0.0007 lma 0.6863  cos_theta_tmp 0.7620  Epoch: 6   Global Step: 96200   Required: 30 hours
Training: 2025-12-01 06:02:07,769-Speed 1102.72 samples/sec   Loss 2.4637 target_logit_mean -0.0022 lma 0.6798  cos_theta_tmp 0.7569  Epoch: 6   Global Step: 96250   Required: 30 hours
Training: 2025-12-01 06:02:25,193-Speed 1101.97 samples/sec   Loss 2.4694 target_logit_mean -0.0024 lma 0.6842  cos_theta_tmp 0.7587  Epoch: 6   Global Step: 96300   Required: 30 hours
Training: 2025-12-01 06:02:42,609-Speed 1102.44 samples/sec   Loss 2.4256 target_logit_mean -0.0008 lma 0.6942  cos_theta_tmp 0.7624  Epoch: 6   Global Step: 96350   Required: 30 hours
Training: 2025-12-01 06:03:00,036-Speed 1101.77 samples/sec   Loss 2.4657 target_logit_mean -0.0002 lma 0.6873  cos_theta_tmp 0.7580  Epoch: 6   Global Step: 96400   Required: 30 hours
Training: 2025-12-01 06:03:17,469-Speed 1101.45 samples/sec   Loss 2.4423 target_logit_mean -0.0007 lma 0.6938  cos_theta_tmp 0.7636  Epoch: 6   Global Step: 96450   Required: 30 hours
Training: 2025-12-01 06:03:34,885-Speed 1102.46 samples/sec   Loss 2.4336 target_logit_mean 0.0014 lma 0.6872  cos_theta_tmp 0.7677  Epoch: 6   Global Step: 96500   Required: 30 hours
Training: 2025-12-01 06:03:52,310-Speed 1101.93 samples/sec   Loss 2.3936 target_logit_mean 0.0012 lma 0.6819  cos_theta_tmp 0.7690  Epoch: 6   Global Step: 96550   Required: 30 hours
Training: 2025-12-01 06:04:09,721-Speed 1102.77 samples/sec   Loss 2.4687 target_logit_mean 0.0020 lma 0.6850  cos_theta_tmp 0.7649  Epoch: 6   Global Step: 96600   Required: 30 hours
Training: 2025-12-01 06:04:27,150-Speed 1101.64 samples/sec   Loss 2.4280 target_logit_mean 0.0006 lma 0.6840  cos_theta_tmp 0.7658  Epoch: 6   Global Step: 96650   Required: 30 hours
Training: 2025-12-01 06:04:44,560-Speed 1102.89 samples/sec   Loss 2.4536 target_logit_mean 0.0003 lma 0.6916  cos_theta_tmp 0.7619  Epoch: 6   Global Step: 96700   Required: 30 hours
Training: 2025-12-01 06:05:01,988-Speed 1101.70 samples/sec   Loss 2.4704 target_logit_mean 0.0009 lma 0.6898  cos_theta_tmp 0.7657  Epoch: 6   Global Step: 96750   Required: 30 hours
Training: 2025-12-01 06:05:19,417-Speed 1101.66 samples/sec   Loss 2.4603 target_logit_mean 0.0028 lma 0.6788  cos_theta_tmp 0.7590  Epoch: 6   Global Step: 96800   Required: 30 hours
Training: 2025-12-01 06:05:36,829-Speed 1102.72 samples/sec   Loss 2.4339 target_logit_mean 0.0021 lma 0.6916  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 96850   Required: 30 hours
Training: 2025-12-01 06:05:54,259-Speed 1101.61 samples/sec   Loss 2.3975 target_logit_mean 0.0014 lma 0.6771  cos_theta_tmp 0.7592  Epoch: 6   Global Step: 96900   Required: 30 hours
Training: 2025-12-01 06:06:11,667-Speed 1102.95 samples/sec   Loss 2.3693 target_logit_mean 0.0002 lma 0.6885  cos_theta_tmp 0.7612  Epoch: 6   Global Step: 96950   Required: 30 hours
Training: 2025-12-01 06:06:29,092-Speed 1101.89 samples/sec   Loss 2.4117 target_logit_mean -0.0015 lma 0.6943  cos_theta_tmp 0.7640  Epoch: 6   Global Step: 97000   Required: 30 hours
Training: 2025-12-01 06:06:46,519-Speed 1101.78 samples/sec   Loss 2.5312 target_logit_mean 0.0002 lma 0.6788  cos_theta_tmp 0.7612  Epoch: 6   Global Step: 97050   Required: 30 hours
Training: 2025-12-01 06:07:03,933-Speed 1102.59 samples/sec   Loss 2.4415 target_logit_mean -0.0018 lma 0.6664  cos_theta_tmp 0.7569  Epoch: 6   Global Step: 97100   Required: 30 hours
Training: 2025-12-01 06:07:21,360-Speed 1101.77 samples/sec   Loss 2.4135 target_logit_mean 0.0008 lma 0.6850  cos_theta_tmp 0.7592  Epoch: 6   Global Step: 97150   Required: 30 hours
Training: 2025-12-01 06:07:38,774-Speed 1102.62 samples/sec   Loss 2.4551 target_logit_mean -0.0011 lma 0.6711  cos_theta_tmp 0.7557  Epoch: 6   Global Step: 97200   Required: 30 hours
Training: 2025-12-01 06:07:56,203-Speed 1101.69 samples/sec   Loss 2.4745 target_logit_mean -0.0012 lma 0.6835  cos_theta_tmp 0.7592  Epoch: 6   Global Step: 97250   Required: 30 hours
Training: 2025-12-01 06:08:13,617-Speed 1102.61 samples/sec   Loss 2.4486 target_logit_mean -0.0026 lma 0.6826  cos_theta_tmp 0.7598  Epoch: 6   Global Step: 97300   Required: 30 hours
Training: 2025-12-01 06:08:31,044-Speed 1101.78 samples/sec   Loss 2.3952 target_logit_mean -0.0013 lma 0.6922  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 97350   Required: 30 hours
Training: 2025-12-01 06:08:48,470-Speed 1101.83 samples/sec   Loss 2.3400 target_logit_mean 0.0004 lma 0.6808  cos_theta_tmp 0.7654  Epoch: 6   Global Step: 97400   Required: 30 hours
Training: 2025-12-01 06:09:05,879-Speed 1102.90 samples/sec   Loss 2.3886 target_logit_mean -0.0034 lma 0.6879  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 97450   Required: 30 hours
Training: 2025-12-01 06:09:23,306-Speed 1101.81 samples/sec   Loss 2.5117 target_logit_mean 0.0012 lma 0.6829  cos_theta_tmp 0.7608  Epoch: 6   Global Step: 97500   Required: 30 hours
Training: 2025-12-01 06:09:40,718-Speed 1102.68 samples/sec   Loss 2.3894 target_logit_mean -0.0023 lma 0.6706  cos_theta_tmp 0.7610  Epoch: 6   Global Step: 97550   Required: 30 hours
Training: 2025-12-01 06:09:58,143-Speed 1101.93 samples/sec   Loss 2.3857 target_logit_mean -0.0009 lma 0.6778  cos_theta_tmp 0.7643  Epoch: 6   Global Step: 97600   Required: 30 hours
Training: 2025-12-01 06:10:15,572-Speed 1101.67 samples/sec   Loss 2.4190 target_logit_mean -0.0014 lma 0.6798  cos_theta_tmp 0.7550  Epoch: 6   Global Step: 97650   Required: 30 hours
Training: 2025-12-01 06:10:32,989-Speed 1102.41 samples/sec   Loss 2.3795 target_logit_mean -0.0019 lma 0.6757  cos_theta_tmp 0.7580  Epoch: 6   Global Step: 97700   Required: 30 hours
Training: 2025-12-01 06:10:50,415-Speed 1101.83 samples/sec   Loss 2.4286 target_logit_mean -0.0011 lma 0.6659  cos_theta_tmp 0.7505  Epoch: 6   Global Step: 97750   Required: 30 hours
Training: 2025-12-01 06:11:07,829-Speed 1102.59 samples/sec   Loss 2.4624 target_logit_mean -0.0007 lma 0.6793  cos_theta_tmp 0.7602  Epoch: 6   Global Step: 97800   Required: 30 hours
Training: 2025-12-01 06:11:25,261-Speed 1101.49 samples/sec   Loss 2.4962 target_logit_mean -0.0009 lma 0.6775  cos_theta_tmp 0.7601  Epoch: 6   Global Step: 97850   Required: 30 hours
Training: 2025-12-01 06:11:42,674-Speed 1102.60 samples/sec   Loss 2.3959 target_logit_mean -0.0005 lma 0.6771  cos_theta_tmp 0.7605  Epoch: 6   Global Step: 97900   Required: 30 hours
Training: 2025-12-01 06:12:00,103-Speed 1101.71 samples/sec   Loss 2.4531 target_logit_mean -0.0009 lma 0.6871  cos_theta_tmp 0.7637  Epoch: 6   Global Step: 97950   Required: 30 hours
Training: 2025-12-01 06:12:17,529-Speed 1101.81 samples/sec   Loss 2.3981 target_logit_mean -0.0016 lma 0.6792  cos_theta_tmp 0.7663  Epoch: 6   Global Step: 98000   Required: 30 hours
Training: 2025-12-01 06:12:34,946-Speed 1102.45 samples/sec   Loss 2.4051 target_logit_mean -0.0022 lma 0.6823  cos_theta_tmp 0.7628  Epoch: 6   Global Step: 98050   Required: 30 hours
Training: 2025-12-01 06:12:52,375-Speed 1101.62 samples/sec   Loss 2.4746 target_logit_mean 0.0002 lma 0.6828  cos_theta_tmp 0.7604  Epoch: 6   Global Step: 98100   Required: 30 hours
Training: 2025-12-01 06:13:09,790-Speed 1102.55 samples/sec   Loss 2.4389 target_logit_mean -0.0020 lma 0.6915  cos_theta_tmp 0.7659  Epoch: 6   Global Step: 98150   Required: 30 hours
Training: 2025-12-01 06:13:27,224-Speed 1101.36 samples/sec   Loss 2.4087 target_logit_mean -0.0019 lma 0.6757  cos_theta_tmp 0.7553  Epoch: 6   Global Step: 98200   Required: 30 hours
Training: 2025-12-01 06:13:44,637-Speed 1102.66 samples/sec   Loss 2.4448 target_logit_mean 0.0001 lma 0.6823  cos_theta_tmp 0.7622  Epoch: 6   Global Step: 98250   Required: 30 hours
Training: 2025-12-01 06:14:02,061-Speed 1101.91 samples/sec   Loss 2.3831 target_logit_mean -0.0002 lma 0.6780  cos_theta_tmp 0.7616  Epoch: 6   Global Step: 98300   Required: 30 hours
Training: 2025-12-01 06:14:19,494-Speed 1101.41 samples/sec   Loss 2.4317 target_logit_mean 0.0016 lma 0.6898  cos_theta_tmp 0.7576  Epoch: 6   Global Step: 98350   Required: 30 hours
Training: 2025-12-01 06:14:36,907-Speed 1102.71 samples/sec   Loss 2.4365 target_logit_mean 0.0005 lma 0.6973  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 98400   Required: 30 hours
Training: 2025-12-01 06:14:54,335-Speed 1101.66 samples/sec   Loss 2.4609 target_logit_mean 0.0019 lma 0.6859  cos_theta_tmp 0.7633  Epoch: 6   Global Step: 98450   Required: 30 hours
Training: 2025-12-01 06:15:11,757-Speed 1102.13 samples/sec   Loss 2.4468 target_logit_mean 0.0038 lma 0.6680  cos_theta_tmp 0.7663  Epoch: 6   Global Step: 98500   Required: 30 hours
Training: 2025-12-01 06:15:29,192-Speed 1101.26 samples/sec   Loss 2.4319 target_logit_mean 0.0004 lma 0.6930  cos_theta_tmp 0.7659  Epoch: 6   Global Step: 98550   Required: 30 hours
Training: 2025-12-01 06:15:46,624-Speed 1101.45 samples/sec   Loss 2.4060 target_logit_mean -0.0025 lma 0.6787  cos_theta_tmp 0.7616  Epoch: 6   Global Step: 98600   Required: 30 hours
Training: 2025-12-01 06:16:04,045-Speed 1102.16 samples/sec   Loss 2.4088 target_logit_mean -0.0016 lma 0.6835  cos_theta_tmp 0.7651  Epoch: 6   Global Step: 98650   Required: 30 hours
Training: 2025-12-01 06:16:21,473-Speed 1101.72 samples/sec   Loss 2.4228 target_logit_mean -0.0020 lma 0.6721  cos_theta_tmp 0.7627  Epoch: 6   Global Step: 98700   Required: 30 hours
Training: 2025-12-01 06:16:38,887-Speed 1102.58 samples/sec   Loss 2.3893 target_logit_mean 0.0031 lma 0.6807  cos_theta_tmp 0.7624  Epoch: 6   Global Step: 98750   Required: 30 hours
Training: 2025-12-01 06:16:56,317-Speed 1101.62 samples/sec   Loss 2.4461 target_logit_mean 0.0006 lma 0.6894  cos_theta_tmp 0.7595  Epoch: 6   Global Step: 98800   Required: 30 hours
Training: 2025-12-01 06:17:13,738-Speed 1102.17 samples/sec   Loss 2.3957 target_logit_mean -0.0001 lma 0.6846  cos_theta_tmp 0.7661  Epoch: 6   Global Step: 98850   Required: 30 hours
Training: 2025-12-01 06:17:31,166-Speed 1101.69 samples/sec   Loss 2.4213 target_logit_mean -0.0009 lma 0.6771  cos_theta_tmp 0.7611  Epoch: 6   Global Step: 98900   Required: 30 hours
Training: 2025-12-01 06:17:48,599-Speed 1101.42 samples/sec   Loss 2.4040 target_logit_mean -0.0011 lma 0.6898  cos_theta_tmp 0.7657  Epoch: 6   Global Step: 98950   Required: 30 hours
Training: 2025-12-01 06:18:06,015-Speed 1102.44 samples/sec   Loss 2.4357 target_logit_mean 0.0004 lma 0.6819  cos_theta_tmp 0.7606  Epoch: 6   Global Step: 99000   Required: 30 hours
Training: 2025-12-01 06:18:23,440-Speed 1101.91 samples/sec   Loss 2.4605 target_logit_mean -0.0008 lma 0.6844  cos_theta_tmp 0.7581  Epoch: 6   Global Step: 99050   Required: 30 hours
Training: 2025-12-01 06:18:40,860-Speed 1102.22 samples/sec   Loss 2.3930 target_logit_mean 0.0008 lma 0.6862  cos_theta_tmp 0.7647  Epoch: 6   Global Step: 99100   Required: 30 hours
Training: 2025-12-01 06:18:58,288-Speed 1101.75 samples/sec   Loss 2.4606 target_logit_mean -0.0015 lma 0.6788  cos_theta_tmp 0.7612  Epoch: 6   Global Step: 99150   Required: 30 hours
Training: 2025-12-01 06:19:15,717-Speed 1101.63 samples/sec   Loss 2.4526 target_logit_mean -0.0009 lma 0.6821  cos_theta_tmp 0.7586  Epoch: 6   Global Step: 99200   Required: 30 hours
Training: 2025-12-01 06:19:33,134-Speed 1102.40 samples/sec   Loss 2.4210 target_logit_mean -0.0012 lma 0.6918  cos_theta_tmp 0.7611  Epoch: 6   Global Step: 99250   Required: 30 hours
Training: 2025-12-01 06:19:50,561-Speed 1101.77 samples/sec   Loss 2.4420 target_logit_mean -0.0008 lma 0.6856  cos_theta_tmp 0.7559  Epoch: 6   Global Step: 99300   Required: 30 hours
Training: 2025-12-01 06:20:07,976-Speed 1102.58 samples/sec   Loss 2.4194 target_logit_mean -0.0008 lma 0.6793  cos_theta_tmp 0.7605  Epoch: 6   Global Step: 99350   Required: 30 hours
Training: 2025-12-01 06:20:25,403-Speed 1101.79 samples/sec   Loss 2.4263 target_logit_mean -0.0005 lma 0.6862  cos_theta_tmp 0.7645  Epoch: 6   Global Step: 99400   Required: 30 hours
Training: 2025-12-01 06:20:42,818-Speed 1102.53 samples/sec   Loss 2.4147 target_logit_mean -0.0001 lma 0.6818  cos_theta_tmp 0.7633  Epoch: 6   Global Step: 99450   Required: 30 hours
Training: 2025-12-01 06:21:00,245-Speed 1101.78 samples/sec   Loss 2.4076 target_logit_mean -0.0035 lma 0.6798  cos_theta_tmp 0.7647  Epoch: 6   Global Step: 99500   Required: 30 hours
Training: 2025-12-01 06:21:17,670-Speed 1101.89 samples/sec   Loss 2.4272 target_logit_mean -0.0001 lma 0.6833  cos_theta_tmp 0.7623  Epoch: 6   Global Step: 99550   Required: 30 hours
Training: 2025-12-01 06:21:35,079-Speed 1102.92 samples/sec   Loss 2.3892 target_logit_mean 0.0012 lma 0.6956  cos_theta_tmp 0.7665  Epoch: 6   Global Step: 99600   Required: 30 hours
Training: 2025-12-01 06:21:52,499-Speed 1102.24 samples/sec   Loss 2.4007 target_logit_mean -0.0014 lma 0.6753  cos_theta_tmp 0.7608  Epoch: 6   Global Step: 99650   Required: 30 hours
Training: 2025-12-01 06:22:09,911-Speed 1102.71 samples/sec   Loss 2.4492 target_logit_mean 0.0013 lma 0.6778  cos_theta_tmp 0.7565  Epoch: 6   Global Step: 99700   Required: 30 hours
Training: 2025-12-01 06:22:27,339-Speed 1101.73 samples/sec   Loss 2.4806 target_logit_mean -0.0012 lma 0.6859  cos_theta_tmp 0.7629  Epoch: 6   Global Step: 99750   Required: 30 hours
Training: 2025-12-01 06:22:44,751-Speed 1102.73 samples/sec   Loss 2.4533 target_logit_mean -0.0012 lma 0.6857  cos_theta_tmp 0.7614  Epoch: 6   Global Step: 99800   Required: 30 hours
Training: 2025-12-01 06:23:02,173-Speed 1102.05 samples/sec   Loss 2.4646 target_logit_mean 0.0015 lma 0.6837  cos_theta_tmp 0.7605  Epoch: 6   Global Step: 99850   Required: 30 hours
Training: 2025-12-01 06:23:19,604-Speed 1101.52 samples/sec   Loss 2.4488 target_logit_mean 0.0011 lma 0.6895  cos_theta_tmp 0.7651  Epoch: 6   Global Step: 99900   Required: 30 hours
Training: 2025-12-01 06:23:37,022-Speed 1102.38 samples/sec   Loss 2.4455 target_logit_mean 0.0014 lma 0.6798  cos_theta_tmp 0.7600  Epoch: 6   Global Step: 99950   Required: 30 hours
Training: 2025-12-01 06:23:54,452-Speed 1101.60 samples/sec   Loss 2.3892 target_logit_mean 0.0010 lma 0.6833  cos_theta_tmp 0.7655  Epoch: 6   Global Step: 100000   Required: 30 hours
Training: 2025-12-01 06:24:11,864-Speed 1102.68 samples/sec   Loss 2.4072 target_logit_mean -0.0003 lma 0.6835  cos_theta_tmp 0.7634  Epoch: 6   Global Step: 100050   Required: 30 hours
Training: 2025-12-01 06:24:29,290-Speed 1101.89 samples/sec   Loss 2.4131 target_logit_mean 0.0009 lma 0.6850  cos_theta_tmp 0.7641  Epoch: 6   Global Step: 100100   Required: 30 hours
Training: 2025-12-01 06:24:46,718-Speed 1101.71 samples/sec   Loss 2.4640 target_logit_mean -0.0030 lma 0.6787  cos_theta_tmp 0.7569  Epoch: 6   Global Step: 100150   Required: 30 hours
Training: 2025-12-01 06:25:04,131-Speed 1102.64 samples/sec   Loss 2.4200 target_logit_mean 0.0010 lma 0.6747  cos_theta_tmp 0.7541  Epoch: 6   Global Step: 100200   Required: 30 hours
Training: 2025-12-01 06:25:21,561-Speed 1101.56 samples/sec   Loss 2.4388 target_logit_mean 0.0021 lma 0.6908  cos_theta_tmp 0.7637  Epoch: 6   Global Step: 100250   Required: 30 hours
Training: 2025-12-01 06:25:38,975-Speed 1102.64 samples/sec   Loss 2.4369 target_logit_mean -0.0013 lma 0.6773  cos_theta_tmp 0.7600  Epoch: 6   Global Step: 100300   Required: 30 hours
Training: 2025-12-01 06:25:56,402-Speed 1101.77 samples/sec   Loss 2.4441 target_logit_mean -0.0010 lma 0.6882  cos_theta_tmp 0.7654  Epoch: 6   Global Step: 100350   Required: 30 hours
Training: 2025-12-01 06:26:13,817-Speed 1102.52 samples/sec   Loss 2.4726 target_logit_mean 0.0000 lma 0.6718  cos_theta_tmp 0.7609  Epoch: 6   Global Step: 100400   Required: 30 hours
Training: 2025-12-01 06:26:31,244-Speed 1101.78 samples/sec   Loss 2.3978 target_logit_mean -0.0022 lma 0.6847  cos_theta_tmp 0.7665  Epoch: 6   Global Step: 100450   Required: 30 hours
Training: 2025-12-01 06:26:48,673-Speed 1101.66 samples/sec   Loss 2.4715 target_logit_mean 0.0006 lma 0.6834  cos_theta_tmp 0.7653  Epoch: 6   Global Step: 100500   Required: 30 hours
Training: 2025-12-01 06:27:06,086-Speed 1102.65 samples/sec   Loss 2.4246 target_logit_mean -0.0001 lma 0.6875  cos_theta_tmp 0.7654  Epoch: 6   Global Step: 100550   Required: 30 hours
Training: 2025-12-01 06:27:23,508-Speed 1102.06 samples/sec   Loss 2.4379 target_logit_mean 0.0008 lma 0.6855  cos_theta_tmp 0.7653  Epoch: 6   Global Step: 100600   Required: 30 hours
Training: 2025-12-01 06:27:40,921-Speed 1102.67 samples/sec   Loss 2.4304 target_logit_mean -0.0011 lma 0.6864  cos_theta_tmp 0.7584  Epoch: 6   Global Step: 100650   Required: 30 hours
Training: 2025-12-01 06:27:58,350-Speed 1101.68 samples/sec   Loss 2.4103 target_logit_mean 0.0006 lma 0.6860  cos_theta_tmp 0.7671  Epoch: 6   Global Step: 100700   Required: 30 hours
Training: 2025-12-01 06:28:15,761-Speed 1102.79 samples/sec   Loss 2.4447 target_logit_mean -0.0026 lma 0.6773  cos_theta_tmp 0.7635  Epoch: 6   Global Step: 100750   Required: 30 hours
Training: 2025-12-01 06:28:33,184-Speed 1102.00 samples/sec   Loss 2.4367 target_logit_mean 0.0008 lma 0.6879  cos_theta_tmp 0.7654  Epoch: 6   Global Step: 100800   Required: 30 hours
Training: 2025-12-01 06:28:50,608-Speed 1102.00 samples/sec   Loss 2.4024 target_logit_mean -0.0001 lma 0.6711  cos_theta_tmp 0.7571  Epoch: 6   Global Step: 100850   Required: 30 hours
Training: 2025-12-01 06:29:08,024-Speed 1102.43 samples/sec   Loss 2.4894 target_logit_mean 0.0021 lma 0.6795  cos_theta_tmp 0.7601  Epoch: 6   Global Step: 100900   Required: 30 hours
Training: 2025-12-01 06:29:25,448-Speed 1101.97 samples/sec   Loss 2.5047 target_logit_mean 0.0016 lma 0.6881  cos_theta_tmp 0.7628  Epoch: 6   Global Step: 100950   Required: 30 hours
Training: 2025-12-01 06:29:42,861-Speed 1102.70 samples/sec   Loss 2.3876 target_logit_mean -0.0009 lma 0.6876  cos_theta_tmp 0.7659  Epoch: 6   Global Step: 101000   Required: 30 hours
Training: 2025-12-01 06:30:00,286-Speed 1101.89 samples/sec   Loss 2.4994 target_logit_mean -0.0017 lma 0.6799  cos_theta_tmp 0.7629  Epoch: 6   Global Step: 101050   Required: 30 hours
Training: 2025-12-01 06:30:17,712-Speed 1101.84 samples/sec   Loss 2.4359 target_logit_mean 0.0027 lma 0.6835  cos_theta_tmp 0.7613  Epoch: 6   Global Step: 101100   Required: 30 hours
Training: 2025-12-01 06:30:35,124-Speed 1102.72 samples/sec   Loss 2.4337 target_logit_mean -0.0045 lma 0.6703  cos_theta_tmp 0.7536  Epoch: 6   Global Step: 101150   Required: 30 hours
Training: 2025-12-01 06:30:52,550-Speed 1101.81 samples/sec   Loss 2.4471 target_logit_mean -0.0018 lma 0.6908  cos_theta_tmp 0.7677  Epoch: 6   Global Step: 101200   Required: 30 hours
Training: 2025-12-01 06:31:09,970-Speed 1102.26 samples/sec   Loss 2.4575 target_logit_mean 0.0018 lma 0.6862  cos_theta_tmp 0.7678  Epoch: 6   Global Step: 101250   Required: 30 hours
Training: 2025-12-01 06:31:27,400-Speed 1101.59 samples/sec   Loss 2.4586 target_logit_mean -0.0015 lma 0.6850  cos_theta_tmp 0.7614  Epoch: 6   Global Step: 101300   Required: 30 hours
Training: 2025-12-01 06:31:44,810-Speed 1102.83 samples/sec   Loss 2.4492 target_logit_mean 0.0001 lma 0.6811  cos_theta_tmp 0.7645  Epoch: 6   Global Step: 101350   Required: 30 hours
Training: 2025-12-01 06:32:02,230-Speed 1102.22 samples/sec   Loss 2.3823 target_logit_mean 0.0004 lma 0.6774  cos_theta_tmp 0.7665  Epoch: 6   Global Step: 101400   Required: 30 hours
Training: 2025-12-01 06:32:19,659-Speed 1101.63 samples/sec   Loss 2.4585 target_logit_mean -0.0007 lma 0.6763  cos_theta_tmp 0.7607  Epoch: 6   Global Step: 101450   Required: 30 hours
Training: 2025-12-01 06:32:37,073-Speed 1102.60 samples/sec   Loss 2.3906 target_logit_mean 0.0009 lma 0.6754  cos_theta_tmp 0.7627  Epoch: 6   Global Step: 101500   Required: 30 hours
Training: 2025-12-01 06:32:54,497-Speed 1102.01 samples/sec   Loss 2.4207 target_logit_mean -0.0012 lma 0.6851  cos_theta_tmp 0.7654  Epoch: 6   Global Step: 101550   Required: 30 hours
Training: 2025-12-01 06:33:11,911-Speed 1102.60 samples/sec   Loss 2.4182 target_logit_mean 0.0013 lma 0.6884  cos_theta_tmp 0.7657  Epoch: 6   Global Step: 101600   Required: 30 hours
Training: 2025-12-01 06:33:29,335-Speed 1101.93 samples/sec   Loss 2.4862 target_logit_mean -0.0004 lma 0.6844  cos_theta_tmp 0.7613  Epoch: 6   Global Step: 101650   Required: 30 hours
Training: 2025-12-01 06:33:46,760-Speed 1101.92 samples/sec   Loss 2.4393 target_logit_mean -0.0002 lma 0.6907  cos_theta_tmp 0.7637  Epoch: 6   Global Step: 101700   Required: 30 hours
Training: 2025-12-01 06:34:04,171-Speed 1102.80 samples/sec   Loss 2.4297 target_logit_mean 0.0000 lma 0.6888  cos_theta_tmp 0.7630  Epoch: 6   Global Step: 101750   Required: 30 hours
Training: 2025-12-01 06:34:21,598-Speed 1101.75 samples/sec   Loss 2.4544 target_logit_mean 0.0009 lma 0.6834  cos_theta_tmp 0.7627  Epoch: 6   Global Step: 101800   Required: 30 hours
Training: 2025-12-01 06:34:39,008-Speed 1102.85 samples/sec   Loss 2.4210 target_logit_mean -0.0027 lma 0.6811  cos_theta_tmp 0.7623  Epoch: 6   Global Step: 101850   Required: 30 hours
Training: 2025-12-01 06:34:56,440-Speed 1101.45 samples/sec   Loss 2.4557 target_logit_mean -0.0001 lma 0.6988  cos_theta_tmp 0.7664  Epoch: 6   Global Step: 101900   Required: 30 hours
Training: 2025-12-01 06:35:13,855-Speed 1102.54 samples/sec   Loss 2.4283 target_logit_mean 0.0014 lma 0.6772  cos_theta_tmp 0.7678  Epoch: 6   Global Step: 101950   Required: 30 hours
Training: 2025-12-01 06:35:31,279-Speed 1101.95 samples/sec   Loss 2.4241 target_logit_mean -0.0020 lma 0.6856  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 102000   Required: 30 hours
Training: 2025-12-01 06:35:48,705-Speed 1101.84 samples/sec   Loss 2.4530 target_logit_mean -0.0019 lma 0.6788  cos_theta_tmp 0.7566  Epoch: 6   Global Step: 102050   Required: 30 hours
Training: 2025-12-01 06:36:06,125-Speed 1102.28 samples/sec   Loss 2.4411 target_logit_mean -0.0010 lma 0.6825  cos_theta_tmp 0.7599  Epoch: 6   Global Step: 102100   Required: 30 hours
Training: 2025-12-01 06:36:23,555-Speed 1101.58 samples/sec   Loss 2.3818 target_logit_mean 0.0036 lma 0.6871  cos_theta_tmp 0.7622  Epoch: 6   Global Step: 102150   Required: 30 hours
Training: 2025-12-01 06:36:40,968-Speed 1102.62 samples/sec   Loss 2.3805 target_logit_mean 0.0022 lma 0.6890  cos_theta_tmp 0.7636  Epoch: 6   Global Step: 102200   Required: 30 hours
Training: 2025-12-01 06:36:58,394-Speed 1101.87 samples/sec   Loss 2.4092 target_logit_mean 0.0014 lma 0.6709  cos_theta_tmp 0.7588  Epoch: 6   Global Step: 102250   Required: 30 hours
Training: 2025-12-01 06:37:15,802-Speed 1102.96 samples/sec   Loss 2.4463 target_logit_mean -0.0004 lma 0.6968  cos_theta_tmp 0.7689  Epoch: 6   Global Step: 102300   Required: 30 hours
Training: 2025-12-01 06:37:33,230-Speed 1101.68 samples/sec   Loss 2.4304 target_logit_mean 0.0024 lma 0.6894  cos_theta_tmp 0.7698  Epoch: 6   Global Step: 102350   Required: 30 hours
Training: 2025-12-01 06:37:50,664-Speed 1101.37 samples/sec   Loss 2.4282 target_logit_mean 0.0017 lma 0.6864  cos_theta_tmp 0.7576  Epoch: 6   Global Step: 102400   Required: 30 hours
Training: 2025-12-01 06:38:08,084-Speed 1102.23 samples/sec   Loss 2.3974 target_logit_mean -0.0003 lma 0.6815  cos_theta_tmp 0.7642  Epoch: 6   Global Step: 102450   Required: 30 hours
Training: 2025-12-01 06:38:25,510-Speed 1101.82 samples/sec   Loss 2.3771 target_logit_mean 0.0023 lma 0.6801  cos_theta_tmp 0.7654  Epoch: 6   Global Step: 102500   Required: 29 hours
Training: 2025-12-01 06:38:42,925-Speed 1102.58 samples/sec   Loss 2.4092 target_logit_mean -0.0006 lma 0.6863  cos_theta_tmp 0.7654  Epoch: 6   Global Step: 102550   Required: 29 hours
Training: 2025-12-01 06:39:00,354-Speed 1101.63 samples/sec   Loss 2.4169 target_logit_mean -0.0010 lma 0.6978  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 102600   Required: 29 hours
Training: 2025-12-01 06:39:17,790-Speed 1101.19 samples/sec   Loss 2.4321 target_logit_mean 0.0010 lma 0.6829  cos_theta_tmp 0.7651  Epoch: 6   Global Step: 102650   Required: 29 hours
Training: 2025-12-01 06:39:35,208-Speed 1102.36 samples/sec   Loss 2.4339 target_logit_mean 0.0006 lma 0.6772  cos_theta_tmp 0.7641  Epoch: 6   Global Step: 102700   Required: 29 hours
Training: 2025-12-01 06:39:52,637-Speed 1101.61 samples/sec   Loss 2.4346 target_logit_mean -0.0001 lma 0.6931  cos_theta_tmp 0.7643  Epoch: 6   Global Step: 102750   Required: 29 hours
Training: 2025-12-01 06:40:10,049-Speed 1102.77 samples/sec   Loss 2.4122 target_logit_mean -0.0009 lma 0.6913  cos_theta_tmp 0.7581  Epoch: 6   Global Step: 102800   Required: 29 hours
Training: 2025-12-01 06:40:27,476-Speed 1101.75 samples/sec   Loss 2.4309 target_logit_mean 0.0018 lma 0.6885  cos_theta_tmp 0.7664  Epoch: 6   Global Step: 102850   Required: 29 hours
Training: 2025-12-01 06:40:44,890-Speed 1102.65 samples/sec   Loss 2.4220 target_logit_mean 0.0020 lma 0.6828  cos_theta_tmp 0.7666  Epoch: 6   Global Step: 102900   Required: 29 hours
Training: 2025-12-01 06:41:02,320-Speed 1101.55 samples/sec   Loss 2.4551 target_logit_mean -0.0005 lma 0.6970  cos_theta_tmp 0.7602  Epoch: 6   Global Step: 102950   Required: 29 hours
Training: 2025-12-01 06:41:19,744-Speed 1101.99 samples/sec   Loss 2.4254 target_logit_mean -0.0003 lma 0.6797  cos_theta_tmp 0.7623  Epoch: 6   Global Step: 103000   Required: 29 hours
Training: 2025-12-01 06:41:37,163-Speed 1102.29 samples/sec   Loss 2.4250 target_logit_mean -0.0013 lma 0.6826  cos_theta_tmp 0.7631  Epoch: 6   Global Step: 103050   Required: 29 hours
Training: 2025-12-01 06:41:54,585-Speed 1102.10 samples/sec   Loss 2.4372 target_logit_mean 0.0022 lma 0.6864  cos_theta_tmp 0.7636  Epoch: 6   Global Step: 103100   Required: 29 hours
Training: 2025-12-01 06:42:12,007-Speed 1102.07 samples/sec   Loss 2.4337 target_logit_mean -0.0006 lma 0.6831  cos_theta_tmp 0.7661  Epoch: 6   Global Step: 103150   Required: 29 hours
Training: 2025-12-01 06:42:29,436-Speed 1101.70 samples/sec   Loss 2.4580 target_logit_mean -0.0010 lma 0.6626  cos_theta_tmp 0.7512  Epoch: 6   Global Step: 103200   Required: 29 hours
Training: 2025-12-01 06:42:46,864-Speed 1101.70 samples/sec   Loss 2.4484 target_logit_mean 0.0003 lma 0.6754  cos_theta_tmp 0.7610  Epoch: 6   Global Step: 103250   Required: 29 hours
Training: 2025-12-01 06:43:04,283-Speed 1102.26 samples/sec   Loss 2.4418 target_logit_mean 0.0018 lma 0.6961  cos_theta_tmp 0.7681  Epoch: 6   Global Step: 103300   Required: 29 hours
Training: 2025-12-01 06:43:21,708-Speed 1101.91 samples/sec   Loss 2.4190 target_logit_mean 0.0031 lma 0.6903  cos_theta_tmp 0.7725  Epoch: 6   Global Step: 103350   Required: 29 hours
Training: 2025-12-01 06:43:39,126-Speed 1102.39 samples/sec   Loss 2.4126 target_logit_mean -0.0004 lma 0.6878  cos_theta_tmp 0.7691  Epoch: 6   Global Step: 103400   Required: 29 hours
Training: 2025-12-01 06:43:56,553-Speed 1101.73 samples/sec   Loss 2.4503 target_logit_mean -0.0031 lma 0.6858  cos_theta_tmp 0.7634  Epoch: 6   Global Step: 103450   Required: 29 hours
Training: 2025-12-01 06:44:13,966-Speed 1102.69 samples/sec   Loss 2.4971 target_logit_mean 0.0002 lma 0.6904  cos_theta_tmp 0.7545  Epoch: 6   Global Step: 103500   Required: 29 hours
Training: 2025-12-01 06:44:31,397-Speed 1101.50 samples/sec   Loss 2.4257 target_logit_mean -0.0001 lma 0.6825  cos_theta_tmp 0.7613  Epoch: 6   Global Step: 103550   Required: 29 hours
Training: 2025-12-01 06:44:48,824-Speed 1101.79 samples/sec   Loss 2.4378 target_logit_mean -0.0011 lma 0.6861  cos_theta_tmp 0.7641  Epoch: 6   Global Step: 103600   Required: 29 hours
Training: 2025-12-01 06:45:06,237-Speed 1102.65 samples/sec   Loss 2.4278 target_logit_mean 0.0016 lma 0.6893  cos_theta_tmp 0.7645  Epoch: 6   Global Step: 103650   Required: 29 hours
Training: 2025-12-01 06:45:23,662-Speed 1101.92 samples/sec   Loss 2.4377 target_logit_mean 0.0006 lma 0.6887  cos_theta_tmp 0.7668  Epoch: 6   Global Step: 103700   Required: 29 hours
Training: 2025-12-01 06:45:41,077-Speed 1102.54 samples/sec   Loss 2.4603 target_logit_mean 0.0049 lma 0.6983  cos_theta_tmp 0.7627  Epoch: 6   Global Step: 103750   Required: 29 hours
Training: 2025-12-01 06:45:58,504-Speed 1101.76 samples/sec   Loss 2.4571 target_logit_mean 0.0016 lma 0.6897  cos_theta_tmp 0.7628  Epoch: 6   Global Step: 103800   Required: 29 hours
Training: 2025-12-01 06:46:15,919-Speed 1102.52 samples/sec   Loss 2.3677 target_logit_mean 0.0002 lma 0.6849  cos_theta_tmp 0.7570  Epoch: 6   Global Step: 103850   Required: 29 hours
Training: 2025-12-01 06:46:33,353-Speed 1101.38 samples/sec   Loss 2.4255 target_logit_mean -0.0009 lma 0.6907  cos_theta_tmp 0.7675  Epoch: 6   Global Step: 103900   Required: 29 hours
Training: 2025-12-01 06:46:50,782-Speed 1101.63 samples/sec   Loss 2.4570 target_logit_mean -0.0018 lma 0.6875  cos_theta_tmp 0.7642  Epoch: 6   Global Step: 103950   Required: 29 hours
Training: 2025-12-01 06:47:08,201-Speed 1102.27 samples/sec   Loss 2.4610 target_logit_mean -0.0017 lma 0.6775  cos_theta_tmp 0.7586  Epoch: 6   Global Step: 104000   Required: 29 hours
Training: 2025-12-01 06:47:25,628-Speed 1101.83 samples/sec   Loss 2.3585 target_logit_mean -0.0027 lma 0.6826  cos_theta_tmp 0.7623  Epoch: 6   Global Step: 104050   Required: 29 hours
Training: 2025-12-01 06:47:43,039-Speed 1102.79 samples/sec   Loss 2.4631 target_logit_mean 0.0016 lma 0.6780  cos_theta_tmp 0.7608  Epoch: 6   Global Step: 104100   Required: 29 hours
Training: 2025-12-01 06:48:00,469-Speed 1101.59 samples/sec   Loss 2.4712 target_logit_mean 0.0004 lma 0.6901  cos_theta_tmp 0.7622  Epoch: 6   Global Step: 104150   Required: 29 hours
Training: 2025-12-01 06:48:17,900-Speed 1101.48 samples/sec   Loss 2.4262 target_logit_mean 0.0016 lma 0.6696  cos_theta_tmp 0.7598  Epoch: 6   Global Step: 104200   Required: 29 hours
Training: 2025-12-01 06:48:35,317-Speed 1102.47 samples/sec   Loss 2.4279 target_logit_mean 0.0003 lma 0.6856  cos_theta_tmp 0.7594  Epoch: 6   Global Step: 104250   Required: 29 hours
Training: 2025-12-01 06:48:52,748-Speed 1101.50 samples/sec   Loss 2.4294 target_logit_mean 0.0008 lma 0.6810  cos_theta_tmp 0.7664  Epoch: 6   Global Step: 104300   Required: 29 hours
Training: 2025-12-01 06:49:10,167-Speed 1102.28 samples/sec   Loss 2.4149 target_logit_mean -0.0038 lma 0.6927  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 104350   Required: 29 hours
Training: 2025-12-01 06:49:27,594-Speed 1101.81 samples/sec   Loss 2.3623 target_logit_mean 0.0006 lma 0.6898  cos_theta_tmp 0.7600  Epoch: 6   Global Step: 104400   Required: 29 hours
Training: 2025-12-01 06:49:45,006-Speed 1102.70 samples/sec   Loss 2.3988 target_logit_mean -0.0010 lma 0.6815  cos_theta_tmp 0.7625  Epoch: 6   Global Step: 104450   Required: 29 hours
Training: 2025-12-01 06:50:02,433-Speed 1101.80 samples/sec   Loss 2.3286 target_logit_mean -0.0012 lma 0.6711  cos_theta_tmp 0.7576  Epoch: 6   Global Step: 104500   Required: 29 hours
Training: 2025-12-01 06:50:19,862-Speed 1101.67 samples/sec   Loss 2.3845 target_logit_mean 0.0002 lma 0.6851  cos_theta_tmp 0.7622  Epoch: 6   Global Step: 104550   Required: 29 hours
Training: 2025-12-01 06:50:37,279-Speed 1102.42 samples/sec   Loss 2.4201 target_logit_mean -0.0001 lma 0.6754  cos_theta_tmp 0.7702  Epoch: 6   Global Step: 104600   Required: 29 hours
Training: 2025-12-01 06:50:54,704-Speed 1101.91 samples/sec   Loss 2.4018 target_logit_mean -0.0019 lma 0.6822  cos_theta_tmp 0.7650  Epoch: 6   Global Step: 104650   Required: 29 hours
Training: 2025-12-01 06:51:12,123-Speed 1102.25 samples/sec   Loss 2.4018 target_logit_mean 0.0015 lma 0.6903  cos_theta_tmp 0.7662  Epoch: 6   Global Step: 104700   Required: 29 hours
Training: 2025-12-01 06:51:29,544-Speed 1102.18 samples/sec   Loss 2.3846 target_logit_mean -0.0000 lma 0.6758  cos_theta_tmp 0.7602  Epoch: 6   Global Step: 104750   Required: 29 hours
Training: 2025-12-01 06:51:46,962-Speed 1102.33 samples/sec   Loss 2.3931 target_logit_mean -0.0025 lma 0.6862  cos_theta_tmp 0.7597  Epoch: 6   Global Step: 104800   Required: 29 hours
Training: 2025-12-01 06:52:04,387-Speed 1101.93 samples/sec   Loss 2.4137 target_logit_mean -0.0015 lma 0.6801  cos_theta_tmp 0.7640  Epoch: 6   Global Step: 104850   Required: 29 hours
Training: 2025-12-01 06:52:21,815-Speed 1101.69 samples/sec   Loss 2.4692 target_logit_mean -0.0017 lma 0.6897  cos_theta_tmp 0.7571  Epoch: 6   Global Step: 104900   Required: 29 hours
Training: 2025-12-01 06:52:39,231-Speed 1102.52 samples/sec   Loss 2.4290 target_logit_mean 0.0034 lma 0.6912  cos_theta_tmp 0.7677  Epoch: 6   Global Step: 104950   Required: 29 hours
Training: 2025-12-01 06:52:56,665-Speed 1101.33 samples/sec   Loss 2.4495 target_logit_mean 0.0014 lma 0.6808  cos_theta_tmp 0.7630  Epoch: 6   Global Step: 105000   Required: 29 hours
Training: 2025-12-01 06:53:14,079-Speed 1102.56 samples/sec   Loss 2.3707 target_logit_mean 0.0018 lma 0.6837  cos_theta_tmp 0.7685  Epoch: 6   Global Step: 105050   Required: 29 hours
Training: 2025-12-01 06:53:31,508-Speed 1101.67 samples/sec   Loss 2.3488 target_logit_mean -0.0008 lma 0.6667  cos_theta_tmp 0.7654  Epoch: 6   Global Step: 105100   Required: 29 hours
Training: 2025-12-01 06:53:48,938-Speed 1101.62 samples/sec   Loss 2.4278 target_logit_mean -0.0024 lma 0.6819  cos_theta_tmp 0.7655  Epoch: 6   Global Step: 105150   Required: 29 hours
Training: 2025-12-01 06:54:06,350-Speed 1102.70 samples/sec   Loss 2.4088 target_logit_mean -0.0004 lma 0.6778  cos_theta_tmp 0.7591  Epoch: 6   Global Step: 105200   Required: 29 hours
Training: 2025-12-01 06:54:23,782-Speed 1101.49 samples/sec   Loss 2.4786 target_logit_mean 0.0009 lma 0.6751  cos_theta_tmp 0.7511  Epoch: 6   Global Step: 105250   Required: 29 hours
Training: 2025-12-01 06:54:41,198-Speed 1102.45 samples/sec   Loss 2.5122 target_logit_mean -0.0032 lma 0.6787  cos_theta_tmp 0.7587  Epoch: 6   Global Step: 105300   Required: 29 hours
Training: 2025-12-01 06:54:58,626-Speed 1101.74 samples/sec   Loss 2.3749 target_logit_mean -0.0035 lma 0.6864  cos_theta_tmp 0.7615  Epoch: 6   Global Step: 105350   Required: 29 hours
Training: 2025-12-01 06:55:16,041-Speed 1102.54 samples/sec   Loss 2.4293 target_logit_mean 0.0051 lma 0.6833  cos_theta_tmp 0.7678  Epoch: 6   Global Step: 105400   Required: 29 hours
Training: 2025-12-01 06:55:33,468-Speed 1101.77 samples/sec   Loss 2.4125 target_logit_mean 0.0003 lma 0.6781  cos_theta_tmp 0.7604  Epoch: 6   Global Step: 105450   Required: 29 hours
Training: 2025-12-01 06:55:50,897-Speed 1101.61 samples/sec   Loss 2.3941 target_logit_mean -0.0010 lma 0.6741  cos_theta_tmp 0.7636  Epoch: 6   Global Step: 105500   Required: 29 hours
Training: 2025-12-01 06:56:08,310-Speed 1102.67 samples/sec   Loss 2.4208 target_logit_mean -0.0022 lma 0.6928  cos_theta_tmp 0.7558  Epoch: 6   Global Step: 105550   Required: 29 hours
Training: 2025-12-01 06:56:25,743-Speed 1101.44 samples/sec   Loss 2.4582 target_logit_mean -0.0017 lma 0.6792  cos_theta_tmp 0.7595  Epoch: 6   Global Step: 105600   Required: 29 hours
Training: 2025-12-01 06:56:43,160-Speed 1102.42 samples/sec   Loss 2.3567 target_logit_mean -0.0015 lma 0.6786  cos_theta_tmp 0.7585  Epoch: 6   Global Step: 105650   Required: 29 hours
Training: 2025-12-01 06:57:00,586-Speed 1101.85 samples/sec   Loss 2.4009 target_logit_mean -0.0013 lma 0.6859  cos_theta_tmp 0.7645  Epoch: 6   Global Step: 105700   Required: 29 hours
Training: 2025-12-01 06:57:18,015-Speed 1101.61 samples/sec   Loss 2.4414 target_logit_mean 0.0008 lma 0.6810  cos_theta_tmp 0.7602  Epoch: 6   Global Step: 105750   Required: 29 hours
Training: 2025-12-01 06:57:35,427-Speed 1102.76 samples/sec   Loss 2.4136 target_logit_mean 0.0014 lma 0.6834  cos_theta_tmp 0.7694  Epoch: 6   Global Step: 105800   Required: 29 hours
Training: 2025-12-01 06:57:52,854-Speed 1101.79 samples/sec   Loss 2.4197 target_logit_mean 0.0007 lma 0.6870  cos_theta_tmp 0.7659  Epoch: 6   Global Step: 105850   Required: 29 hours
Training: 2025-12-01 06:58:10,269-Speed 1102.52 samples/sec   Loss 2.4554 target_logit_mean 0.0016 lma 0.6855  cos_theta_tmp 0.7649  Epoch: 6   Global Step: 105900   Required: 29 hours
Training: 2025-12-01 06:58:27,694-Speed 1101.88 samples/sec   Loss 2.4481 target_logit_mean -0.0008 lma 0.6843  cos_theta_tmp 0.7596  Epoch: 6   Global Step: 105950   Required: 29 hours
Training: 2025-12-01 06:58:45,106-Speed 1102.77 samples/sec   Loss 2.4172 target_logit_mean 0.0004 lma 0.6865  cos_theta_tmp 0.7716  Epoch: 6   Global Step: 106000   Required: 29 hours
Training: 2025-12-01 06:59:02,535-Speed 1101.61 samples/sec   Loss 2.4141 target_logit_mean -0.0002 lma 0.6692  cos_theta_tmp 0.7624  Epoch: 6   Global Step: 106050   Required: 29 hours
Training: 2025-12-01 06:59:19,958-Speed 1102.06 samples/sec   Loss 2.3666 target_logit_mean 0.0029 lma 0.6733  cos_theta_tmp 0.7683  Epoch: 6   Global Step: 106100   Required: 29 hours
Training: 2025-12-01 06:59:46,612-[lfw][106141]XNorm: 23.192571
Training: 2025-12-01 06:59:46,612-[lfw][106141]Accuracy-Flip: 0.99200+-0.00379
Training: 2025-12-01 06:59:46,612-[lfw][106141]Accuracy-Highest: 0.99217
Training: 2025-12-01 07:00:00,713-[cfp_fp][106141]XNorm: 18.897957
Training: 2025-12-01 07:00:00,714-[cfp_fp][106141]Accuracy-Flip: 0.87357+-0.01797
Training: 2025-12-01 07:00:00,714-[cfp_fp][106141]Accuracy-Highest: 0.88429
Training: 2025-12-01 07:00:14,870-[cfp_ff][106141]XNorm: 22.603142
Training: 2025-12-01 07:00:14,870-[cfp_ff][106141]Accuracy-Flip: 0.98929+-0.00301
Training: 2025-12-01 07:00:14,870-[cfp_ff][106141]Accuracy-Highest: 0.99043
Training: 2025-12-01 07:00:27,088-[agedb_30][106141]XNorm: 22.133517
Training: 2025-12-01 07:00:27,088-[agedb_30][106141]Accuracy-Flip: 0.92717+-0.01607
Training: 2025-12-01 07:00:27,088-[agedb_30][106141]Accuracy-Highest: 0.93133
Training: 2025-12-01 07:00:39,594-[calfw][106141]XNorm: 23.209542
Training: 2025-12-01 07:00:39,595-[calfw][106141]Accuracy-Flip: 0.93467+-0.00843
Training: 2025-12-01 07:00:39,595-[calfw][106141]Accuracy-Highest: 0.93883
Training: 2025-12-01 07:00:52,007-[cplfw][106141]XNorm: 19.029438
Training: 2025-12-01 07:00:52,007-[cplfw][106141]Accuracy-Flip: 0.85133+-0.02002
Training: 2025-12-01 07:00:52,007-[cplfw][106141]Accuracy-Highest: 0.85333
Training: 2025-12-01 07:01:02,491-[vgg2_fp][106141]XNorm: 19.306271
Training: 2025-12-01 07:01:02,491-[vgg2_fp][106141]Accuracy-Flip: 0.88540+-0.01459
Training: 2025-12-01 07:01:02,491-[vgg2_fp][106141]Accuracy-Highest: 0.88840
Training: 2025-12-01 07:01:20,121-Speed 159.78 samples/sec   Loss 2.3337 target_logit_mean -0.0013 lma 0.7037  cos_theta_tmp 0.7763  Epoch: 7   Global Step: 106150   Required: 29 hours
Training: 2025-12-01 07:01:37,464-Speed 1107.14 samples/sec   Loss 1.6802 target_logit_mean -0.0002 lma 0.6922  cos_theta_tmp 0.8004  Epoch: 7   Global Step: 106200   Required: 29 hours
Training: 2025-12-01 07:01:54,851-Speed 1104.29 samples/sec   Loss 1.4516 target_logit_mean -0.0001 lma 0.6928  cos_theta_tmp 0.8041  Epoch: 7   Global Step: 106250   Required: 29 hours
Training: 2025-12-01 07:02:12,263-Speed 1102.75 samples/sec   Loss 1.3545 target_logit_mean -0.0007 lma 0.6926  cos_theta_tmp 0.8047  Epoch: 7   Global Step: 106300   Required: 29 hours
Training: 2025-12-01 07:02:29,686-Speed 1101.99 samples/sec   Loss 1.3169 target_logit_mean 0.0009 lma 0.6790  cos_theta_tmp 0.8087  Epoch: 7   Global Step: 106350   Required: 29 hours
Training: 2025-12-01 07:02:47,102-Speed 1102.47 samples/sec   Loss 1.2568 target_logit_mean 0.0002 lma 0.6979  cos_theta_tmp 0.8161  Epoch: 7   Global Step: 106400   Required: 29 hours
Training: 2025-12-01 07:03:04,525-Speed 1102.09 samples/sec   Loss 1.2602 target_logit_mean -0.0015 lma 0.6968  cos_theta_tmp 0.8106  Epoch: 7   Global Step: 106450   Required: 29 hours
Training: 2025-12-01 07:03:21,958-Speed 1101.38 samples/sec   Loss 1.2138 target_logit_mean -0.0004 lma 0.7030  cos_theta_tmp 0.8152  Epoch: 7   Global Step: 106500   Required: 29 hours
Training: 2025-12-01 07:03:39,373-Speed 1102.54 samples/sec   Loss 1.1711 target_logit_mean -0.0016 lma 0.6811  cos_theta_tmp 0.8135  Epoch: 7   Global Step: 106550   Required: 29 hours
Training: 2025-12-01 07:03:56,800-Speed 1101.76 samples/sec   Loss 1.1546 target_logit_mean -0.0018 lma 0.6891  cos_theta_tmp 0.8145  Epoch: 7   Global Step: 106600   Required: 29 hours
Training: 2025-12-01 07:04:14,218-Speed 1102.37 samples/sec   Loss 1.1854 target_logit_mean 0.0029 lma 0.6954  cos_theta_tmp 0.8201  Epoch: 7   Global Step: 106650   Required: 29 hours
Training: 2025-12-01 07:04:31,646-Speed 1101.68 samples/sec   Loss 1.1779 target_logit_mean 0.0010 lma 0.6872  cos_theta_tmp 0.8162  Epoch: 7   Global Step: 106700   Required: 29 hours
Training: 2025-12-01 07:04:49,082-Speed 1101.24 samples/sec   Loss 1.1466 target_logit_mean 0.0028 lma 0.6999  cos_theta_tmp 0.8222  Epoch: 7   Global Step: 106750   Required: 29 hours
Training: 2025-12-01 07:05:06,496-Speed 1102.62 samples/sec   Loss 1.1852 target_logit_mean -0.0000 lma 0.6922  cos_theta_tmp 0.8172  Epoch: 7   Global Step: 106800   Required: 29 hours
Training: 2025-12-01 07:05:23,925-Speed 1101.65 samples/sec   Loss 1.1174 target_logit_mean 0.0010 lma 0.6943  cos_theta_tmp 0.8236  Epoch: 7   Global Step: 106850   Required: 29 hours
Training: 2025-12-01 07:05:41,346-Speed 1102.17 samples/sec   Loss 1.1189 target_logit_mean -0.0004 lma 0.6860  cos_theta_tmp 0.8183  Epoch: 7   Global Step: 106900   Required: 29 hours
Training: 2025-12-01 07:05:58,771-Speed 1101.88 samples/sec   Loss 1.1215 target_logit_mean 0.0021 lma 0.6875  cos_theta_tmp 0.8206  Epoch: 7   Global Step: 106950   Required: 29 hours
Training: 2025-12-01 07:06:16,187-Speed 1102.47 samples/sec   Loss 1.1019 target_logit_mean -0.0020 lma 0.6748  cos_theta_tmp 0.8158  Epoch: 7   Global Step: 107000   Required: 29 hours
Training: 2025-12-01 07:06:33,613-Speed 1101.83 samples/sec   Loss 1.1268 target_logit_mean -0.0013 lma 0.6902  cos_theta_tmp 0.8209  Epoch: 7   Global Step: 107050   Required: 29 hours
Training: 2025-12-01 07:06:51,042-Speed 1101.64 samples/sec   Loss 1.0827 target_logit_mean 0.0003 lma 0.6941  cos_theta_tmp 0.8232  Epoch: 7   Global Step: 107100   Required: 29 hours
Training: 2025-12-01 07:07:08,461-Speed 1102.31 samples/sec   Loss 1.0763 target_logit_mean 0.0019 lma 0.6987  cos_theta_tmp 0.8252  Epoch: 7   Global Step: 107150   Required: 29 hours
Training: 2025-12-01 07:07:25,891-Speed 1101.56 samples/sec   Loss 1.0505 target_logit_mean -0.0020 lma 0.6978  cos_theta_tmp 0.8207  Epoch: 7   Global Step: 107200   Required: 29 hours
Training: 2025-12-01 07:07:43,305-Speed 1102.60 samples/sec   Loss 1.0909 target_logit_mean 0.0008 lma 0.6831  cos_theta_tmp 0.8213  Epoch: 7   Global Step: 107250   Required: 29 hours
Training: 2025-12-01 07:08:00,735-Speed 1101.65 samples/sec   Loss 1.0891 target_logit_mean -0.0002 lma 0.6811  cos_theta_tmp 0.8202  Epoch: 7   Global Step: 107300   Required: 29 hours
Training: 2025-12-01 07:08:18,164-Speed 1101.63 samples/sec   Loss 1.0858 target_logit_mean -0.0005 lma 0.6863  cos_theta_tmp 0.8187  Epoch: 7   Global Step: 107350   Required: 29 hours
Training: 2025-12-01 07:08:35,579-Speed 1102.56 samples/sec   Loss 1.0480 target_logit_mean 0.0004 lma 0.7006  cos_theta_tmp 0.8262  Epoch: 7   Global Step: 107400   Required: 29 hours
Training: 2025-12-01 07:08:53,013-Speed 1101.33 samples/sec   Loss 1.0278 target_logit_mean 0.0006 lma 0.6881  cos_theta_tmp 0.8225  Epoch: 7   Global Step: 107450   Required: 29 hours
Training: 2025-12-01 07:09:10,427-Speed 1102.59 samples/sec   Loss 1.0960 target_logit_mean -0.0014 lma 0.6910  cos_theta_tmp 0.8237  Epoch: 7   Global Step: 107500   Required: 29 hours
Training: 2025-12-01 07:09:27,858-Speed 1101.54 samples/sec   Loss 1.0603 target_logit_mean 0.0025 lma 0.6930  cos_theta_tmp 0.8268  Epoch: 7   Global Step: 107550   Required: 29 hours
Training: 2025-12-01 07:09:45,275-Speed 1102.37 samples/sec   Loss 1.0774 target_logit_mean 0.0015 lma 0.6827  cos_theta_tmp 0.8242  Epoch: 7   Global Step: 107600   Required: 29 hours
Training: 2025-12-01 07:10:02,699-Speed 1102.00 samples/sec   Loss 1.0558 target_logit_mean 0.0004 lma 0.6870  cos_theta_tmp 0.8209  Epoch: 7   Global Step: 107650   Required: 29 hours
Training: 2025-12-01 07:10:20,129-Speed 1101.62 samples/sec   Loss 1.1073 target_logit_mean -0.0006 lma 0.6814  cos_theta_tmp 0.8196  Epoch: 7   Global Step: 107700   Required: 29 hours
Training: 2025-12-01 07:10:37,541-Speed 1102.69 samples/sec   Loss 1.0421 target_logit_mean 0.0025 lma 0.6884  cos_theta_tmp 0.8269  Epoch: 7   Global Step: 107750   Required: 29 hours
Training: 2025-12-01 07:10:54,969-Speed 1101.71 samples/sec   Loss 1.0196 target_logit_mean 0.0002 lma 0.6897  cos_theta_tmp 0.8271  Epoch: 7   Global Step: 107800   Required: 29 hours
Training: 2025-12-01 07:11:12,380-Speed 1102.77 samples/sec   Loss 1.0186 target_logit_mean -0.0000 lma 0.6872  cos_theta_tmp 0.8208  Epoch: 7   Global Step: 107850   Required: 29 hours
Training: 2025-12-01 07:11:29,805-Speed 1101.94 samples/sec   Loss 1.0325 target_logit_mean -0.0005 lma 0.6860  cos_theta_tmp 0.8236  Epoch: 7   Global Step: 107900   Required: 29 hours
Training: 2025-12-01 07:11:47,223-Speed 1102.34 samples/sec   Loss 1.0237 target_logit_mean 0.0019 lma 0.6953  cos_theta_tmp 0.8304  Epoch: 7   Global Step: 107950   Required: 29 hours
Training: 2025-12-01 07:12:04,647-Speed 1101.97 samples/sec   Loss 1.0103 target_logit_mean -0.0002 lma 0.6977  cos_theta_tmp 0.8267  Epoch: 7   Global Step: 108000   Required: 29 hours
Training: 2025-12-01 07:12:22,072-Speed 1101.92 samples/sec   Loss 1.0193 target_logit_mean -0.0002 lma 0.6901  cos_theta_tmp 0.8272  Epoch: 7   Global Step: 108050   Required: 29 hours
Training: 2025-12-01 07:12:39,494-Speed 1102.11 samples/sec   Loss 1.0305 target_logit_mean -0.0006 lma 0.6896  cos_theta_tmp 0.8262  Epoch: 7   Global Step: 108100   Required: 29 hours
Training: 2025-12-01 07:12:56,920-Speed 1101.81 samples/sec   Loss 1.0425 target_logit_mean 0.0028 lma 0.6863  cos_theta_tmp 0.8280  Epoch: 7   Global Step: 108150   Required: 29 hours
Training: 2025-12-01 07:13:14,332-Speed 1102.74 samples/sec   Loss 1.0339 target_logit_mean -0.0002 lma 0.6836  cos_theta_tmp 0.8234  Epoch: 7   Global Step: 108200   Required: 29 hours
Training: 2025-12-01 07:13:31,761-Speed 1101.62 samples/sec   Loss 1.0590 target_logit_mean 0.0010 lma 0.6947  cos_theta_tmp 0.8226  Epoch: 7   Global Step: 108250   Required: 29 hours
Training: 2025-12-01 07:13:49,187-Speed 1101.85 samples/sec   Loss 1.0010 target_logit_mean -0.0013 lma 0.6944  cos_theta_tmp 0.8271  Epoch: 7   Global Step: 108300   Required: 29 hours
Training: 2025-12-01 07:14:06,600-Speed 1102.70 samples/sec   Loss 1.0272 target_logit_mean 0.0004 lma 0.6963  cos_theta_tmp 0.8293  Epoch: 7   Global Step: 108350   Required: 29 hours
Training: 2025-12-01 07:14:24,032-Speed 1101.44 samples/sec   Loss 1.0086 target_logit_mean -0.0017 lma 0.6960  cos_theta_tmp 0.8271  Epoch: 7   Global Step: 108400   Required: 29 hours
Training: 2025-12-01 07:14:41,450-Speed 1102.33 samples/sec   Loss 1.0137 target_logit_mean 0.0024 lma 0.6822  cos_theta_tmp 0.8254  Epoch: 7   Global Step: 108450   Required: 29 hours
Training: 2025-12-01 07:14:58,879-Speed 1101.70 samples/sec   Loss 1.0067 target_logit_mean -0.0003 lma 0.6901  cos_theta_tmp 0.8313  Epoch: 7   Global Step: 108500   Required: 29 hours
Training: 2025-12-01 07:15:16,293-Speed 1102.59 samples/sec   Loss 1.0132 target_logit_mean 0.0024 lma 0.6958  cos_theta_tmp 0.8283  Epoch: 7   Global Step: 108550   Required: 29 hours
Training: 2025-12-01 07:15:33,716-Speed 1102.01 samples/sec   Loss 1.0314 target_logit_mean -0.0018 lma 0.6954  cos_theta_tmp 0.8268  Epoch: 7   Global Step: 108600   Required: 29 hours
Training: 2025-12-01 07:15:51,149-Speed 1101.40 samples/sec   Loss 1.0069 target_logit_mean 0.0013 lma 0.6966  cos_theta_tmp 0.8280  Epoch: 7   Global Step: 108650   Required: 29 hours
Training: 2025-12-01 07:16:08,566-Speed 1102.42 samples/sec   Loss 0.9874 target_logit_mean 0.0004 lma 0.7006  cos_theta_tmp 0.8258  Epoch: 7   Global Step: 108700   Required: 29 hours
Training: 2025-12-01 07:16:25,996-Speed 1101.58 samples/sec   Loss 1.0338 target_logit_mean 0.0033 lma 0.7065  cos_theta_tmp 0.8290  Epoch: 7   Global Step: 108750   Required: 29 hours
Training: 2025-12-01 07:16:43,403-Speed 1103.01 samples/sec   Loss 1.0157 target_logit_mean -0.0001 lma 0.6822  cos_theta_tmp 0.8233  Epoch: 7   Global Step: 108800   Required: 29 hours
Training: 2025-12-01 07:17:00,834-Speed 1101.55 samples/sec   Loss 1.0025 target_logit_mean -0.0019 lma 0.6874  cos_theta_tmp 0.8232  Epoch: 7   Global Step: 108850   Required: 29 hours
Training: 2025-12-01 07:17:18,257-Speed 1102.04 samples/sec   Loss 0.9891 target_logit_mean 0.0004 lma 0.6906  cos_theta_tmp 0.8272  Epoch: 7   Global Step: 108900   Required: 29 hours
Training: 2025-12-01 07:17:35,671-Speed 1102.59 samples/sec   Loss 1.0116 target_logit_mean 0.0018 lma 0.6919  cos_theta_tmp 0.8316  Epoch: 7   Global Step: 108950   Required: 29 hours
Training: 2025-12-01 07:17:53,102-Speed 1101.50 samples/sec   Loss 1.0256 target_logit_mean 0.0020 lma 0.6982  cos_theta_tmp 0.8311  Epoch: 7   Global Step: 109000   Required: 29 hours
Training: 2025-12-01 07:18:10,514-Speed 1102.72 samples/sec   Loss 0.9693 target_logit_mean 0.0006 lma 0.6931  cos_theta_tmp 0.8256  Epoch: 7   Global Step: 109050   Required: 29 hours
Training: 2025-12-01 07:18:27,938-Speed 1101.99 samples/sec   Loss 1.0292 target_logit_mean 0.0008 lma 0.6913  cos_theta_tmp 0.8251  Epoch: 7   Global Step: 109100   Required: 29 hours
Training: 2025-12-01 07:18:45,355-Speed 1102.44 samples/sec   Loss 0.9856 target_logit_mean 0.0012 lma 0.6896  cos_theta_tmp 0.8326  Epoch: 7   Global Step: 109150   Required: 29 hours
Training: 2025-12-01 07:19:02,784-Speed 1101.60 samples/sec   Loss 0.9764 target_logit_mean 0.0027 lma 0.6979  cos_theta_tmp 0.8319  Epoch: 7   Global Step: 109200   Required: 29 hours
Training: 2025-12-01 07:19:20,211-Speed 1101.80 samples/sec   Loss 0.9796 target_logit_mean -0.0023 lma 0.6809  cos_theta_tmp 0.8260  Epoch: 7   Global Step: 109250   Required: 29 hours
Training: 2025-12-01 07:19:37,627-Speed 1102.48 samples/sec   Loss 0.9851 target_logit_mean -0.0004 lma 0.6946  cos_theta_tmp 0.8331  Epoch: 7   Global Step: 109300   Required: 29 hours
Training: 2025-12-01 07:19:55,051-Speed 1101.92 samples/sec   Loss 0.9840 target_logit_mean 0.0024 lma 0.6860  cos_theta_tmp 0.8289  Epoch: 7   Global Step: 109350   Required: 29 hours
Training: 2025-12-01 07:20:12,464-Speed 1102.68 samples/sec   Loss 0.9953 target_logit_mean -0.0007 lma 0.6812  cos_theta_tmp 0.8254  Epoch: 7   Global Step: 109400   Required: 29 hours
Training: 2025-12-01 07:20:29,892-Speed 1101.74 samples/sec   Loss 0.9962 target_logit_mean -0.0021 lma 0.6825  cos_theta_tmp 0.8224  Epoch: 7   Global Step: 109450   Required: 29 hours
Training: 2025-12-01 07:20:47,307-Speed 1102.51 samples/sec   Loss 0.9673 target_logit_mean -0.0007 lma 0.7003  cos_theta_tmp 0.8313  Epoch: 7   Global Step: 109500   Required: 29 hours
Training: 2025-12-01 07:21:04,739-Speed 1101.44 samples/sec   Loss 0.9946 target_logit_mean -0.0001 lma 0.6888  cos_theta_tmp 0.8318  Epoch: 7   Global Step: 109550   Required: 29 hours
Training: 2025-12-01 07:21:22,173-Speed 1101.32 samples/sec   Loss 0.9845 target_logit_mean 0.0019 lma 0.6989  cos_theta_tmp 0.8317  Epoch: 7   Global Step: 109600   Required: 29 hours
Training: 2025-12-01 07:21:39,593-Speed 1102.22 samples/sec   Loss 0.9620 target_logit_mean -0.0005 lma 0.6997  cos_theta_tmp 0.8271  Epoch: 7   Global Step: 109650   Required: 29 hours
Training: 2025-12-01 07:21:57,022-Speed 1101.64 samples/sec   Loss 0.9919 target_logit_mean 0.0004 lma 0.6889  cos_theta_tmp 0.8292  Epoch: 7   Global Step: 109700   Required: 29 hours
Training: 2025-12-01 07:22:14,439-Speed 1102.44 samples/sec   Loss 1.0162 target_logit_mean -0.0003 lma 0.6960  cos_theta_tmp 0.8296  Epoch: 7   Global Step: 109750   Required: 29 hours
Training: 2025-12-01 07:22:31,868-Speed 1101.65 samples/sec   Loss 0.9885 target_logit_mean 0.0018 lma 0.6911  cos_theta_tmp 0.8307  Epoch: 7   Global Step: 109800   Required: 29 hours
Training: 2025-12-01 07:22:49,293-Speed 1101.91 samples/sec   Loss 0.9499 target_logit_mean 0.0000 lma 0.6900  cos_theta_tmp 0.8289  Epoch: 7   Global Step: 109850   Required: 29 hours
Training: 2025-12-01 07:23:06,708-Speed 1102.53 samples/sec   Loss 0.9399 target_logit_mean -0.0015 lma 0.6873  cos_theta_tmp 0.8281  Epoch: 7   Global Step: 109900   Required: 29 hours
Training: 2025-12-01 07:23:24,135-Speed 1101.77 samples/sec   Loss 0.9785 target_logit_mean -0.0001 lma 0.6926  cos_theta_tmp 0.8294  Epoch: 7   Global Step: 109950   Required: 29 hours
Training: 2025-12-01 07:23:41,549-Speed 1102.61 samples/sec   Loss 0.9873 target_logit_mean 0.0003 lma 0.6951  cos_theta_tmp 0.8283  Epoch: 7   Global Step: 110000   Required: 29 hours
Training: 2025-12-01 07:23:58,975-Speed 1101.82 samples/sec   Loss 0.9817 target_logit_mean -0.0008 lma 0.6767  cos_theta_tmp 0.8283  Epoch: 7   Global Step: 110050   Required: 29 hours
Training: 2025-12-01 07:24:16,390-Speed 1102.53 samples/sec   Loss 0.9729 target_logit_mean -0.0019 lma 0.6871  cos_theta_tmp 0.8279  Epoch: 7   Global Step: 110100   Required: 29 hours
Training: 2025-12-01 07:24:33,817-Speed 1101.80 samples/sec   Loss 0.9877 target_logit_mean -0.0000 lma 0.6911  cos_theta_tmp 0.8281  Epoch: 7   Global Step: 110150   Required: 29 hours
Training: 2025-12-01 07:24:51,246-Speed 1101.65 samples/sec   Loss 1.0071 target_logit_mean 0.0005 lma 0.6887  cos_theta_tmp 0.8239  Epoch: 7   Global Step: 110200   Required: 29 hours
Training: 2025-12-01 07:25:08,660-Speed 1102.58 samples/sec   Loss 0.9891 target_logit_mean -0.0015 lma 0.6826  cos_theta_tmp 0.8267  Epoch: 7   Global Step: 110250   Required: 29 hours
Training: 2025-12-01 07:25:26,088-Speed 1101.70 samples/sec   Loss 0.9722 target_logit_mean -0.0017 lma 0.6805  cos_theta_tmp 0.8278  Epoch: 7   Global Step: 110300   Required: 29 hours
Training: 2025-12-01 07:25:43,504-Speed 1102.48 samples/sec   Loss 0.9884 target_logit_mean -0.0016 lma 0.6952  cos_theta_tmp 0.8259  Epoch: 7   Global Step: 110350   Required: 29 hours
Training: 2025-12-01 07:26:00,932-Speed 1101.72 samples/sec   Loss 0.9728 target_logit_mean -0.0006 lma 0.6886  cos_theta_tmp 0.8307  Epoch: 7   Global Step: 110400   Required: 29 hours
Training: 2025-12-01 07:26:18,344-Speed 1102.69 samples/sec   Loss 0.9714 target_logit_mean -0.0001 lma 0.6810  cos_theta_tmp 0.8267  Epoch: 7   Global Step: 110450   Required: 29 hours
Training: 2025-12-01 07:26:35,774-Speed 1101.62 samples/sec   Loss 0.9706 target_logit_mean 0.0005 lma 0.6964  cos_theta_tmp 0.8275  Epoch: 7   Global Step: 110500   Required: 29 hours
Training: 2025-12-01 07:26:53,198-Speed 1101.97 samples/sec   Loss 0.9937 target_logit_mean -0.0023 lma 0.6978  cos_theta_tmp 0.8298  Epoch: 7   Global Step: 110550   Required: 29 hours
Training: 2025-12-01 07:27:10,612-Speed 1102.57 samples/sec   Loss 1.0002 target_logit_mean 0.0003 lma 0.6936  cos_theta_tmp 0.8307  Epoch: 7   Global Step: 110600   Required: 29 hours
Training: 2025-12-01 07:27:28,040-Speed 1101.74 samples/sec   Loss 0.9729 target_logit_mean -0.0002 lma 0.7043  cos_theta_tmp 0.8301  Epoch: 7   Global Step: 110650   Required: 29 hours
Training: 2025-12-01 07:27:45,457-Speed 1102.42 samples/sec   Loss 0.9591 target_logit_mean -0.0017 lma 0.6884  cos_theta_tmp 0.8277  Epoch: 7   Global Step: 110700   Required: 29 hours
Training: 2025-12-01 07:28:02,882-Speed 1101.89 samples/sec   Loss 0.9509 target_logit_mean -0.0007 lma 0.6905  cos_theta_tmp 0.8289  Epoch: 7   Global Step: 110750   Required: 29 hours
Training: 2025-12-01 07:28:20,309-Speed 1101.76 samples/sec   Loss 1.0159 target_logit_mean 0.0007 lma 0.6887  cos_theta_tmp 0.8320  Epoch: 7   Global Step: 110800   Required: 29 hours
Training: 2025-12-01 07:28:37,719-Speed 1102.84 samples/sec   Loss 1.0241 target_logit_mean -0.0002 lma 0.6853  cos_theta_tmp 0.8284  Epoch: 7   Global Step: 110850   Required: 29 hours
Training: 2025-12-01 07:28:55,142-Speed 1102.07 samples/sec   Loss 0.9818 target_logit_mean 0.0002 lma 0.6941  cos_theta_tmp 0.8277  Epoch: 7   Global Step: 110900   Required: 29 hours
Training: 2025-12-01 07:29:12,560-Speed 1102.32 samples/sec   Loss 1.0298 target_logit_mean -0.0005 lma 0.6962  cos_theta_tmp 0.8294  Epoch: 7   Global Step: 110950   Required: 29 hours
Training: 2025-12-01 07:29:29,992-Speed 1101.46 samples/sec   Loss 0.9635 target_logit_mean -0.0002 lma 0.6888  cos_theta_tmp 0.8272  Epoch: 7   Global Step: 111000   Required: 29 hours
Training: 2025-12-01 07:29:47,412-Speed 1102.23 samples/sec   Loss 0.9290 target_logit_mean -0.0010 lma 0.6869  cos_theta_tmp 0.8287  Epoch: 7   Global Step: 111050   Required: 29 hours
Training: 2025-12-01 07:30:04,839-Speed 1101.78 samples/sec   Loss 0.9683 target_logit_mean -0.0005 lma 0.6922  cos_theta_tmp 0.8291  Epoch: 7   Global Step: 111100   Required: 29 hours
Training: 2025-12-01 07:30:22,263-Speed 1101.97 samples/sec   Loss 0.9645 target_logit_mean -0.0023 lma 0.6957  cos_theta_tmp 0.8264  Epoch: 7   Global Step: 111150   Required: 29 hours
Training: 2025-12-01 07:30:39,675-Speed 1102.68 samples/sec   Loss 1.0189 target_logit_mean -0.0014 lma 0.6918  cos_theta_tmp 0.8271  Epoch: 7   Global Step: 111200   Required: 29 hours
Training: 2025-12-01 07:30:57,107-Speed 1101.50 samples/sec   Loss 0.9706 target_logit_mean 0.0008 lma 0.6985  cos_theta_tmp 0.8283  Epoch: 7   Global Step: 111250   Required: 29 hours
Training: 2025-12-01 07:31:14,521-Speed 1102.57 samples/sec   Loss 0.9672 target_logit_mean 0.0010 lma 0.6930  cos_theta_tmp 0.8301  Epoch: 7   Global Step: 111300   Required: 29 hours
Training: 2025-12-01 07:31:31,949-Speed 1101.72 samples/sec   Loss 0.9826 target_logit_mean 0.0002 lma 0.6978  cos_theta_tmp 0.8273  Epoch: 7   Global Step: 111350   Required: 29 hours
Training: 2025-12-01 07:31:49,366-Speed 1102.38 samples/sec   Loss 0.9438 target_logit_mean -0.0000 lma 0.6938  cos_theta_tmp 0.8266  Epoch: 7   Global Step: 111400   Required: 29 hours
Training: 2025-12-01 07:32:06,800-Speed 1101.38 samples/sec   Loss 0.9866 target_logit_mean -0.0001 lma 0.6954  cos_theta_tmp 0.8294  Epoch: 7   Global Step: 111450   Required: 29 hours
Training: 2025-12-01 07:32:24,230-Speed 1101.57 samples/sec   Loss 1.0038 target_logit_mean -0.0011 lma 0.6923  cos_theta_tmp 0.8317  Epoch: 7   Global Step: 111500   Required: 29 hours
Training: 2025-12-01 07:32:41,643-Speed 1102.63 samples/sec   Loss 0.9761 target_logit_mean 0.0032 lma 0.6974  cos_theta_tmp 0.8268  Epoch: 7   Global Step: 111550   Required: 29 hours
Training: 2025-12-01 07:32:59,069-Speed 1101.83 samples/sec   Loss 0.9705 target_logit_mean -0.0006 lma 0.6872  cos_theta_tmp 0.8307  Epoch: 7   Global Step: 111600   Required: 29 hours
Training: 2025-12-01 07:33:16,485-Speed 1102.47 samples/sec   Loss 0.9939 target_logit_mean -0.0009 lma 0.6954  cos_theta_tmp 0.8283  Epoch: 7   Global Step: 111650   Required: 29 hours
Training: 2025-12-01 07:33:33,912-Speed 1101.80 samples/sec   Loss 1.0038 target_logit_mean 0.0017 lma 0.6899  cos_theta_tmp 0.8240  Epoch: 7   Global Step: 111700   Required: 29 hours
Training: 2025-12-01 07:33:51,341-Speed 1101.68 samples/sec   Loss 0.9723 target_logit_mean -0.0023 lma 0.6945  cos_theta_tmp 0.8303  Epoch: 7   Global Step: 111750   Required: 29 hours
Training: 2025-12-01 07:34:08,754-Speed 1102.62 samples/sec   Loss 0.9689 target_logit_mean -0.0016 lma 0.6791  cos_theta_tmp 0.8249  Epoch: 7   Global Step: 111800   Required: 29 hours
Training: 2025-12-01 07:34:26,183-Speed 1101.64 samples/sec   Loss 0.9728 target_logit_mean -0.0010 lma 0.6955  cos_theta_tmp 0.8296  Epoch: 7   Global Step: 111850   Required: 29 hours
Training: 2025-12-01 07:34:43,599-Speed 1102.48 samples/sec   Loss 0.9866 target_logit_mean 0.0006 lma 0.6894  cos_theta_tmp 0.8305  Epoch: 7   Global Step: 111900   Required: 29 hours
Training: 2025-12-01 07:35:01,021-Speed 1102.12 samples/sec   Loss 0.9797 target_logit_mean 0.0016 lma 0.6903  cos_theta_tmp 0.8297  Epoch: 7   Global Step: 111950   Required: 29 hours
Training: 2025-12-01 07:35:18,436-Speed 1102.52 samples/sec   Loss 0.9782 target_logit_mean 0.0012 lma 0.6908  cos_theta_tmp 0.8298  Epoch: 7   Global Step: 112000   Required: 29 hours
Training: 2025-12-01 07:35:35,863-Speed 1101.75 samples/sec   Loss 0.9543 target_logit_mean 0.0004 lma 0.7021  cos_theta_tmp 0.8289  Epoch: 7   Global Step: 112050   Required: 29 hours
Training: 2025-12-01 07:35:53,289-Speed 1101.86 samples/sec   Loss 0.9371 target_logit_mean 0.0027 lma 0.6850  cos_theta_tmp 0.8322  Epoch: 7   Global Step: 112100   Required: 28 hours
Training: 2025-12-01 07:36:10,703-Speed 1102.59 samples/sec   Loss 0.9748 target_logit_mean -0.0015 lma 0.6942  cos_theta_tmp 0.8287  Epoch: 7   Global Step: 112150   Required: 28 hours
Training: 2025-12-01 07:36:28,126-Speed 1102.01 samples/sec   Loss 0.9554 target_logit_mean -0.0001 lma 0.6838  cos_theta_tmp 0.8293  Epoch: 7   Global Step: 112200   Required: 28 hours
Training: 2025-12-01 07:36:45,541-Speed 1102.54 samples/sec   Loss 0.9622 target_logit_mean -0.0009 lma 0.6826  cos_theta_tmp 0.8270  Epoch: 7   Global Step: 112250   Required: 28 hours
Training: 2025-12-01 07:37:02,968-Speed 1101.79 samples/sec   Loss 0.9576 target_logit_mean -0.0022 lma 0.6794  cos_theta_tmp 0.8300  Epoch: 7   Global Step: 112300   Required: 28 hours
Training: 2025-12-01 07:37:20,390-Speed 1102.12 samples/sec   Loss 0.9591 target_logit_mean 0.0010 lma 0.6801  cos_theta_tmp 0.8279  Epoch: 7   Global Step: 112350   Required: 28 hours
Training: 2025-12-01 07:37:37,799-Speed 1102.91 samples/sec   Loss 0.9492 target_logit_mean 0.0001 lma 0.7032  cos_theta_tmp 0.8263  Epoch: 7   Global Step: 112400   Required: 28 hours
Training: 2025-12-01 07:37:55,223-Speed 1101.95 samples/sec   Loss 0.9773 target_logit_mean 0.0005 lma 0.6766  cos_theta_tmp 0.8300  Epoch: 7   Global Step: 112450   Required: 28 hours
Training: 2025-12-01 07:38:12,638-Speed 1102.52 samples/sec   Loss 0.9867 target_logit_mean -0.0024 lma 0.6960  cos_theta_tmp 0.8270  Epoch: 7   Global Step: 112500   Required: 28 hours
Training: 2025-12-01 07:38:30,065-Speed 1101.77 samples/sec   Loss 0.9617 target_logit_mean 0.0006 lma 0.6925  cos_theta_tmp 0.8319  Epoch: 7   Global Step: 112550   Required: 28 hours
Training: 2025-12-01 07:38:47,476-Speed 1102.80 samples/sec   Loss 0.9360 target_logit_mean 0.0016 lma 0.6804  cos_theta_tmp 0.8255  Epoch: 7   Global Step: 112600   Required: 28 hours
Training: 2025-12-01 07:39:04,906-Speed 1101.64 samples/sec   Loss 0.9845 target_logit_mean 0.0021 lma 0.6943  cos_theta_tmp 0.8323  Epoch: 7   Global Step: 112650   Required: 28 hours
Training: 2025-12-01 07:39:22,327-Speed 1102.13 samples/sec   Loss 0.9747 target_logit_mean -0.0010 lma 0.6735  cos_theta_tmp 0.8246  Epoch: 7   Global Step: 112700   Required: 28 hours
Training: 2025-12-01 07:39:39,740-Speed 1102.68 samples/sec   Loss 0.9413 target_logit_mean 0.0023 lma 0.6868  cos_theta_tmp 0.8281  Epoch: 7   Global Step: 112750   Required: 28 hours
Training: 2025-12-01 07:39:57,168-Speed 1101.68 samples/sec   Loss 0.9753 target_logit_mean 0.0006 lma 0.6989  cos_theta_tmp 0.8316  Epoch: 7   Global Step: 112800   Required: 28 hours
Training: 2025-12-01 07:40:14,578-Speed 1102.91 samples/sec   Loss 0.9644 target_logit_mean -0.0009 lma 0.6970  cos_theta_tmp 0.8278  Epoch: 7   Global Step: 112850   Required: 28 hours
Training: 2025-12-01 07:40:31,999-Speed 1102.14 samples/sec   Loss 0.9977 target_logit_mean -0.0023 lma 0.6942  cos_theta_tmp 0.8282  Epoch: 7   Global Step: 112900   Required: 28 hours
Training: 2025-12-01 07:40:49,414-Speed 1102.52 samples/sec   Loss 0.9637 target_logit_mean 0.0014 lma 0.6882  cos_theta_tmp 0.8242  Epoch: 7   Global Step: 112950   Required: 28 hours
Training: 2025-12-01 07:41:06,843-Speed 1101.67 samples/sec   Loss 0.9596 target_logit_mean -0.0014 lma 0.6906  cos_theta_tmp 0.8320  Epoch: 7   Global Step: 113000   Required: 28 hours
Training: 2025-12-01 07:41:24,270-Speed 1101.74 samples/sec   Loss 0.9474 target_logit_mean 0.0034 lma 0.6822  cos_theta_tmp 0.8352  Epoch: 7   Global Step: 113050   Required: 28 hours
Training: 2025-12-01 07:41:41,684-Speed 1102.64 samples/sec   Loss 0.9672 target_logit_mean -0.0002 lma 0.6881  cos_theta_tmp 0.8301  Epoch: 7   Global Step: 113100   Required: 28 hours
Training: 2025-12-01 07:41:59,105-Speed 1102.14 samples/sec   Loss 0.9764 target_logit_mean 0.0003 lma 0.6831  cos_theta_tmp 0.8263  Epoch: 7   Global Step: 113150   Required: 28 hours
Training: 2025-12-01 07:42:16,520-Speed 1102.52 samples/sec   Loss 0.9599 target_logit_mean 0.0002 lma 0.6914  cos_theta_tmp 0.8305  Epoch: 7   Global Step: 113200   Required: 28 hours
Training: 2025-12-01 07:42:33,949-Speed 1101.69 samples/sec   Loss 0.9345 target_logit_mean 0.0027 lma 0.6969  cos_theta_tmp 0.8333  Epoch: 7   Global Step: 113250   Required: 28 hours
Training: 2025-12-01 07:42:51,374-Speed 1101.85 samples/sec   Loss 0.9298 target_logit_mean -0.0003 lma 0.6850  cos_theta_tmp 0.8266  Epoch: 7   Global Step: 113300   Required: 28 hours
Training: 2025-12-01 07:43:08,784-Speed 1102.86 samples/sec   Loss 0.9688 target_logit_mean -0.0003 lma 0.6931  cos_theta_tmp 0.8277  Epoch: 7   Global Step: 113350   Required: 28 hours
Training: 2025-12-01 07:43:26,209-Speed 1101.95 samples/sec   Loss 0.9430 target_logit_mean -0.0001 lma 0.6889  cos_theta_tmp 0.8293  Epoch: 7   Global Step: 113400   Required: 28 hours
Training: 2025-12-01 07:43:43,623-Speed 1102.57 samples/sec   Loss 0.9490 target_logit_mean 0.0005 lma 0.6981  cos_theta_tmp 0.8324  Epoch: 7   Global Step: 113450   Required: 28 hours
Training: 2025-12-01 07:44:01,047-Speed 1101.98 samples/sec   Loss 0.9337 target_logit_mean 0.0013 lma 0.6875  cos_theta_tmp 0.8297  Epoch: 7   Global Step: 113500   Required: 28 hours
Training: 2025-12-01 07:44:18,460-Speed 1102.68 samples/sec   Loss 0.9436 target_logit_mean 0.0006 lma 0.6931  cos_theta_tmp 0.8267  Epoch: 7   Global Step: 113550   Required: 28 hours
Training: 2025-12-01 07:44:35,888-Speed 1101.72 samples/sec   Loss 0.9554 target_logit_mean -0.0005 lma 0.6924  cos_theta_tmp 0.8306  Epoch: 7   Global Step: 113600   Required: 28 hours
Training: 2025-12-01 07:44:53,311-Speed 1102.01 samples/sec   Loss 0.9530 target_logit_mean 0.0014 lma 0.6838  cos_theta_tmp 0.8262  Epoch: 7   Global Step: 113650   Required: 28 hours
Training: 2025-12-01 07:45:10,728-Speed 1102.39 samples/sec   Loss 0.9808 target_logit_mean -0.0018 lma 0.6883  cos_theta_tmp 0.8276  Epoch: 7   Global Step: 113700   Required: 28 hours
Training: 2025-12-01 07:45:28,156-Speed 1101.77 samples/sec   Loss 0.9764 target_logit_mean -0.0006 lma 0.6901  cos_theta_tmp 0.8257  Epoch: 7   Global Step: 113750   Required: 28 hours
Training: 2025-12-01 07:45:45,568-Speed 1102.68 samples/sec   Loss 0.9697 target_logit_mean -0.0013 lma 0.6980  cos_theta_tmp 0.8258  Epoch: 7   Global Step: 113800   Required: 28 hours
Training: 2025-12-01 07:46:02,995-Speed 1101.81 samples/sec   Loss 0.9410 target_logit_mean 0.0005 lma 0.6903  cos_theta_tmp 0.8276  Epoch: 7   Global Step: 113850   Required: 28 hours
Training: 2025-12-01 07:46:20,422-Speed 1101.76 samples/sec   Loss 0.9575 target_logit_mean 0.0005 lma 0.6857  cos_theta_tmp 0.8280  Epoch: 7   Global Step: 113900   Required: 28 hours
Training: 2025-12-01 07:46:37,835-Speed 1102.64 samples/sec   Loss 0.9564 target_logit_mean 0.0009 lma 0.6890  cos_theta_tmp 0.8302  Epoch: 7   Global Step: 113950   Required: 28 hours
Training: 2025-12-01 07:46:55,263-Speed 1101.77 samples/sec   Loss 0.9941 target_logit_mean 0.0031 lma 0.6895  cos_theta_tmp 0.8313  Epoch: 7   Global Step: 114000   Required: 28 hours
Training: 2025-12-01 07:47:12,679-Speed 1102.48 samples/sec   Loss 0.9517 target_logit_mean 0.0013 lma 0.6907  cos_theta_tmp 0.8262  Epoch: 7   Global Step: 114050   Required: 28 hours
Training: 2025-12-01 07:47:30,108-Speed 1101.65 samples/sec   Loss 0.9694 target_logit_mean 0.0039 lma 0.6857  cos_theta_tmp 0.8282  Epoch: 7   Global Step: 114100   Required: 28 hours
Training: 2025-12-01 07:47:47,526-Speed 1102.33 samples/sec   Loss 0.9709 target_logit_mean 0.0020 lma 0.6979  cos_theta_tmp 0.8302  Epoch: 7   Global Step: 114150   Required: 28 hours
Training: 2025-12-01 07:48:04,956-Speed 1101.60 samples/sec   Loss 0.9596 target_logit_mean -0.0002 lma 0.6843  cos_theta_tmp 0.8274  Epoch: 7   Global Step: 114200   Required: 28 hours
Training: 2025-12-01 07:48:22,378-Speed 1102.07 samples/sec   Loss 0.9534 target_logit_mean 0.0046 lma 0.6931  cos_theta_tmp 0.8325  Epoch: 7   Global Step: 114250   Required: 28 hours
Training: 2025-12-01 07:48:39,792-Speed 1102.63 samples/sec   Loss 0.9812 target_logit_mean 0.0009 lma 0.6930  cos_theta_tmp 0.8309  Epoch: 7   Global Step: 114300   Required: 28 hours
Training: 2025-12-01 07:48:57,219-Speed 1101.78 samples/sec   Loss 0.9493 target_logit_mean -0.0015 lma 0.6862  cos_theta_tmp 0.8269  Epoch: 7   Global Step: 114350   Required: 28 hours
Training: 2025-12-01 07:49:14,632-Speed 1102.67 samples/sec   Loss 0.9622 target_logit_mean -0.0015 lma 0.6905  cos_theta_tmp 0.8274  Epoch: 7   Global Step: 114400   Required: 28 hours
Training: 2025-12-01 07:49:32,060-Speed 1101.70 samples/sec   Loss 0.9634 target_logit_mean 0.0001 lma 0.6932  cos_theta_tmp 0.8271  Epoch: 7   Global Step: 114450   Required: 28 hours
Training: 2025-12-01 07:49:49,469-Speed 1102.90 samples/sec   Loss 0.9681 target_logit_mean -0.0020 lma 0.6940  cos_theta_tmp 0.8289  Epoch: 7   Global Step: 114500   Required: 28 hours
Training: 2025-12-01 07:50:06,894-Speed 1101.93 samples/sec   Loss 0.9559 target_logit_mean 0.0005 lma 0.6912  cos_theta_tmp 0.8286  Epoch: 7   Global Step: 114550   Required: 28 hours
Training: 2025-12-01 07:50:24,320-Speed 1101.85 samples/sec   Loss 0.9455 target_logit_mean -0.0003 lma 0.6868  cos_theta_tmp 0.8291  Epoch: 7   Global Step: 114600   Required: 28 hours
Training: 2025-12-01 07:50:41,733-Speed 1102.69 samples/sec   Loss 0.9679 target_logit_mean 0.0018 lma 0.6890  cos_theta_tmp 0.8276  Epoch: 7   Global Step: 114650   Required: 28 hours
Training: 2025-12-01 07:50:59,162-Speed 1101.61 samples/sec   Loss 0.9470 target_logit_mean 0.0002 lma 0.6912  cos_theta_tmp 0.8281  Epoch: 7   Global Step: 114700   Required: 28 hours
Training: 2025-12-01 07:51:16,575-Speed 1102.70 samples/sec   Loss 0.9746 target_logit_mean 0.0009 lma 0.6824  cos_theta_tmp 0.8300  Epoch: 7   Global Step: 114750   Required: 28 hours
Training: 2025-12-01 07:51:33,996-Speed 1102.11 samples/sec   Loss 0.9664 target_logit_mean 0.0005 lma 0.6832  cos_theta_tmp 0.8296  Epoch: 7   Global Step: 114800   Required: 28 hours
Training: 2025-12-01 07:51:51,425-Speed 1101.68 samples/sec   Loss 0.9714 target_logit_mean 0.0010 lma 0.6737  cos_theta_tmp 0.8291  Epoch: 7   Global Step: 114850   Required: 28 hours
Training: 2025-12-01 07:52:08,841-Speed 1102.47 samples/sec   Loss 1.0286 target_logit_mean 0.0019 lma 0.6918  cos_theta_tmp 0.8323  Epoch: 7   Global Step: 114900   Required: 28 hours
Training: 2025-12-01 07:52:26,267-Speed 1101.82 samples/sec   Loss 0.9834 target_logit_mean -0.0003 lma 0.6996  cos_theta_tmp 0.8272  Epoch: 7   Global Step: 114950   Required: 28 hours
Training: 2025-12-01 07:52:43,687-Speed 1102.25 samples/sec   Loss 0.9866 target_logit_mean -0.0003 lma 0.6958  cos_theta_tmp 0.8289  Epoch: 7   Global Step: 115000   Required: 28 hours
Training: 2025-12-01 07:53:01,119-Speed 1101.45 samples/sec   Loss 0.9620 target_logit_mean -0.0010 lma 0.6943  cos_theta_tmp 0.8296  Epoch: 7   Global Step: 115050   Required: 28 hours
Training: 2025-12-01 07:53:18,535-Speed 1102.49 samples/sec   Loss 0.9800 target_logit_mean 0.0000 lma 0.6962  cos_theta_tmp 0.8319  Epoch: 7   Global Step: 115100   Required: 28 hours
Training: 2025-12-01 07:53:35,962-Speed 1101.74 samples/sec   Loss 0.9667 target_logit_mean -0.0014 lma 0.6946  cos_theta_tmp 0.8251  Epoch: 7   Global Step: 115150   Required: 28 hours
Training: 2025-12-01 07:53:53,388-Speed 1101.82 samples/sec   Loss 0.9792 target_logit_mean 0.0007 lma 0.6913  cos_theta_tmp 0.8263  Epoch: 7   Global Step: 115200   Required: 28 hours
Training: 2025-12-01 07:54:10,805-Speed 1102.48 samples/sec   Loss 0.9653 target_logit_mean 0.0040 lma 0.6922  cos_theta_tmp 0.8325  Epoch: 7   Global Step: 115250   Required: 28 hours
Training: 2025-12-01 07:54:28,232-Speed 1101.75 samples/sec   Loss 0.9987 target_logit_mean -0.0008 lma 0.6777  cos_theta_tmp 0.8300  Epoch: 7   Global Step: 115300   Required: 28 hours
Training: 2025-12-01 07:54:45,647-Speed 1102.52 samples/sec   Loss 0.9537 target_logit_mean -0.0010 lma 0.6875  cos_theta_tmp 0.8250  Epoch: 7   Global Step: 115350   Required: 28 hours
Training: 2025-12-01 07:55:03,074-Speed 1101.80 samples/sec   Loss 0.9793 target_logit_mean 0.0009 lma 0.6899  cos_theta_tmp 0.8270  Epoch: 7   Global Step: 115400   Required: 28 hours
Training: 2025-12-01 07:55:20,488-Speed 1102.59 samples/sec   Loss 0.9861 target_logit_mean 0.0019 lma 0.6907  cos_theta_tmp 0.8270  Epoch: 7   Global Step: 115450   Required: 28 hours
Training: 2025-12-01 07:55:37,921-Speed 1101.40 samples/sec   Loss 0.9888 target_logit_mean 0.0018 lma 0.6897  cos_theta_tmp 0.8305  Epoch: 7   Global Step: 115500   Required: 28 hours
Training: 2025-12-01 07:55:55,352-Speed 1101.52 samples/sec   Loss 1.0004 target_logit_mean 0.0008 lma 0.6954  cos_theta_tmp 0.8281  Epoch: 7   Global Step: 115550   Required: 28 hours
Training: 2025-12-01 07:56:12,767-Speed 1102.55 samples/sec   Loss 0.9808 target_logit_mean -0.0009 lma 0.6912  cos_theta_tmp 0.8247  Epoch: 7   Global Step: 115600   Required: 28 hours
Training: 2025-12-01 07:56:30,193-Speed 1101.88 samples/sec   Loss 1.0018 target_logit_mean 0.0017 lma 0.6880  cos_theta_tmp 0.8294  Epoch: 7   Global Step: 115650   Required: 28 hours
Training: 2025-12-01 07:56:47,610-Speed 1102.41 samples/sec   Loss 0.9854 target_logit_mean -0.0002 lma 0.6894  cos_theta_tmp 0.8274  Epoch: 7   Global Step: 115700   Required: 28 hours
Training: 2025-12-01 07:57:05,040-Speed 1101.56 samples/sec   Loss 0.9352 target_logit_mean 0.0001 lma 0.6866  cos_theta_tmp 0.8251  Epoch: 7   Global Step: 115750   Required: 28 hours
Training: 2025-12-01 07:57:22,468-Speed 1101.68 samples/sec   Loss 0.9541 target_logit_mean 0.0015 lma 0.6906  cos_theta_tmp 0.8297  Epoch: 7   Global Step: 115800   Required: 28 hours
Training: 2025-12-01 07:57:39,885-Speed 1102.45 samples/sec   Loss 0.9768 target_logit_mean -0.0008 lma 0.6931  cos_theta_tmp 0.8273  Epoch: 7   Global Step: 115850   Required: 28 hours
Training: 2025-12-01 07:57:57,311-Speed 1101.83 samples/sec   Loss 0.9361 target_logit_mean -0.0003 lma 0.6943  cos_theta_tmp 0.8269  Epoch: 7   Global Step: 115900   Required: 28 hours
Training: 2025-12-01 07:58:14,721-Speed 1102.86 samples/sec   Loss 0.9532 target_logit_mean -0.0001 lma 0.6902  cos_theta_tmp 0.8252  Epoch: 7   Global Step: 115950   Required: 28 hours
Training: 2025-12-01 07:58:32,147-Speed 1101.79 samples/sec   Loss 0.9585 target_logit_mean -0.0006 lma 0.6880  cos_theta_tmp 0.8233  Epoch: 7   Global Step: 116000   Required: 28 hours
Training: 2025-12-01 07:58:49,562-Speed 1102.56 samples/sec   Loss 0.9434 target_logit_mean -0.0016 lma 0.6968  cos_theta_tmp 0.8247  Epoch: 7   Global Step: 116050   Required: 28 hours
Training: 2025-12-01 07:59:06,989-Speed 1101.75 samples/sec   Loss 0.9595 target_logit_mean 0.0010 lma 0.6932  cos_theta_tmp 0.8302  Epoch: 7   Global Step: 116100   Required: 28 hours
Training: 2025-12-01 07:59:24,414-Speed 1101.93 samples/sec   Loss 0.9813 target_logit_mean -0.0007 lma 0.6877  cos_theta_tmp 0.8316  Epoch: 7   Global Step: 116150   Required: 28 hours
Training: 2025-12-01 07:59:41,825-Speed 1102.78 samples/sec   Loss 0.9928 target_logit_mean 0.0020 lma 0.6809  cos_theta_tmp 0.8231  Epoch: 7   Global Step: 116200   Required: 28 hours
Training: 2025-12-01 07:59:59,253-Speed 1101.72 samples/sec   Loss 0.9633 target_logit_mean -0.0039 lma 0.6912  cos_theta_tmp 0.8259  Epoch: 7   Global Step: 116250   Required: 28 hours
Training: 2025-12-01 08:00:16,663-Speed 1102.85 samples/sec   Loss 0.9767 target_logit_mean -0.0005 lma 0.6938  cos_theta_tmp 0.8301  Epoch: 7   Global Step: 116300   Required: 28 hours
Training: 2025-12-01 08:00:34,091-Speed 1101.71 samples/sec   Loss 1.0070 target_logit_mean 0.0021 lma 0.6923  cos_theta_tmp 0.8316  Epoch: 7   Global Step: 116350   Required: 28 hours
Training: 2025-12-01 08:00:51,500-Speed 1102.91 samples/sec   Loss 0.9444 target_logit_mean 0.0010 lma 0.6922  cos_theta_tmp 0.8289  Epoch: 7   Global Step: 116400   Required: 28 hours
Training: 2025-12-01 08:01:08,930-Speed 1101.58 samples/sec   Loss 1.0028 target_logit_mean 0.0011 lma 0.6861  cos_theta_tmp 0.8253  Epoch: 7   Global Step: 116450   Required: 28 hours
Training: 2025-12-01 08:01:26,354-Speed 1101.98 samples/sec   Loss 0.9415 target_logit_mean -0.0021 lma 0.6936  cos_theta_tmp 0.8289  Epoch: 7   Global Step: 116500   Required: 28 hours
Training: 2025-12-01 08:01:43,768-Speed 1102.57 samples/sec   Loss 0.9844 target_logit_mean 0.0003 lma 0.6834  cos_theta_tmp 0.8259  Epoch: 7   Global Step: 116550   Required: 28 hours
Training: 2025-12-01 08:02:01,195-Speed 1101.79 samples/sec   Loss 0.9868 target_logit_mean 0.0019 lma 0.7036  cos_theta_tmp 0.8266  Epoch: 7   Global Step: 116600   Required: 28 hours
Training: 2025-12-01 08:02:18,606-Speed 1102.80 samples/sec   Loss 0.9768 target_logit_mean 0.0023 lma 0.6936  cos_theta_tmp 0.8303  Epoch: 7   Global Step: 116650   Required: 28 hours
Training: 2025-12-01 08:02:36,029-Speed 1101.99 samples/sec   Loss 0.9871 target_logit_mean 0.0013 lma 0.6921  cos_theta_tmp 0.8307  Epoch: 7   Global Step: 116700   Required: 28 hours
Training: 2025-12-01 08:02:53,459-Speed 1101.63 samples/sec   Loss 0.9805 target_logit_mean -0.0000 lma 0.6853  cos_theta_tmp 0.8267  Epoch: 7   Global Step: 116750   Required: 28 hours
Training: 2025-12-01 08:03:10,875-Speed 1102.46 samples/sec   Loss 1.0020 target_logit_mean -0.0014 lma 0.6977  cos_theta_tmp 0.8271  Epoch: 7   Global Step: 116800   Required: 28 hours
Training: 2025-12-01 08:03:28,300-Speed 1101.92 samples/sec   Loss 0.9622 target_logit_mean 0.0012 lma 0.6852  cos_theta_tmp 0.8282  Epoch: 7   Global Step: 116850   Required: 28 hours
Training: 2025-12-01 08:03:45,714-Speed 1102.57 samples/sec   Loss 0.9749 target_logit_mean -0.0018 lma 0.6962  cos_theta_tmp 0.8240  Epoch: 7   Global Step: 116900   Required: 28 hours
Training: 2025-12-01 08:04:03,140-Speed 1101.84 samples/sec   Loss 0.9664 target_logit_mean 0.0015 lma 0.6985  cos_theta_tmp 0.8325  Epoch: 7   Global Step: 116950   Required: 28 hours
Training: 2025-12-01 08:04:20,548-Speed 1102.97 samples/sec   Loss 1.0255 target_logit_mean 0.0009 lma 0.6808  cos_theta_tmp 0.8291  Epoch: 7   Global Step: 117000   Required: 28 hours
Training: 2025-12-01 08:04:37,975-Speed 1101.77 samples/sec   Loss 0.9762 target_logit_mean 0.0005 lma 0.7010  cos_theta_tmp 0.8295  Epoch: 7   Global Step: 117050   Required: 28 hours
Training: 2025-12-01 08:04:55,403-Speed 1101.72 samples/sec   Loss 0.9631 target_logit_mean -0.0008 lma 0.6828  cos_theta_tmp 0.8224  Epoch: 7   Global Step: 117100   Required: 28 hours
Training: 2025-12-01 08:05:12,813-Speed 1102.86 samples/sec   Loss 0.9609 target_logit_mean 0.0007 lma 0.6981  cos_theta_tmp 0.8264  Epoch: 7   Global Step: 117150   Required: 28 hours
Training: 2025-12-01 08:05:30,240-Speed 1101.80 samples/sec   Loss 0.9835 target_logit_mean 0.0000 lma 0.6907  cos_theta_tmp 0.8225  Epoch: 7   Global Step: 117200   Required: 28 hours
Training: 2025-12-01 08:05:47,649-Speed 1102.93 samples/sec   Loss 1.0056 target_logit_mean 0.0002 lma 0.6859  cos_theta_tmp 0.8269  Epoch: 7   Global Step: 117250   Required: 28 hours
Training: 2025-12-01 08:06:05,078-Speed 1101.62 samples/sec   Loss 1.0045 target_logit_mean 0.0006 lma 0.6745  cos_theta_tmp 0.8271  Epoch: 7   Global Step: 117300   Required: 28 hours
Training: 2025-12-01 08:06:22,497-Speed 1102.26 samples/sec   Loss 0.9746 target_logit_mean -0.0005 lma 0.6902  cos_theta_tmp 0.8287  Epoch: 7   Global Step: 117350   Required: 28 hours
Training: 2025-12-01 08:06:39,914-Speed 1102.42 samples/sec   Loss 0.9746 target_logit_mean -0.0000 lma 0.6969  cos_theta_tmp 0.8260  Epoch: 7   Global Step: 117400   Required: 28 hours
Training: 2025-12-01 08:06:57,342-Speed 1101.72 samples/sec   Loss 1.0260 target_logit_mean -0.0017 lma 0.6782  cos_theta_tmp 0.8265  Epoch: 7   Global Step: 117450   Required: 28 hours
Training: 2025-12-01 08:07:14,758-Speed 1102.47 samples/sec   Loss 1.0355 target_logit_mean -0.0010 lma 0.6860  cos_theta_tmp 0.8250  Epoch: 7   Global Step: 117500   Required: 28 hours
Training: 2025-12-01 08:07:32,182-Speed 1102.00 samples/sec   Loss 0.9542 target_logit_mean 0.0016 lma 0.6957  cos_theta_tmp 0.8298  Epoch: 7   Global Step: 117550   Required: 28 hours
Training: 2025-12-01 08:07:49,601-Speed 1102.25 samples/sec   Loss 1.0026 target_logit_mean -0.0004 lma 0.6915  cos_theta_tmp 0.8245  Epoch: 7   Global Step: 117600   Required: 28 hours
Training: 2025-12-01 08:08:07,024-Speed 1102.04 samples/sec   Loss 0.9625 target_logit_mean 0.0026 lma 0.7006  cos_theta_tmp 0.8298  Epoch: 7   Global Step: 117650   Required: 28 hours
Training: 2025-12-01 08:08:24,446-Speed 1102.08 samples/sec   Loss 0.9918 target_logit_mean -0.0002 lma 0.6869  cos_theta_tmp 0.8243  Epoch: 7   Global Step: 117700   Required: 28 hours
Training: 2025-12-01 08:08:41,855-Speed 1102.91 samples/sec   Loss 0.9981 target_logit_mean -0.0018 lma 0.6834  cos_theta_tmp 0.8236  Epoch: 7   Global Step: 117750   Required: 28 hours
Training: 2025-12-01 08:08:59,283-Speed 1101.71 samples/sec   Loss 0.9738 target_logit_mean 0.0010 lma 0.6802  cos_theta_tmp 0.8250  Epoch: 7   Global Step: 117800   Required: 28 hours
Training: 2025-12-01 08:09:16,698-Speed 1102.54 samples/sec   Loss 0.9916 target_logit_mean 0.0004 lma 0.6792  cos_theta_tmp 0.8252  Epoch: 7   Global Step: 117850   Required: 28 hours
Training: 2025-12-01 08:09:34,126-Speed 1101.75 samples/sec   Loss 0.9800 target_logit_mean -0.0000 lma 0.6875  cos_theta_tmp 0.8238  Epoch: 7   Global Step: 117900   Required: 28 hours
Training: 2025-12-01 08:09:51,538-Speed 1102.74 samples/sec   Loss 1.0131 target_logit_mean 0.0019 lma 0.6974  cos_theta_tmp 0.8307  Epoch: 7   Global Step: 117950   Required: 28 hours
Training: 2025-12-01 08:10:08,963-Speed 1101.90 samples/sec   Loss 0.9679 target_logit_mean 0.0010 lma 0.6913  cos_theta_tmp 0.8297  Epoch: 7   Global Step: 118000   Required: 28 hours
Training: 2025-12-01 08:10:26,388-Speed 1101.91 samples/sec   Loss 0.9760 target_logit_mean -0.0002 lma 0.6840  cos_theta_tmp 0.8284  Epoch: 7   Global Step: 118050   Required: 28 hours
Training: 2025-12-01 08:10:43,800-Speed 1102.72 samples/sec   Loss 1.0090 target_logit_mean -0.0023 lma 0.6905  cos_theta_tmp 0.8226  Epoch: 7   Global Step: 118100   Required: 28 hours
Training: 2025-12-01 08:11:01,227-Speed 1101.80 samples/sec   Loss 0.9971 target_logit_mean 0.0022 lma 0.6854  cos_theta_tmp 0.8234  Epoch: 7   Global Step: 118150   Required: 28 hours
Training: 2025-12-01 08:11:18,641-Speed 1102.58 samples/sec   Loss 1.0146 target_logit_mean 0.0020 lma 0.6933  cos_theta_tmp 0.8282  Epoch: 7   Global Step: 118200   Required: 28 hours
Training: 2025-12-01 08:11:36,067-Speed 1101.80 samples/sec   Loss 0.9578 target_logit_mean 0.0008 lma 0.6989  cos_theta_tmp 0.8314  Epoch: 7   Global Step: 118250   Required: 28 hours
Training: 2025-12-01 08:11:53,494-Speed 1101.78 samples/sec   Loss 1.0079 target_logit_mean 0.0021 lma 0.6945  cos_theta_tmp 0.8282  Epoch: 7   Global Step: 118300   Required: 28 hours
Training: 2025-12-01 08:12:10,910-Speed 1102.48 samples/sec   Loss 1.0038 target_logit_mean 0.0013 lma 0.6881  cos_theta_tmp 0.8266  Epoch: 7   Global Step: 118350   Required: 28 hours
Training: 2025-12-01 08:12:28,338-Speed 1101.73 samples/sec   Loss 0.9757 target_logit_mean 0.0045 lma 0.6887  cos_theta_tmp 0.8288  Epoch: 7   Global Step: 118400   Required: 28 hours
Training: 2025-12-01 08:12:45,756-Speed 1102.34 samples/sec   Loss 0.9948 target_logit_mean -0.0008 lma 0.6802  cos_theta_tmp 0.8232  Epoch: 7   Global Step: 118450   Required: 28 hours
Training: 2025-12-01 08:13:03,185-Speed 1101.66 samples/sec   Loss 0.9802 target_logit_mean -0.0003 lma 0.6895  cos_theta_tmp 0.8259  Epoch: 7   Global Step: 118500   Required: 28 hours
Training: 2025-12-01 08:13:20,601-Speed 1102.46 samples/sec   Loss 0.9880 target_logit_mean 0.0008 lma 0.6870  cos_theta_tmp 0.8260  Epoch: 7   Global Step: 118550   Required: 28 hours
Training: 2025-12-01 08:13:38,025-Speed 1101.95 samples/sec   Loss 0.9970 target_logit_mean -0.0018 lma 0.6846  cos_theta_tmp 0.8218  Epoch: 7   Global Step: 118600   Required: 28 hours
Training: 2025-12-01 08:13:55,451-Speed 1101.85 samples/sec   Loss 0.9724 target_logit_mean -0.0003 lma 0.6963  cos_theta_tmp 0.8334  Epoch: 7   Global Step: 118650   Required: 28 hours
Training: 2025-12-01 08:14:12,862-Speed 1102.81 samples/sec   Loss 1.0460 target_logit_mean 0.0007 lma 0.6910  cos_theta_tmp 0.8275  Epoch: 7   Global Step: 118700   Required: 28 hours
Training: 2025-12-01 08:14:30,291-Speed 1101.66 samples/sec   Loss 1.0423 target_logit_mean -0.0005 lma 0.6870  cos_theta_tmp 0.8234  Epoch: 7   Global Step: 118750   Required: 28 hours
Training: 2025-12-01 08:14:47,702-Speed 1102.75 samples/sec   Loss 0.9745 target_logit_mean -0.0018 lma 0.6815  cos_theta_tmp 0.8257  Epoch: 7   Global Step: 118800   Required: 28 hours
Training: 2025-12-01 08:15:05,128-Speed 1101.87 samples/sec   Loss 0.9967 target_logit_mean -0.0003 lma 0.6960  cos_theta_tmp 0.8268  Epoch: 7   Global Step: 118850   Required: 28 hours
Training: 2025-12-01 08:15:22,544-Speed 1102.42 samples/sec   Loss 0.9955 target_logit_mean 0.0002 lma 0.6931  cos_theta_tmp 0.8295  Epoch: 7   Global Step: 118900   Required: 28 hours
Training: 2025-12-01 08:15:39,969-Speed 1101.95 samples/sec   Loss 1.0141 target_logit_mean -0.0009 lma 0.6896  cos_theta_tmp 0.8246  Epoch: 7   Global Step: 118950   Required: 28 hours
Training: 2025-12-01 08:15:57,397-Speed 1101.72 samples/sec   Loss 0.9838 target_logit_mean 0.0026 lma 0.6944  cos_theta_tmp 0.8268  Epoch: 7   Global Step: 119000   Required: 28 hours
Training: 2025-12-01 08:16:14,811-Speed 1102.58 samples/sec   Loss 0.9800 target_logit_mean -0.0004 lma 0.6960  cos_theta_tmp 0.8298  Epoch: 7   Global Step: 119050   Required: 28 hours
Training: 2025-12-01 08:16:32,242-Speed 1101.56 samples/sec   Loss 0.9612 target_logit_mean -0.0016 lma 0.6881  cos_theta_tmp 0.8299  Epoch: 7   Global Step: 119100   Required: 28 hours
Training: 2025-12-01 08:16:49,660-Speed 1102.33 samples/sec   Loss 0.9522 target_logit_mean 0.0003 lma 0.6927  cos_theta_tmp 0.8260  Epoch: 7   Global Step: 119150   Required: 28 hours
Training: 2025-12-01 08:17:07,084-Speed 1101.97 samples/sec   Loss 1.0013 target_logit_mean -0.0030 lma 0.6847  cos_theta_tmp 0.8198  Epoch: 7   Global Step: 119200   Required: 28 hours
Training: 2025-12-01 08:17:24,513-Speed 1101.63 samples/sec   Loss 1.0180 target_logit_mean 0.0010 lma 0.6903  cos_theta_tmp 0.8274  Epoch: 7   Global Step: 119250   Required: 28 hours
Training: 2025-12-01 08:17:41,932-Speed 1102.31 samples/sec   Loss 1.0031 target_logit_mean 0.0024 lma 0.6959  cos_theta_tmp 0.8323  Epoch: 7   Global Step: 119300   Required: 28 hours
Training: 2025-12-01 08:17:59,359-Speed 1101.79 samples/sec   Loss 0.9787 target_logit_mean -0.0001 lma 0.6876  cos_theta_tmp 0.8212  Epoch: 7   Global Step: 119350   Required: 28 hours
Training: 2025-12-01 08:18:16,767-Speed 1102.99 samples/sec   Loss 0.9861 target_logit_mean -0.0017 lma 0.6887  cos_theta_tmp 0.8280  Epoch: 7   Global Step: 119400   Required: 28 hours
Training: 2025-12-01 08:18:34,194-Speed 1101.74 samples/sec   Loss 0.9963 target_logit_mean 0.0016 lma 0.7003  cos_theta_tmp 0.8262  Epoch: 7   Global Step: 119450   Required: 28 hours
Training: 2025-12-01 08:18:51,611-Speed 1102.44 samples/sec   Loss 0.9853 target_logit_mean -0.0027 lma 0.6892  cos_theta_tmp 0.8238  Epoch: 7   Global Step: 119500   Required: 28 hours
Training: 2025-12-01 08:19:09,041-Speed 1101.60 samples/sec   Loss 1.0201 target_logit_mean 0.0003 lma 0.6953  cos_theta_tmp 0.8227  Epoch: 7   Global Step: 119550   Required: 28 hours
Training: 2025-12-01 08:19:26,466-Speed 1101.88 samples/sec   Loss 1.0104 target_logit_mean 0.0027 lma 0.6884  cos_theta_tmp 0.8285  Epoch: 7   Global Step: 119600   Required: 28 hours
Training: 2025-12-01 08:19:43,877-Speed 1102.82 samples/sec   Loss 1.0228 target_logit_mean 0.0003 lma 0.6883  cos_theta_tmp 0.8223  Epoch: 7   Global Step: 119650   Required: 28 hours
Training: 2025-12-01 08:20:01,299-Speed 1102.07 samples/sec   Loss 1.0003 target_logit_mean 0.0007 lma 0.6842  cos_theta_tmp 0.8241  Epoch: 7   Global Step: 119700   Required: 28 hours
Training: 2025-12-01 08:20:18,712-Speed 1102.69 samples/sec   Loss 1.0141 target_logit_mean 0.0010 lma 0.6918  cos_theta_tmp 0.8269  Epoch: 7   Global Step: 119750   Required: 28 hours
Training: 2025-12-01 08:20:36,139-Speed 1101.76 samples/sec   Loss 1.0191 target_logit_mean 0.0019 lma 0.6942  cos_theta_tmp 0.8272  Epoch: 7   Global Step: 119800   Required: 28 hours
Training: 2025-12-01 08:20:53,553-Speed 1102.55 samples/sec   Loss 1.0117 target_logit_mean -0.0001 lma 0.6889  cos_theta_tmp 0.8293  Epoch: 7   Global Step: 119850   Required: 28 hours
Training: 2025-12-01 08:21:10,980-Speed 1101.80 samples/sec   Loss 1.0211 target_logit_mean -0.0013 lma 0.6907  cos_theta_tmp 0.8272  Epoch: 7   Global Step: 119900   Required: 28 hours
Training: 2025-12-01 08:21:28,404-Speed 1101.99 samples/sec   Loss 0.9630 target_logit_mean -0.0010 lma 0.6833  cos_theta_tmp 0.8228  Epoch: 7   Global Step: 119950   Required: 28 hours
Training: 2025-12-01 08:21:45,819-Speed 1102.53 samples/sec   Loss 1.0589 target_logit_mean 0.0015 lma 0.6951  cos_theta_tmp 0.8238  Epoch: 7   Global Step: 120000   Required: 28 hours
Training: 2025-12-01 08:22:03,249-Speed 1101.62 samples/sec   Loss 0.9911 target_logit_mean -0.0013 lma 0.7005  cos_theta_tmp 0.8270  Epoch: 7   Global Step: 120050   Required: 28 hours
Training: 2025-12-01 08:22:20,661-Speed 1102.69 samples/sec   Loss 0.9985 target_logit_mean -0.0011 lma 0.6979  cos_theta_tmp 0.8297  Epoch: 7   Global Step: 120100   Required: 28 hours
Training: 2025-12-01 08:22:38,079-Speed 1102.35 samples/sec   Loss 1.0113 target_logit_mean 0.0002 lma 0.6963  cos_theta_tmp 0.8281  Epoch: 7   Global Step: 120150   Required: 28 hours
Training: 2025-12-01 08:22:55,506-Speed 1101.81 samples/sec   Loss 1.0321 target_logit_mean 0.0020 lma 0.6938  cos_theta_tmp 0.8237  Epoch: 7   Global Step: 120200   Required: 28 hours
Training: 2025-12-01 08:23:12,924-Speed 1102.35 samples/sec   Loss 0.9914 target_logit_mean -0.0022 lma 0.6925  cos_theta_tmp 0.8262  Epoch: 7   Global Step: 120250   Required: 28 hours
Training: 2025-12-01 08:23:30,347-Speed 1101.99 samples/sec   Loss 1.0081 target_logit_mean -0.0003 lma 0.6794  cos_theta_tmp 0.8228  Epoch: 7   Global Step: 120300   Required: 28 hours
Training: 2025-12-01 08:23:47,760-Speed 1102.71 samples/sec   Loss 1.0006 target_logit_mean 0.0015 lma 0.6980  cos_theta_tmp 0.8286  Epoch: 7   Global Step: 120350   Required: 28 hours
Training: 2025-12-01 08:24:05,182-Speed 1102.08 samples/sec   Loss 0.9994 target_logit_mean -0.0006 lma 0.6885  cos_theta_tmp 0.8253  Epoch: 7   Global Step: 120400   Required: 28 hours
Training: 2025-12-01 08:24:22,596-Speed 1102.62 samples/sec   Loss 0.9953 target_logit_mean 0.0015 lma 0.6768  cos_theta_tmp 0.8238  Epoch: 7   Global Step: 120450   Required: 28 hours
Training: 2025-12-01 08:24:40,020-Speed 1101.95 samples/sec   Loss 1.0085 target_logit_mean 0.0003 lma 0.6793  cos_theta_tmp 0.8238  Epoch: 7   Global Step: 120500   Required: 28 hours
Training: 2025-12-01 08:24:57,449-Speed 1101.64 samples/sec   Loss 1.0154 target_logit_mean 0.0001 lma 0.6957  cos_theta_tmp 0.8200  Epoch: 7   Global Step: 120550   Required: 28 hours
Training: 2025-12-01 08:25:14,862-Speed 1102.68 samples/sec   Loss 1.0251 target_logit_mean -0.0003 lma 0.6925  cos_theta_tmp 0.8194  Epoch: 7   Global Step: 120600   Required: 28 hours
Training: 2025-12-01 08:25:32,290-Speed 1101.70 samples/sec   Loss 0.9940 target_logit_mean 0.0013 lma 0.6949  cos_theta_tmp 0.8285  Epoch: 7   Global Step: 120650   Required: 28 hours
Training: 2025-12-01 08:25:49,698-Speed 1102.96 samples/sec   Loss 1.0061 target_logit_mean -0.0006 lma 0.6888  cos_theta_tmp 0.8281  Epoch: 7   Global Step: 120700   Required: 28 hours
Training: 2025-12-01 08:26:07,122-Speed 1102.00 samples/sec   Loss 1.0396 target_logit_mean 0.0011 lma 0.6979  cos_theta_tmp 0.8297  Epoch: 7   Global Step: 120750   Required: 28 hours
Training: 2025-12-01 08:26:24,551-Speed 1101.62 samples/sec   Loss 0.9900 target_logit_mean -0.0019 lma 0.6823  cos_theta_tmp 0.8244  Epoch: 7   Global Step: 120800   Required: 28 hours
Training: 2025-12-01 08:26:41,966-Speed 1102.52 samples/sec   Loss 1.0244 target_logit_mean -0.0000 lma 0.6807  cos_theta_tmp 0.8238  Epoch: 7   Global Step: 120850   Required: 28 hours
Training: 2025-12-01 08:26:59,396-Speed 1101.62 samples/sec   Loss 1.0150 target_logit_mean -0.0013 lma 0.6926  cos_theta_tmp 0.8221  Epoch: 7   Global Step: 120900   Required: 28 hours
Training: 2025-12-01 08:27:16,806-Speed 1102.88 samples/sec   Loss 1.0418 target_logit_mean -0.0018 lma 0.6888  cos_theta_tmp 0.8287  Epoch: 7   Global Step: 120950   Required: 28 hours
Training: 2025-12-01 08:27:34,229-Speed 1101.97 samples/sec   Loss 1.0435 target_logit_mean -0.0032 lma 0.6811  cos_theta_tmp 0.8196  Epoch: 7   Global Step: 121000   Required: 28 hours
Training: 2025-12-01 08:27:51,643-Speed 1102.61 samples/sec   Loss 0.9848 target_logit_mean -0.0019 lma 0.6931  cos_theta_tmp 0.8270  Epoch: 7   Global Step: 121050   Required: 28 hours
Training: 2025-12-01 08:28:09,070-Speed 1101.78 samples/sec   Loss 1.0219 target_logit_mean -0.0001 lma 0.7018  cos_theta_tmp 0.8310  Epoch: 7   Global Step: 121100   Required: 28 hours
Training: 2025-12-01 08:28:26,499-Speed 1101.68 samples/sec   Loss 1.0059 target_logit_mean -0.0001 lma 0.6853  cos_theta_tmp 0.8267  Epoch: 7   Global Step: 121150   Required: 27 hours
Training: 2025-12-01 08:28:43,909-Speed 1102.86 samples/sec   Loss 0.9942 target_logit_mean 0.0025 lma 0.6918  cos_theta_tmp 0.8283  Epoch: 7   Global Step: 121200   Required: 27 hours
Training: 2025-12-01 08:29:01,335-Speed 1101.80 samples/sec   Loss 1.0012 target_logit_mean -0.0002 lma 0.6885  cos_theta_tmp 0.8229  Epoch: 7   Global Step: 121250   Required: 27 hours
Training: 2025-12-01 08:29:18,786-Speed 1100.27 samples/sec   Loss 1.0431 target_logit_mean -0.0001 lma 0.6871  cos_theta_tmp 0.8144  Epoch: 7   Global Step: 121300   Required: 27 hours
Training: 2025-12-01 08:29:32,384-[lfw][121304]XNorm: 23.208736
Training: 2025-12-01 08:29:32,384-[lfw][121304]Accuracy-Flip: 0.99367+-0.00414
Training: 2025-12-01 08:29:32,384-[lfw][121304]Accuracy-Highest: 0.99367
Training: 2025-12-01 08:29:46,472-[cfp_fp][121304]XNorm: 18.980475
Training: 2025-12-01 08:29:46,472-[cfp_fp][121304]Accuracy-Flip: 0.93014+-0.01651
Training: 2025-12-01 08:29:46,472-[cfp_fp][121304]Accuracy-Highest: 0.93014
Training: 2025-12-01 08:30:00,023-[cfp_ff][121304]XNorm: 22.528006
Training: 2025-12-01 08:30:00,023-[cfp_ff][121304]Accuracy-Flip: 0.99414+-0.00289
Training: 2025-12-01 08:30:00,023-[cfp_ff][121304]Accuracy-Highest: 0.99414
Training: 2025-12-01 08:30:11,684-[agedb_30][121304]XNorm: 22.134270
Training: 2025-12-01 08:30:11,684-[agedb_30][121304]Accuracy-Flip: 0.94917+-0.00857
Training: 2025-12-01 08:30:11,684-[agedb_30][121304]Accuracy-Highest: 0.94917
Training: 2025-12-01 08:30:23,520-[calfw][121304]XNorm: 23.223724
Training: 2025-12-01 08:30:23,520-[calfw][121304]Accuracy-Flip: 0.94583+-0.00938
Training: 2025-12-01 08:30:23,520-[calfw][121304]Accuracy-Highest: 0.94583
Training: 2025-12-01 08:30:35,393-[cplfw][121304]XNorm: 19.250334
Training: 2025-12-01 08:30:35,393-[cplfw][121304]Accuracy-Flip: 0.88667+-0.01823
Training: 2025-12-01 08:30:35,393-[cplfw][121304]Accuracy-Highest: 0.88667
Training: 2025-12-01 08:30:45,306-[vgg2_fp][121304]XNorm: 19.573039
Training: 2025-12-01 08:30:45,306-[vgg2_fp][121304]Accuracy-Flip: 0.91760+-0.00907
Training: 2025-12-01 08:30:45,306-[vgg2_fp][121304]Accuracy-Highest: 0.91760
Training: 2025-12-01 08:32:42,346-[IJB][IJBB_gt_aligned] {'Norm:True_Det:True_tpr_at_fpr_1e-06': 37.29308666017527, 'Norm:True_Det:True_thresh_at_fpr_1e-06': 0.7113277227281163, 'Norm:True_Det:True_tpr_at_fpr_1e-05': 79.62999026290166, 'Norm:True_Det:True_thresh_at_fpr_1e-05': 0.44906285324004974, 'Norm:True_Det:True_tpr_at_fpr_0.0001': 89.68841285296982, 'Norm:True_Det:True_thresh_at_fpr_0.0001': 0.32986117297644046, 'Norm:True_Det:True_tpr_at_fpr_0.001': 93.60272638753652, 'Norm:True_Det:True_thresh_at_fpr_0.001': 0.2553574718898569, 'Norm:True_Det:True_tpr_at_fpr_0.01': 96.30963972736126, 'Norm:True_Det:True_thresh_at_fpr_0.01': 0.18544203821658942, 'Norm:True_Det:True_tpr_at_fpr_0.1': 98.19863680623175, 'Norm:True_Det:True_thresh_at_fpr_0.1': 0.10641891938313515, 'Norm:True_Det:False_tpr_at_fpr_1e-06': 37.15676728334956, 'Norm:True_Det:False_thresh_at_fpr_1e-06': 0.7113138046703917, 'Norm:True_Det:False_tpr_at_fpr_1e-05': 78.19863680623175, 'Norm:True_Det:False_thresh_at_fpr_1e-05': 0.4591631961053663, 'Norm:True_Det:False_tpr_at_fpr_0.0001': 89.37682570593964, 'Norm:True_Det:False_thresh_at_fpr_0.0001': 0.33357737708596763, 'Norm:True_Det:False_tpr_at_fpr_0.001': 93.53456669912366, 'Norm:True_Det:False_thresh_at_fpr_0.001': 0.2571435838533953, 'Norm:True_Det:False_tpr_at_fpr_0.01': 96.27069133398247, 'Norm:True_Det:False_thresh_at_fpr_0.01': 0.18620964911599935, 'Norm:True_Det:False_tpr_at_fpr_0.1': 98.15968841285297, 'Norm:True_Det:False_thresh_at_fpr_0.1': 0.10641409050360492, 'Norm:False_Det:True_tpr_at_fpr_1e-06': 36.056475170399224, 'Norm:False_Det:True_thresh_at_fpr_1e-06': 0.7007370850381606, 'Norm:False_Det:True_tpr_at_fpr_1e-05': 75.9396299902629, 'Norm:False_Det:True_thresh_at_fpr_1e-05': 0.46613395915492595, 'Norm:False_Det:True_tpr_at_fpr_0.0001': 88.3933787731256, 'Norm:False_Det:True_thresh_at_fpr_0.0001': 0.3403635774769887, 'Norm:False_Det:True_tpr_at_fpr_0.001': 93.12560856864654, 'Norm:False_Det:True_thresh_at_fpr_0.001': 0.2622142264175137, 'Norm:False_Det:True_tpr_at_fpr_0.01': 96.12463485881207, 'Norm:False_Det:True_thresh_at_fpr_0.01': 0.18922526155485242, 'Norm:False_Det:True_tpr_at_fpr_0.1': 98.18889970788705, 'Norm:False_Det:True_thresh_at_fpr_0.1': 0.10949830860298629}
Training: 2025-12-01 08:36:42,990-[IJB][IJBC_gt_aligned] {'Norm:True_Det:True_tpr_at_fpr_1e-06': 76.77046581786573, 'Norm:True_Det:True_thresh_at_fpr_1e-06': 0.5002030657148805, 'Norm:True_Det:True_tpr_at_fpr_1e-05': 86.89471800378381, 'Norm:True_Det:True_thresh_at_fpr_1e-05': 0.40189623138967356, 'Norm:True_Det:True_tpr_at_fpr_0.0001': 91.92616454466432, 'Norm:True_Det:True_thresh_at_fpr_0.0001': 0.323964660116426, 'Norm:True_Det:True_tpr_at_fpr_0.001': 95.05547885667536, 'Norm:True_Det:True_thresh_at_fpr_0.001': 0.25318620016964016, 'Norm:True_Det:True_tpr_at_fpr_0.01': 97.09566906989825, 'Norm:True_Det:True_thresh_at_fpr_0.01': 0.18377959629321053, 'Norm:True_Det:True_tpr_at_fpr_0.1': 98.65521296722402, 'Norm:True_Det:True_thresh_at_fpr_0.1': 0.10580172249871153, 'Norm:True_Det:False_tpr_at_fpr_1e-06': 75.14956281638288, 'Norm:True_Det:False_thresh_at_fpr_1e-06': 0.5122271769670033, 'Norm:True_Det:False_tpr_at_fpr_1e-05': 85.79536738763615, 'Norm:True_Det:False_thresh_at_fpr_1e-05': 0.41490508497401585, 'Norm:True_Det:False_tpr_at_fpr_0.0001': 91.67050161067648, 'Norm:True_Det:False_thresh_at_fpr_0.0001': 0.3282421991895683, 'Norm:True_Det:False_tpr_at_fpr_0.001': 94.95832694175999, 'Norm:True_Det:False_thresh_at_fpr_0.001': 0.25494286558596657, 'Norm:True_Det:False_tpr_at_fpr_0.01': 97.03430996574117, 'Norm:True_Det:False_thresh_at_fpr_0.01': 0.1850396815608339, 'Norm:True_Det:False_tpr_at_fpr_0.1': 98.61942015646572, 'Norm:True_Det:False_thresh_at_fpr_0.1': 0.10615202460768808, 'Norm:False_Det:True_tpr_at_fpr_1e-06': 72.46510200951066, 'Norm:False_Det:True_thresh_at_fpr_1e-06': 0.5166648520438997, 'Norm:False_Det:True_tpr_at_fpr_1e-05': 83.45349491230762, 'Norm:False_Det:True_thresh_at_fpr_1e-05': 0.4273855613530215, 'Norm:False_Det:True_tpr_at_fpr_0.0001': 90.64784987472517, 'Norm:False_Det:True_thresh_at_fpr_0.0001': 0.33813634005216897, 'Norm:False_Det:True_tpr_at_fpr_0.001': 94.579945799458, 'Norm:False_Det:True_thresh_at_fpr_0.001': 0.2617891673486258, 'Norm:False_Det:True_tpr_at_fpr_0.01': 96.93204479214603, 'Norm:False_Det:True_thresh_at_fpr_0.01': 0.18943883069183398, 'Norm:False_Det:True_tpr_at_fpr_0.1': 98.6449864498645, 'Norm:False_Det:True_thresh_at_fpr_0.1': 0.10824484292058716}
Training: 2025-12-01 08:38:29,337-[TinyFace][tinyface_aligned_pad_0.1] {'rank-1': 57.91308879852295, 'rank-5': 63.063305616378784, 'rank-20': 67.27467775344849}
Training: 2025-12-01 08:38:59,972-Speed 33.04 samples/sec   Loss 1.0100 target_logit_mean 0.0007 lma 0.6892  cos_theta_tmp 0.8216  Epoch: 8   Global Step: 121350   Required: 28 hours
Training: 2025-12-01 08:39:17,321-Speed 1106.70 samples/sec   Loss 1.0041 target_logit_mean 0.0004 lma 0.7052  cos_theta_tmp 0.8232  Epoch: 8   Global Step: 121400   Required: 28 hours
Training: 2025-12-01 08:39:34,724-Speed 1103.32 samples/sec   Loss 1.0309 target_logit_mean -0.0003 lma 0.7003  cos_theta_tmp 0.8280  Epoch: 8   Global Step: 121450   Required: 28 hours
Training: 2025-12-01 08:39:52,116-Speed 1104.01 samples/sec   Loss 1.0220 target_logit_mean 0.0023 lma 0.6965  cos_theta_tmp 0.8270  Epoch: 8   Global Step: 121500   Required: 28 hours
Training: 2025-12-01 08:40:09,523-Speed 1103.00 samples/sec   Loss 0.9857 target_logit_mean 0.0003 lma 0.6906  cos_theta_tmp 0.8228  Epoch: 8   Global Step: 121550   Required: 28 hours
Training: 2025-12-01 08:40:26,935-Speed 1102.78 samples/sec   Loss 1.0150 target_logit_mean -0.0016 lma 0.6991  cos_theta_tmp 0.8226  Epoch: 8   Global Step: 121600   Required: 28 hours
Training: 2025-12-01 08:40:44,339-Speed 1103.23 samples/sec   Loss 1.0319 target_logit_mean -0.0018 lma 0.7074  cos_theta_tmp 0.8239  Epoch: 8   Global Step: 121650   Required: 28 hours
Training: 2025-12-01 08:41:01,762-Speed 1102.00 samples/sec   Loss 0.9881 target_logit_mean 0.0010 lma 0.6923  cos_theta_tmp 0.8222  Epoch: 8   Global Step: 121700   Required: 28 hours
Training: 2025-12-01 08:41:19,167-Speed 1103.19 samples/sec   Loss 1.0222 target_logit_mean -0.0013 lma 0.6863  cos_theta_tmp 0.8207  Epoch: 8   Global Step: 121750   Required: 28 hours
Training: 2025-12-01 08:41:36,586-Speed 1102.30 samples/sec   Loss 0.9815 target_logit_mean 0.0023 lma 0.7001  cos_theta_tmp 0.8261  Epoch: 8   Global Step: 121800   Required: 28 hours
Training: 2025-12-01 08:41:53,995-Speed 1102.93 samples/sec   Loss 0.9953 target_logit_mean -0.0004 lma 0.6890  cos_theta_tmp 0.8223  Epoch: 8   Global Step: 121850   Required: 28 hours
Training: 2025-12-01 08:42:11,412-Speed 1102.43 samples/sec   Loss 1.0293 target_logit_mean -0.0007 lma 0.6934  cos_theta_tmp 0.8206  Epoch: 8   Global Step: 121900   Required: 28 hours
Training: 2025-12-01 08:42:28,833-Speed 1102.11 samples/sec   Loss 1.0098 target_logit_mean 0.0007 lma 0.6956  cos_theta_tmp 0.8236  Epoch: 8   Global Step: 121950   Required: 28 hours
Training: 2025-12-01 08:42:46,256-Speed 1102.06 samples/sec   Loss 0.9924 target_logit_mean 0.0022 lma 0.6806  cos_theta_tmp 0.8243  Epoch: 8   Global Step: 122000   Required: 28 hours
Training: 2025-12-01 08:43:03,711-Speed 1100.30 samples/sec   Loss 1.0332 target_logit_mean 0.0004 lma 0.6907  cos_theta_tmp 0.8259  Epoch: 8   Global Step: 122050   Required: 28 hours
Training: 2025-12-01 08:43:21,147-Speed 1101.22 samples/sec   Loss 1.0129 target_logit_mean 0.0025 lma 0.6880  cos_theta_tmp 0.8216  Epoch: 8   Global Step: 122100   Required: 28 hours
Training: 2025-12-01 08:43:38,593-Speed 1100.60 samples/sec   Loss 0.9881 target_logit_mean 0.0024 lma 0.6984  cos_theta_tmp 0.8284  Epoch: 8   Global Step: 122150   Required: 28 hours
Training: 2025-12-01 08:43:56,027-Speed 1101.32 samples/sec   Loss 1.0036 target_logit_mean 0.0018 lma 0.6922  cos_theta_tmp 0.8299  Epoch: 8   Global Step: 122200   Required: 28 hours
Training: 2025-12-01 08:44:13,467-Speed 1100.97 samples/sec   Loss 1.0400 target_logit_mean -0.0014 lma 0.6895  cos_theta_tmp 0.8246  Epoch: 8   Global Step: 122250   Required: 28 hours
Training: 2025-12-01 08:44:30,915-Speed 1100.48 samples/sec   Loss 1.0280 target_logit_mean -0.0001 lma 0.6839  cos_theta_tmp 0.8217  Epoch: 8   Global Step: 122300   Required: 28 hours
Training: 2025-12-01 08:44:48,346-Speed 1101.49 samples/sec   Loss 1.0100 target_logit_mean 0.0000 lma 0.6833  cos_theta_tmp 0.8233  Epoch: 8   Global Step: 122350   Required: 28 hours
Training: 2025-12-01 08:45:05,794-Speed 1100.47 samples/sec   Loss 1.0315 target_logit_mean 0.0008 lma 0.7064  cos_theta_tmp 0.8255  Epoch: 8   Global Step: 122400   Required: 28 hours
Training: 2025-12-01 08:45:23,233-Speed 1101.02 samples/sec   Loss 1.0106 target_logit_mean -0.0002 lma 0.6907  cos_theta_tmp 0.8227  Epoch: 8   Global Step: 122450   Required: 28 hours
Training: 2025-12-01 08:45:40,676-Speed 1100.80 samples/sec   Loss 1.0273 target_logit_mean 0.0021 lma 0.6908  cos_theta_tmp 0.8231  Epoch: 8   Global Step: 122500   Required: 28 hours
Training: 2025-12-01 08:45:58,160-Speed 1098.20 samples/sec   Loss 1.0396 target_logit_mean 0.0002 lma 0.6962  cos_theta_tmp 0.8264  Epoch: 8   Global Step: 122550   Required: 28 hours
Training: 2025-12-01 08:46:15,673-Speed 1096.33 samples/sec   Loss 1.0490 target_logit_mean 0.0010 lma 0.6857  cos_theta_tmp 0.8175  Epoch: 8   Global Step: 122600   Required: 28 hours
Training: 2025-12-01 08:46:33,224-Speed 1094.00 samples/sec   Loss 1.0442 target_logit_mean 0.0002 lma 0.7014  cos_theta_tmp 0.8280  Epoch: 8   Global Step: 122650   Required: 28 hours
Training: 2025-12-01 08:46:50,807-Speed 1092.02 samples/sec   Loss 1.0770 target_logit_mean 0.0004 lma 0.6939  cos_theta_tmp 0.8234  Epoch: 8   Global Step: 122700   Required: 28 hours
Training: 2025-12-01 08:47:08,306-Speed 1097.25 samples/sec   Loss 1.0378 target_logit_mean -0.0003 lma 0.6905  cos_theta_tmp 0.8270  Epoch: 8   Global Step: 122750   Required: 28 hours
Training: 2025-12-01 08:47:25,843-Speed 1094.84 samples/sec   Loss 1.0695 target_logit_mean -0.0008 lma 0.6837  cos_theta_tmp 0.8220  Epoch: 8   Global Step: 122800   Required: 28 hours
Training: 2025-12-01 08:47:43,392-Speed 1094.11 samples/sec   Loss 1.0184 target_logit_mean -0.0012 lma 0.6938  cos_theta_tmp 0.8234  Epoch: 8   Global Step: 122850   Required: 28 hours
Training: 2025-12-01 08:48:00,919-Speed 1095.51 samples/sec   Loss 1.0198 target_logit_mean -0.0013 lma 0.7021  cos_theta_tmp 0.8255  Epoch: 8   Global Step: 122900   Required: 28 hours
Training: 2025-12-01 08:48:18,394-Speed 1098.75 samples/sec   Loss 1.0492 target_logit_mean 0.0005 lma 0.6914  cos_theta_tmp 0.8248  Epoch: 8   Global Step: 122950   Required: 28 hours
Training: 2025-12-01 08:48:35,835-Speed 1100.89 samples/sec   Loss 1.0497 target_logit_mean 0.0015 lma 0.7131  cos_theta_tmp 0.8284  Epoch: 8   Global Step: 123000   Required: 28 hours
Training: 2025-12-01 08:48:53,265-Speed 1101.59 samples/sec   Loss 1.0323 target_logit_mean -0.0003 lma 0.6980  cos_theta_tmp 0.8235  Epoch: 8   Global Step: 123050   Required: 28 hours
Training: 2025-12-01 08:49:10,699-Speed 1101.37 samples/sec   Loss 1.0194 target_logit_mean 0.0021 lma 0.6883  cos_theta_tmp 0.8239  Epoch: 8   Global Step: 123100   Required: 28 hours
Training: 2025-12-01 08:49:28,133-Speed 1101.30 samples/sec   Loss 1.0144 target_logit_mean 0.0013 lma 0.6978  cos_theta_tmp 0.8217  Epoch: 8   Global Step: 123150   Required: 28 hours
Training: 2025-12-01 08:49:45,565-Speed 1101.46 samples/sec   Loss 1.0256 target_logit_mean -0.0011 lma 0.6886  cos_theta_tmp 0.8244  Epoch: 8   Global Step: 123200   Required: 28 hours
Training: 2025-12-01 08:50:03,006-Speed 1100.88 samples/sec   Loss 1.0251 target_logit_mean -0.0003 lma 0.6920  cos_theta_tmp 0.8209  Epoch: 8   Global Step: 123250   Required: 28 hours
Training: 2025-12-01 08:50:20,436-Speed 1101.64 samples/sec   Loss 1.0368 target_logit_mean 0.0010 lma 0.6940  cos_theta_tmp 0.8230  Epoch: 8   Global Step: 123300   Required: 28 hours
Training: 2025-12-01 08:50:37,873-Speed 1101.16 samples/sec   Loss 1.0553 target_logit_mean 0.0004 lma 0.6813  cos_theta_tmp 0.8191  Epoch: 8   Global Step: 123350   Required: 28 hours
Training: 2025-12-01 08:50:55,298-Speed 1101.89 samples/sec   Loss 1.0401 target_logit_mean -0.0002 lma 0.6918  cos_theta_tmp 0.8273  Epoch: 8   Global Step: 123400   Required: 28 hours
Training: 2025-12-01 08:51:12,740-Speed 1100.84 samples/sec   Loss 1.0589 target_logit_mean 0.0008 lma 0.6829  cos_theta_tmp 0.8239  Epoch: 8   Global Step: 123450   Required: 28 hours
Training: 2025-12-01 08:51:30,176-Speed 1101.21 samples/sec   Loss 1.0428 target_logit_mean 0.0030 lma 0.6832  cos_theta_tmp 0.8217  Epoch: 8   Global Step: 123500   Required: 28 hours
Training: 2025-12-01 08:51:47,602-Speed 1101.80 samples/sec   Loss 1.0263 target_logit_mean 0.0008 lma 0.6912  cos_theta_tmp 0.8188  Epoch: 8   Global Step: 123550   Required: 28 hours
Training: 2025-12-01 08:52:05,039-Speed 1101.16 samples/sec   Loss 1.0773 target_logit_mean 0.0008 lma 0.6796  cos_theta_tmp 0.8193  Epoch: 8   Global Step: 123600   Required: 28 hours
Training: 2025-12-01 08:52:22,465-Speed 1101.85 samples/sec   Loss 1.0252 target_logit_mean -0.0019 lma 0.6830  cos_theta_tmp 0.8206  Epoch: 8   Global Step: 123650   Required: 28 hours
Training: 2025-12-01 08:52:39,913-Speed 1100.44 samples/sec   Loss 1.0287 target_logit_mean -0.0004 lma 0.6910  cos_theta_tmp 0.8207  Epoch: 8   Global Step: 123700   Required: 28 hours
Training: 2025-12-01 08:52:57,349-Speed 1101.20 samples/sec   Loss 1.0593 target_logit_mean 0.0007 lma 0.6828  cos_theta_tmp 0.8201  Epoch: 8   Global Step: 123750   Required: 28 hours
Training: 2025-12-01 08:53:14,790-Speed 1100.91 samples/sec   Loss 1.0422 target_logit_mean -0.0013 lma 0.6839  cos_theta_tmp 0.8211  Epoch: 8   Global Step: 123800   Required: 28 hours
Training: 2025-12-01 08:53:32,256-Speed 1099.35 samples/sec   Loss 1.0572 target_logit_mean 0.0011 lma 0.6940  cos_theta_tmp 0.8254  Epoch: 8   Global Step: 123850   Required: 28 hours
Training: 2025-12-01 08:53:49,767-Speed 1096.43 samples/sec   Loss 1.0358 target_logit_mean 0.0013 lma 0.6915  cos_theta_tmp 0.8252  Epoch: 8   Global Step: 123900   Required: 28 hours
Training: 2025-12-01 08:54:07,276-Speed 1096.63 samples/sec   Loss 1.0436 target_logit_mean -0.0015 lma 0.7012  cos_theta_tmp 0.8198  Epoch: 8   Global Step: 123950   Required: 28 hours
Training: 2025-12-01 08:54:24,733-Speed 1099.89 samples/sec   Loss 1.0485 target_logit_mean 0.0002 lma 0.6882  cos_theta_tmp 0.8244  Epoch: 8   Global Step: 124000   Required: 28 hours
Training: 2025-12-01 08:54:42,194-Speed 1099.62 samples/sec   Loss 1.0167 target_logit_mean 0.0026 lma 0.7010  cos_theta_tmp 0.8256  Epoch: 8   Global Step: 124050   Required: 28 hours
Training: 2025-12-01 08:54:59,662-Speed 1099.18 samples/sec   Loss 1.0409 target_logit_mean 0.0012 lma 0.6936  cos_theta_tmp 0.8219  Epoch: 8   Global Step: 124100   Required: 28 hours
Training: 2025-12-01 08:55:17,116-Speed 1100.11 samples/sec   Loss 1.0474 target_logit_mean -0.0004 lma 0.6873  cos_theta_tmp 0.8202  Epoch: 8   Global Step: 124150   Required: 28 hours
Training: 2025-12-01 08:55:34,576-Speed 1099.70 samples/sec   Loss 1.0778 target_logit_mean -0.0001 lma 0.6743  cos_theta_tmp 0.8160  Epoch: 8   Global Step: 124200   Required: 28 hours
Training: 2025-12-01 08:55:52,029-Speed 1100.10 samples/sec   Loss 1.0662 target_logit_mean -0.0017 lma 0.6793  cos_theta_tmp 0.8174  Epoch: 8   Global Step: 124250   Required: 27 hours
Training: 2025-12-01 08:56:09,524-Speed 1097.54 samples/sec   Loss 1.0723 target_logit_mean 0.0001 lma 0.7013  cos_theta_tmp 0.8247  Epoch: 8   Global Step: 124300   Required: 27 hours
Training: 2025-12-01 08:56:27,029-Speed 1096.82 samples/sec   Loss 1.0743 target_logit_mean 0.0002 lma 0.6872  cos_theta_tmp 0.8255  Epoch: 8   Global Step: 124350   Required: 27 hours
Training: 2025-12-01 08:56:44,581-Speed 1093.97 samples/sec   Loss 1.0777 target_logit_mean 0.0000 lma 0.6931  cos_theta_tmp 0.8241  Epoch: 8   Global Step: 124400   Required: 27 hours
Training: 2025-12-01 08:57:02,073-Speed 1097.70 samples/sec   Loss 1.0634 target_logit_mean 0.0001 lma 0.7016  cos_theta_tmp 0.8206  Epoch: 8   Global Step: 124450   Required: 27 hours
Training: 2025-12-01 08:57:19,548-Speed 1098.76 samples/sec   Loss 1.0753 target_logit_mean -0.0015 lma 0.6888  cos_theta_tmp 0.8237  Epoch: 8   Global Step: 124500   Required: 27 hours
Training: 2025-12-01 08:57:37,032-Speed 1098.15 samples/sec   Loss 1.0488 target_logit_mean -0.0005 lma 0.6835  cos_theta_tmp 0.8196  Epoch: 8   Global Step: 124550   Required: 27 hours
Training: 2025-12-01 08:57:54,511-Speed 1098.51 samples/sec   Loss 1.0499 target_logit_mean 0.0000 lma 0.6978  cos_theta_tmp 0.8269  Epoch: 8   Global Step: 124600   Required: 27 hours
Training: 2025-12-01 08:58:11,996-Speed 1098.13 samples/sec   Loss 1.0602 target_logit_mean -0.0014 lma 0.6909  cos_theta_tmp 0.8194  Epoch: 8   Global Step: 124650   Required: 27 hours
Training: 2025-12-01 08:58:29,482-Speed 1098.07 samples/sec   Loss 1.0684 target_logit_mean 0.0019 lma 0.6844  cos_theta_tmp 0.8235  Epoch: 8   Global Step: 124700   Required: 27 hours
Training: 2025-12-01 08:58:46,955-Speed 1098.83 samples/sec   Loss 1.0432 target_logit_mean -0.0015 lma 0.6922  cos_theta_tmp 0.8211  Epoch: 8   Global Step: 124750   Required: 27 hours
Training: 2025-12-01 08:59:04,442-Speed 1098.01 samples/sec   Loss 1.0554 target_logit_mean -0.0010 lma 0.7018  cos_theta_tmp 0.8240  Epoch: 8   Global Step: 124800   Required: 27 hours
Training: 2025-12-01 08:59:21,921-Speed 1098.49 samples/sec   Loss 1.0564 target_logit_mean -0.0027 lma 0.6916  cos_theta_tmp 0.8213  Epoch: 8   Global Step: 124850   Required: 27 hours
Training: 2025-12-01 08:59:39,405-Speed 1098.18 samples/sec   Loss 1.0597 target_logit_mean 0.0035 lma 0.6821  cos_theta_tmp 0.8261  Epoch: 8   Global Step: 124900   Required: 27 hours
Training: 2025-12-01 08:59:56,884-Speed 1098.52 samples/sec   Loss 1.0820 target_logit_mean 0.0005 lma 0.6848  cos_theta_tmp 0.8220  Epoch: 8   Global Step: 124950   Required: 27 hours
Training: 2025-12-01 09:00:14,378-Speed 1097.59 samples/sec   Loss 1.0537 target_logit_mean -0.0017 lma 0.6847  cos_theta_tmp 0.8198  Epoch: 8   Global Step: 125000   Required: 27 hours
Training: 2025-12-01 09:00:31,861-Speed 1098.20 samples/sec   Loss 1.0541 target_logit_mean 0.0011 lma 0.6825  cos_theta_tmp 0.8213  Epoch: 8   Global Step: 125050   Required: 27 hours
Training: 2025-12-01 09:00:49,338-Speed 1098.64 samples/sec   Loss 1.0540 target_logit_mean -0.0008 lma 0.6940  cos_theta_tmp 0.8174  Epoch: 8   Global Step: 125100   Required: 27 hours
Training: 2025-12-01 09:01:06,823-Speed 1098.12 samples/sec   Loss 1.0430 target_logit_mean 0.0014 lma 0.6892  cos_theta_tmp 0.8185  Epoch: 8   Global Step: 125150   Required: 27 hours
Training: 2025-12-01 09:01:24,307-Speed 1098.19 samples/sec   Loss 1.0610 target_logit_mean 0.0018 lma 0.6903  cos_theta_tmp 0.8248  Epoch: 8   Global Step: 125200   Required: 27 hours
Training: 2025-12-01 09:01:41,797-Speed 1097.86 samples/sec   Loss 1.0480 target_logit_mean -0.0009 lma 0.6968  cos_theta_tmp 0.8239  Epoch: 8   Global Step: 125250   Required: 27 hours
Training: 2025-12-01 09:01:59,276-Speed 1098.43 samples/sec   Loss 1.0898 target_logit_mean -0.0029 lma 0.6925  cos_theta_tmp 0.8182  Epoch: 8   Global Step: 125300   Required: 27 hours
Training: 2025-12-01 09:02:16,747-Speed 1099.05 samples/sec   Loss 1.0475 target_logit_mean 0.0001 lma 0.6867  cos_theta_tmp 0.8219  Epoch: 8   Global Step: 125350   Required: 27 hours
Training: 2025-12-01 09:02:34,239-Speed 1097.65 samples/sec   Loss 1.0411 target_logit_mean 0.0007 lma 0.6995  cos_theta_tmp 0.8206  Epoch: 8   Global Step: 125400   Required: 27 hours
Training: 2025-12-01 09:02:51,708-Speed 1099.12 samples/sec   Loss 1.0502 target_logit_mean 0.0015 lma 0.6986  cos_theta_tmp 0.8216  Epoch: 8   Global Step: 125450   Required: 27 hours
Training: 2025-12-01 09:03:09,191-Speed 1098.23 samples/sec   Loss 1.1052 target_logit_mean -0.0030 lma 0.6916  cos_theta_tmp 0.8204  Epoch: 8   Global Step: 125500   Required: 27 hours
Training: 2025-12-01 09:03:26,698-Speed 1096.80 samples/sec   Loss 1.0963 target_logit_mean -0.0007 lma 0.6937  cos_theta_tmp 0.8206  Epoch: 8   Global Step: 125550   Required: 27 hours
Training: 2025-12-01 09:03:44,237-Speed 1094.72 samples/sec   Loss 1.0689 target_logit_mean 0.0004 lma 0.6905  cos_theta_tmp 0.8228  Epoch: 8   Global Step: 125600   Required: 27 hours
Training: 2025-12-01 09:04:01,720-Speed 1098.27 samples/sec   Loss 1.0634 target_logit_mean -0.0008 lma 0.6877  cos_theta_tmp 0.8247  Epoch: 8   Global Step: 125650   Required: 27 hours
Training: 2025-12-01 09:04:19,203-Speed 1098.19 samples/sec   Loss 1.0544 target_logit_mean 0.0002 lma 0.6980  cos_theta_tmp 0.8221  Epoch: 8   Global Step: 125700   Required: 27 hours
Training: 2025-12-01 09:04:36,806-Speed 1090.80 samples/sec   Loss 1.0296 target_logit_mean 0.0013 lma 0.6951  cos_theta_tmp 0.8269  Epoch: 8   Global Step: 125750   Required: 27 hours
Training: 2025-12-01 09:04:54,278-Speed 1098.95 samples/sec   Loss 1.0302 target_logit_mean 0.0026 lma 0.6922  cos_theta_tmp 0.8224  Epoch: 8   Global Step: 125800   Required: 27 hours
Training: 2025-12-01 09:05:11,794-Speed 1096.19 samples/sec   Loss 1.0312 target_logit_mean 0.0009 lma 0.6943  cos_theta_tmp 0.8202  Epoch: 8   Global Step: 125850   Required: 27 hours
Training: 2025-12-01 09:05:29,233-Speed 1100.97 samples/sec   Loss 1.0435 target_logit_mean -0.0016 lma 0.6750  cos_theta_tmp 0.8192  Epoch: 8   Global Step: 125900   Required: 27 hours
Training: 2025-12-01 09:05:46,644-Speed 1102.81 samples/sec   Loss 1.0519 target_logit_mean 0.0013 lma 0.6940  cos_theta_tmp 0.8195  Epoch: 8   Global Step: 125950   Required: 27 hours
Training: 2025-12-01 09:06:04,295-Speed 1087.78 samples/sec   Loss 1.0757 target_logit_mean 0.0003 lma 0.6770  cos_theta_tmp 0.8216  Epoch: 8   Global Step: 126000   Required: 27 hours
Training: 2025-12-01 09:06:21,781-Speed 1098.13 samples/sec   Loss 1.0770 target_logit_mean 0.0011 lma 0.6958  cos_theta_tmp 0.8256  Epoch: 8   Global Step: 126050   Required: 27 hours
Training: 2025-12-01 09:06:39,278-Speed 1097.34 samples/sec   Loss 1.0429 target_logit_mean 0.0015 lma 0.6869  cos_theta_tmp 0.8187  Epoch: 8   Global Step: 126100   Required: 27 hours
Training: 2025-12-01 09:06:56,779-Speed 1097.11 samples/sec   Loss 1.0559 target_logit_mean -0.0014 lma 0.6947  cos_theta_tmp 0.8229  Epoch: 8   Global Step: 126150   Required: 27 hours
Training: 2025-12-01 09:07:14,294-Speed 1096.25 samples/sec   Loss 1.0838 target_logit_mean 0.0012 lma 0.6883  cos_theta_tmp 0.8222  Epoch: 8   Global Step: 126200   Required: 27 hours
Training: 2025-12-01 09:07:31,766-Speed 1098.94 samples/sec   Loss 1.0255 target_logit_mean -0.0006 lma 0.6996  cos_theta_tmp 0.8244  Epoch: 8   Global Step: 126250   Required: 27 hours
Training: 2025-12-01 09:07:49,390-Speed 1089.48 samples/sec   Loss 1.0752 target_logit_mean -0.0019 lma 0.6912  cos_theta_tmp 0.8222  Epoch: 8   Global Step: 126300   Required: 27 hours
Training: 2025-12-01 09:08:07,100-Speed 1084.20 samples/sec   Loss 1.0801 target_logit_mean -0.0009 lma 0.6860  cos_theta_tmp 0.8214  Epoch: 8   Global Step: 126350   Required: 27 hours
Training: 2025-12-01 09:08:24,847-Speed 1081.91 samples/sec   Loss 1.1077 target_logit_mean 0.0020 lma 0.6992  cos_theta_tmp 0.8201  Epoch: 8   Global Step: 126400   Required: 27 hours
Training: 2025-12-01 09:08:42,485-Speed 1088.59 samples/sec   Loss 1.0380 target_logit_mean 0.0020 lma 0.6964  cos_theta_tmp 0.8233  Epoch: 8   Global Step: 126450   Required: 27 hours
Training: 2025-12-01 09:09:00,047-Speed 1093.31 samples/sec   Loss 1.0886 target_logit_mean 0.0024 lma 0.6948  cos_theta_tmp 0.8232  Epoch: 8   Global Step: 126500   Required: 27 hours
Training: 2025-12-01 09:09:17,550-Speed 1096.95 samples/sec   Loss 1.0669 target_logit_mean -0.0002 lma 0.6983  cos_theta_tmp 0.8249  Epoch: 8   Global Step: 126550   Required: 27 hours
Training: 2025-12-01 09:09:35,015-Speed 1099.44 samples/sec   Loss 1.0505 target_logit_mean 0.0028 lma 0.6998  cos_theta_tmp 0.8252  Epoch: 8   Global Step: 126600   Required: 27 hours
Training: 2025-12-01 09:09:52,575-Speed 1093.43 samples/sec   Loss 1.0400 target_logit_mean 0.0019 lma 0.7026  cos_theta_tmp 0.8269  Epoch: 8   Global Step: 126650   Required: 27 hours
Training: 2025-12-01 09:10:10,186-Speed 1090.26 samples/sec   Loss 1.0584 target_logit_mean 0.0012 lma 0.6878  cos_theta_tmp 0.8200  Epoch: 8   Global Step: 126700   Required: 27 hours
Training: 2025-12-01 09:10:27,800-Speed 1090.07 samples/sec   Loss 1.0472 target_logit_mean 0.0018 lma 0.6872  cos_theta_tmp 0.8259  Epoch: 8   Global Step: 126750   Required: 27 hours
Training: 2025-12-01 09:10:45,342-Speed 1094.57 samples/sec   Loss 1.0716 target_logit_mean -0.0009 lma 0.6877  cos_theta_tmp 0.8216  Epoch: 8   Global Step: 126800   Required: 27 hours
Training: 2025-12-01 09:11:02,905-Speed 1093.22 samples/sec   Loss 1.0739 target_logit_mean 0.0023 lma 0.6791  cos_theta_tmp 0.8251  Epoch: 8   Global Step: 126850   Required: 27 hours
Training: 2025-12-01 09:11:20,384-Speed 1098.53 samples/sec   Loss 1.0369 target_logit_mean -0.0014 lma 0.6810  cos_theta_tmp 0.8181  Epoch: 8   Global Step: 126900   Required: 27 hours
Training: 2025-12-01 09:11:37,945-Speed 1093.38 samples/sec   Loss 1.0790 target_logit_mean -0.0008 lma 0.6853  cos_theta_tmp 0.8198  Epoch: 8   Global Step: 126950   Required: 27 hours
Training: 2025-12-01 09:11:55,513-Speed 1092.94 samples/sec   Loss 1.1053 target_logit_mean -0.0001 lma 0.6888  cos_theta_tmp 0.8238  Epoch: 8   Global Step: 127000   Required: 27 hours
Training: 2025-12-01 09:12:13,067-Speed 1093.77 samples/sec   Loss 1.0644 target_logit_mean 0.0012 lma 0.6936  cos_theta_tmp 0.8231  Epoch: 8   Global Step: 127050   Required: 27 hours
Training: 2025-12-01 09:12:30,670-Speed 1090.79 samples/sec   Loss 1.0682 target_logit_mean -0.0002 lma 0.6964  cos_theta_tmp 0.8240  Epoch: 8   Global Step: 127100   Required: 27 hours
Training: 2025-12-01 09:12:48,166-Speed 1097.40 samples/sec   Loss 1.0381 target_logit_mean 0.0024 lma 0.6845  cos_theta_tmp 0.8220  Epoch: 8   Global Step: 127150   Required: 27 hours
Training: 2025-12-01 09:13:05,689-Speed 1095.71 samples/sec   Loss 1.0731 target_logit_mean -0.0003 lma 0.6795  cos_theta_tmp 0.8191  Epoch: 8   Global Step: 127200   Required: 27 hours
Training: 2025-12-01 09:13:23,237-Speed 1094.20 samples/sec   Loss 1.0782 target_logit_mean 0.0025 lma 0.6939  cos_theta_tmp 0.8270  Epoch: 8   Global Step: 127250   Required: 27 hours
Training: 2025-12-01 09:13:40,779-Speed 1094.59 samples/sec   Loss 1.0715 target_logit_mean 0.0018 lma 0.6987  cos_theta_tmp 0.8260  Epoch: 8   Global Step: 127300   Required: 27 hours
Training: 2025-12-01 09:13:58,320-Speed 1094.58 samples/sec   Loss 1.0691 target_logit_mean -0.0019 lma 0.6971  cos_theta_tmp 0.8203  Epoch: 8   Global Step: 127350   Required: 27 hours
Training: 2025-12-01 09:14:15,843-Speed 1095.74 samples/sec   Loss 1.0765 target_logit_mean 0.0013 lma 0.6868  cos_theta_tmp 0.8213  Epoch: 8   Global Step: 127400   Required: 27 hours
Training: 2025-12-01 09:14:33,367-Speed 1095.69 samples/sec   Loss 1.0776 target_logit_mean -0.0005 lma 0.6952  cos_theta_tmp 0.8174  Epoch: 8   Global Step: 127450   Required: 27 hours
Training: 2025-12-01 09:14:50,831-Speed 1099.45 samples/sec   Loss 1.0760 target_logit_mean -0.0005 lma 0.6893  cos_theta_tmp 0.8236  Epoch: 8   Global Step: 127500   Required: 27 hours
Training: 2025-12-01 09:15:08,378-Speed 1094.25 samples/sec   Loss 1.0562 target_logit_mean -0.0006 lma 0.6956  cos_theta_tmp 0.8169  Epoch: 8   Global Step: 127550   Required: 27 hours
Training: 2025-12-01 09:15:25,903-Speed 1095.61 samples/sec   Loss 1.0918 target_logit_mean 0.0004 lma 0.6872  cos_theta_tmp 0.8200  Epoch: 8   Global Step: 127600   Required: 27 hours
Training: 2025-12-01 09:15:43,399-Speed 1097.40 samples/sec   Loss 1.0809 target_logit_mean 0.0002 lma 0.6897  cos_theta_tmp 0.8215  Epoch: 8   Global Step: 127650   Required: 27 hours
Training: 2025-12-01 09:16:00,832-Speed 1101.42 samples/sec   Loss 1.0388 target_logit_mean 0.0004 lma 0.6880  cos_theta_tmp 0.8231  Epoch: 8   Global Step: 127700   Required: 27 hours
Training: 2025-12-01 09:16:18,332-Speed 1097.14 samples/sec   Loss 1.0825 target_logit_mean -0.0014 lma 0.6894  cos_theta_tmp 0.8212  Epoch: 8   Global Step: 127750   Required: 27 hours
Training: 2025-12-01 09:16:35,952-Speed 1089.75 samples/sec   Loss 1.0817 target_logit_mean 0.0029 lma 0.6843  cos_theta_tmp 0.8213  Epoch: 8   Global Step: 127800   Required: 27 hours
Training: 2025-12-01 09:16:53,467-Speed 1096.24 samples/sec   Loss 1.0710 target_logit_mean -0.0003 lma 0.6780  cos_theta_tmp 0.8130  Epoch: 8   Global Step: 127850   Required: 27 hours
Training: 2025-12-01 09:17:11,022-Speed 1093.73 samples/sec   Loss 1.0943 target_logit_mean -0.0026 lma 0.6945  cos_theta_tmp 0.8173  Epoch: 8   Global Step: 127900   Required: 27 hours
Training: 2025-12-01 09:17:28,541-Speed 1095.97 samples/sec   Loss 1.1032 target_logit_mean 0.0010 lma 0.6915  cos_theta_tmp 0.8164  Epoch: 8   Global Step: 127950   Required: 27 hours
Training: 2025-12-01 09:17:46,052-Speed 1096.54 samples/sec   Loss 1.0851 target_logit_mean 0.0003 lma 0.6957  cos_theta_tmp 0.8206  Epoch: 8   Global Step: 128000   Required: 27 hours
Training: 2025-12-01 09:18:03,559-Speed 1096.75 samples/sec   Loss 1.1198 target_logit_mean -0.0010 lma 0.6849  cos_theta_tmp 0.8211  Epoch: 8   Global Step: 128050   Required: 27 hours
Training: 2025-12-01 09:18:21,044-Speed 1098.10 samples/sec   Loss 1.0687 target_logit_mean 0.0005 lma 0.6943  cos_theta_tmp 0.8205  Epoch: 8   Global Step: 128100   Required: 27 hours
Training: 2025-12-01 09:18:38,636-Speed 1091.48 samples/sec   Loss 1.0379 target_logit_mean 0.0012 lma 0.6999  cos_theta_tmp 0.8224  Epoch: 8   Global Step: 128150   Required: 27 hours
Training: 2025-12-01 09:18:56,238-Speed 1090.82 samples/sec   Loss 1.0831 target_logit_mean 0.0001 lma 0.6945  cos_theta_tmp 0.8200  Epoch: 8   Global Step: 128200   Required: 27 hours
Training: 2025-12-01 09:19:13,853-Speed 1089.97 samples/sec   Loss 1.0694 target_logit_mean -0.0007 lma 0.6955  cos_theta_tmp 0.8188  Epoch: 8   Global Step: 128250   Required: 27 hours
Training: 2025-12-01 09:19:31,358-Speed 1096.90 samples/sec   Loss 1.1130 target_logit_mean -0.0028 lma 0.6789  cos_theta_tmp 0.8156  Epoch: 8   Global Step: 128300   Required: 27 hours
Training: 2025-12-01 09:19:48,784-Speed 1101.82 samples/sec   Loss 1.0762 target_logit_mean -0.0001 lma 0.6898  cos_theta_tmp 0.8153  Epoch: 8   Global Step: 128350   Required: 27 hours
Training: 2025-12-01 09:20:06,215-Speed 1101.55 samples/sec   Loss 1.0765 target_logit_mean -0.0013 lma 0.6949  cos_theta_tmp 0.8209  Epoch: 8   Global Step: 128400   Required: 27 hours
Training: 2025-12-01 09:20:23,648-Speed 1101.38 samples/sec   Loss 1.0698 target_logit_mean 0.0011 lma 0.6845  cos_theta_tmp 0.8187  Epoch: 8   Global Step: 128450   Required: 27 hours
Training: 2025-12-01 09:20:41,081-Speed 1101.43 samples/sec   Loss 1.0902 target_logit_mean -0.0013 lma 0.6831  cos_theta_tmp 0.8192  Epoch: 8   Global Step: 128500   Required: 27 hours
Training: 2025-12-01 09:20:58,512-Speed 1101.48 samples/sec   Loss 1.0934 target_logit_mean 0.0012 lma 0.6953  cos_theta_tmp 0.8244  Epoch: 8   Global Step: 128550   Required: 27 hours
Training: 2025-12-01 09:21:15,942-Speed 1101.60 samples/sec   Loss 1.1000 target_logit_mean 0.0007 lma 0.6819  cos_theta_tmp 0.8200  Epoch: 8   Global Step: 128600   Required: 27 hours
Training: 2025-12-01 09:21:33,376-Speed 1101.36 samples/sec   Loss 1.0925 target_logit_mean -0.0028 lma 0.6740  cos_theta_tmp 0.8171  Epoch: 8   Global Step: 128650   Required: 27 hours
Training: 2025-12-01 09:21:50,809-Speed 1101.37 samples/sec   Loss 1.0734 target_logit_mean 0.0014 lma 0.6897  cos_theta_tmp 0.8245  Epoch: 8   Global Step: 128700   Required: 27 hours
Training: 2025-12-01 09:22:08,239-Speed 1101.59 samples/sec   Loss 1.0888 target_logit_mean -0.0021 lma 0.6870  cos_theta_tmp 0.8166  Epoch: 8   Global Step: 128750   Required: 27 hours
Training: 2025-12-01 09:22:25,670-Speed 1101.53 samples/sec   Loss 1.0886 target_logit_mean -0.0009 lma 0.6851  cos_theta_tmp 0.8224  Epoch: 8   Global Step: 128800   Required: 27 hours
Training: 2025-12-01 09:22:43,099-Speed 1101.63 samples/sec   Loss 1.0597 target_logit_mean -0.0000 lma 0.6847  cos_theta_tmp 0.8225  Epoch: 8   Global Step: 128850   Required: 27 hours
Training: 2025-12-01 09:23:00,528-Speed 1101.64 samples/sec   Loss 1.0948 target_logit_mean -0.0009 lma 0.6984  cos_theta_tmp 0.8210  Epoch: 8   Global Step: 128900   Required: 27 hours
Training: 2025-12-01 09:23:17,960-Speed 1101.51 samples/sec   Loss 1.0647 target_logit_mean 0.0004 lma 0.6930  cos_theta_tmp 0.8227  Epoch: 8   Global Step: 128950   Required: 27 hours
Training: 2025-12-01 09:23:35,387-Speed 1101.77 samples/sec   Loss 1.0931 target_logit_mean -0.0006 lma 0.6882  cos_theta_tmp 0.8256  Epoch: 8   Global Step: 129000   Required: 27 hours
Training: 2025-12-01 09:23:52,820-Speed 1101.42 samples/sec   Loss 1.0886 target_logit_mean -0.0021 lma 0.6886  cos_theta_tmp 0.8155  Epoch: 8   Global Step: 129050   Required: 27 hours
Training: 2025-12-01 09:24:10,252-Speed 1101.42 samples/sec   Loss 1.0931 target_logit_mean 0.0012 lma 0.6945  cos_theta_tmp 0.8219  Epoch: 8   Global Step: 129100   Required: 27 hours
Training: 2025-12-01 09:24:27,685-Speed 1101.41 samples/sec   Loss 1.0895 target_logit_mean 0.0019 lma 0.6974  cos_theta_tmp 0.8199  Epoch: 8   Global Step: 129150   Required: 27 hours
Training: 2025-12-01 09:24:45,242-Speed 1093.59 samples/sec   Loss 1.0576 target_logit_mean -0.0009 lma 0.6855  cos_theta_tmp 0.8172  Epoch: 8   Global Step: 129200   Required: 27 hours
Training: 2025-12-01 09:25:02,767-Speed 1095.66 samples/sec   Loss 1.0962 target_logit_mean -0.0006 lma 0.6868  cos_theta_tmp 0.8151  Epoch: 8   Global Step: 129250   Required: 27 hours
Training: 2025-12-01 09:25:20,208-Speed 1100.89 samples/sec   Loss 1.0740 target_logit_mean 0.0017 lma 0.6997  cos_theta_tmp 0.8230  Epoch: 8   Global Step: 129300   Required: 27 hours
Training: 2025-12-01 09:25:37,618-Speed 1102.82 samples/sec   Loss 1.0803 target_logit_mean 0.0001 lma 0.6823  cos_theta_tmp 0.8203  Epoch: 8   Global Step: 129350   Required: 27 hours
Training: 2025-12-01 09:25:54,995-Speed 1104.98 samples/sec   Loss 1.0836 target_logit_mean 0.0002 lma 0.6977  cos_theta_tmp 0.8193  Epoch: 8   Global Step: 129400   Required: 27 hours
Training: 2025-12-01 09:26:12,546-Speed 1094.00 samples/sec   Loss 1.0620 target_logit_mean -0.0018 lma 0.6792  cos_theta_tmp 0.8194  Epoch: 8   Global Step: 129450   Required: 27 hours
Training: 2025-12-01 09:26:30,028-Speed 1098.31 samples/sec   Loss 1.0843 target_logit_mean 0.0014 lma 0.6836  cos_theta_tmp 0.8156  Epoch: 8   Global Step: 129500   Required: 27 hours
Training: 2025-12-01 09:26:47,482-Speed 1100.09 samples/sec   Loss 1.0832 target_logit_mean 0.0001 lma 0.6981  cos_theta_tmp 0.8242  Epoch: 8   Global Step: 129550   Required: 27 hours
Training: 2025-12-01 09:27:04,887-Speed 1103.12 samples/sec   Loss 1.0654 target_logit_mean 0.0023 lma 0.6918  cos_theta_tmp 0.8221  Epoch: 8   Global Step: 129600   Required: 27 hours
Training: 2025-12-01 09:27:22,321-Speed 1101.38 samples/sec   Loss 1.0631 target_logit_mean 0.0004 lma 0.6820  cos_theta_tmp 0.8208  Epoch: 8   Global Step: 129650   Required: 27 hours
Training: 2025-12-01 09:27:39,835-Speed 1096.30 samples/sec   Loss 1.0861 target_logit_mean -0.0023 lma 0.6882  cos_theta_tmp 0.8158  Epoch: 8   Global Step: 129700   Required: 27 hours
